var store = [
  
    
    
    
      
      {
        "title": "잡코리아 현직자 멘토링 (LG CNS BigData)",
        "excerpt":
          
            "   문제시 삭제하겠습니다.   LG CNS     각 담당사업부(전자, 이노텍 등)와만 일을 한다       취업준비   데이터 관련 역량      엑셀 vlookup, SQL 역량 어필하면 좋다   커뮤니케이션 능력      원하는/예상하는 데이터가 나오지 않았을때, 설득하는 능력   담당엔지니어의 평소 고민을 숫자로 보여주고 문제를 해결해야 할 때가 많음   대단한 알고리즘을 아는 것보다는 담당자가 말해주지 않는 문제를 정확히 파악하는 게 중요   제조업 분야 데이터 분석을 위해선 해당 분야에서 사용하는 프로그램들을 미리 파악해야; ERP, SCM 등   딥러닝     화이트박스로 데이터 분석   어떤 알고리즘으로 정확도가 높아졌는지와 무관하게 결과값만 잘 나오면 되기 때문에   LG CNS 장점     잔업무 없이 데이터 분석만 하면 된다   실적 압박 거의 없음; 디스플레이가 안좋아지면 화학이나 전자로 발령남   스펙은 있을수록 좋지만, 무엇보다 인성이 중요하다     잘 견디고 잘 어울리는 사람   나 없으면 못할 그런 대단한 업무는 없다   데이터는 주로 SQL로 받아서 CSV 형태로 관리     꼭 파이썬 같은 코딩을 할 필요는 없다.   엑셀 정말 많이 쓰고, SQL/RDBMS 다룰 줄 알면 좋다,   도메인 관련 업무가 50% 이상   머신러닝 위한 학습데이터 입력 : 완전 단순노동, 이것만 몇달 하는 경우도 많음   사내교육     회사 내부적으로 머신러닝 인력이 많지 않아서 교육은 원하는대로 시켜줌   데이터 분석 직무     특정 산업군에 특화되는 경우는 별로 없고,   그때그때 일을 하지만   제조업 쪽으로 특화되면 안정적이라 좋다   지금까지 다양한 업무 해왔지만 데이터 분석 업무는 업무의 효율 개선할 수 있는 업무라 강력 추천   특히 DW 업무, 내가 만든 보고서의 파급력이 크다, 공정 설비가 바뀜   이래서 보고서가 중요함; 일반 엔지니어가 잘 모르는 게 많을 수 있어서 잘 설명해야, 분석결과에 대한 시각화 중요, 아무리 분석 잘해도 상대가 수긍하지 않으면 날라간다   역량 어필     단순히 어떤 알고리즘 알고 있고 코딩할 수 있다 보다는   해당 산업에서 데이터 분석이 필요한 분야를 알고 있고, 대회/공모전 수상 이력 어필   신입은 당장 투입하지 않고, 교육을 시켜서 그 분야에서 활용할 수 있게 함   데이터 분석 +도메인 지식(타분야 지식; 공정/금융 등) 있으면 메리트 큼   자격증     ADsP, 구글 애널리틱스는 기본적인 자격증, 입사자 다 갖고 있음,   필수 아니지만 없으면 불리   근무환경     데이터 분석가는 혼자 공장에 파견, 혼자 공정 배우고 보고서 냄  ",
          
        "categories": ["Career","Aidata"],
        "tags": ["Career","BigData","HyndaiCard","Mentor"],
        "url": "https://gitgitwi.github.io"/career/aidata/LGCNS_BigData/"",
        "teaser": null
      },
    
      
      {
        "title": "신한퓨쳐스랩 취준생을 위한 Lunch Talk",
        "excerpt":
          
            "1부. 김나이 작가   소개   현대카드-한투증권-JP모건 근무 후 커리어 엑셀러레이터   원하는 곳에서 원하는 일을 하기 위해 반드시 기억해야 할 것      나에 대한 이해; 내가 좋아하고 잘할 수 있는 것   상대에 대한 이해 ; 기업과 직무   나는 스타트업에 맞는 사람인가?      성장 - 스타트업 커브, 대기업의 구조화된 일과는 달리 다양한 업무 수행   돈   워라밸 - 주52시간제의 예외, 일하는 시간의 경계가 없음, 주도성이 있어야   의미   재미 - 일에서 어떤 재미를 느끼는가   인간관계   스타트업 진입은 투자자의 관점에서 봐야     시장의 성장성, 대표의 성향   Why-Mission, How-Information Research, What-Business Model ￼     Business Model Canvas          어디서 어떻게 돈을 벌고, 어디로 돈이 나가는지   Product Life Cycle   개인에게 좋은 시기는 도입기를 지나 성장기-성숙기에서 쇠퇴기 직전까지   경력 이직   지금의 이직시장은 전직장의 네임 벨류 보다 실제로 했던 업무가 무엇인지가 중요   앞으로 우리의 일은 어떻게 바뀔까?     나만의 커리어 지도를 그려봐야   첫 커리어에 대해 너무 걱정하지말자          2부. 토크 콘서트; 로켓펀치 조민희 대표, 김나이 작가   패널 소개   어니스트펀드 브랜드팀 팀장 고재형     자사 브랜드 전략 총괄   문과생으로 금융 브랜딩, 페이스북 문과생존원정대 운영   런인베스트 엄기현 이사     법/심리 전공-대통령경호실 경호관-메트라이프 기업컨설팅-창업실패 후 런인베스트,   취업은 소개팅이다; 사전준비와 상호탐색이 중요하다   블루프린트랩 AI 엔지니어 박종민     빅데이터 경영 전공;   개발자로서 알고리즘과 자료구조를 잘 알아야,   학교에서의 프로젝트는 결과만 내는 것으로 보여서 그닥, 블로그/Github 활용해 프로젝트 정확히 정리   사전 질의 응답  1. 자신이 잘하는 것을 찾는 방법     소거법; 다양한 일을 해보면서 자신이 못하는 것을 버리고 잘하는 것을 찾는다   잘할 수 있거나 잘할 거 같은 영역에 있는 현직자를 만나서 이야기를 해본다, 잘 모르는 사람이라도 생각보다 많은 사람이 긍정적으로 답변해준다   정중하게 메일을 보내야 정중하게 답을 줄 것   2. 직무/커리어를 바꿔서 중고신입으로 갈 떄?     이전에 어떤 일이든지 그 일을 통해서 강점/역량을 찾자   직무를 변경할 때는 본인을 갈아넣어야 한다   현직자들과의 네트워크 형성   의미 없는 일은 없다, 일단 뭐라도 하면서 이 일을 좋아하고 잘할 수 있다고 믿으며 간다  ",
          
        "categories": ["Career","Start-up"],
        "tags": ["Career","Start-up","신한퓨쳐스랩"],
        "url": "https://gitgitwi.github.io"/career/start-up/ShinhanFuturesLab_LunchTalk/"",
        "teaser": null
      },
    
      
      {
        "title": "itdaa 현직자 멘토링 (현대카드 Data Engineer)",
        "excerpt":
          
            "1부 특강   현대카드 기업 소개     ‘디지탈’ 현대카드   Digitalization - Data driven economy; 요즘 금융권에서 디지탈을 빼놓을 수 없다   양질의 데이터 수집 - 가공 - 빠른 분석 - 초개인화 마케팅   개인정보/민감정보 관리 문제, 금융당국 규제; 금융은 정부 규제가 강함   Hybrid - Multi - Cloud; data를 위해 Cloud가 필수적, 그중에서도 multi / hybrid cloud 도입 확산; public cloud + private cloud   빅데이터팀 부서 소개     data warehouse ; data base에서 심화된 개념   big data platform ;  warehouse에 저장된 data를 platform에 옮긴다   data engineering ; platform에서 data 꺼내서 마케팅/서비스를 위한 자료 가공, 서비스 이용을 통해 만들어진 data는 다시 warehouse로   2019 채용 트렌드  IT산업의 채용 트렌드     data와 관련된 직무 채용 본격화, 이전 보다 많이 늘어남   기존 전통 직무 채용 또한 유지   스펙 보다는 실력/경험 위주의 채용 증가세   여전한 수요/공급 불균형   기업 문화 변화   금융 IT 채용 트렌드     digitalization 인력 채용 증가; 전체 인원은 감소할 수도..   은행권 필기시험 부담   스펙 비중이 줄어드는 느낌   IT 직무 소개; 가장 많이 하는/중요한 업무     회의; 애자일agile - 수평적 관계, 유연한 조직/업무처리, 점점 복잡하고 빨라지는 환경에 대응, XP(extreme programming) / 짝코딩 / 코드 리뷰   SW개발 : 요구사항 분석, 아키텍처 설계, 개발/구현, 테스트(!중요!), 적용; TDD test-driven development, test에 대한 중요성, 서비스에 대한 신뢰도   끊임 없는 공부/자기개발; 기술이 빠르게 생김, 최신 기술은 대부분 영어, 체력관리   IT 직무의 장단점     자부심, 보람 / 야근, 주말 연휴 출근;            지번 주소 → 도로명 주소; 약 1년의 준비 기간 필요       차세대 시스템 도입; 특히 금융권은 주말/새벽에 업데이트           비교적 높은 업무 자유도 / 반복되는 삽질; 시행착오   4차 산업의 핵심 업종 / 계속해야 하는 공부   낮은 직무별 장벽 / 지속적인 이직 고민            SW개발, 데이터엔지니어링, 기획 운영, QA 등 직무 간 장벽이 낮은 편, 자기 노력 여하에 따라 충분히 가능       잦은 이직이 흠이 되지 않음           취업 노하우     탄탄한 기본역량 : 기본이 튼튼해야 실력이 쑥쑥   기술에 대한 이해 및 호기심; 기술 트렌드, 신기술 습득 등   다양한 커뮤니케이션 능력; PJT는 혼자할 수 없다, 회의가 많음, 개발자들끼리만 하는게 아니라 다양한 사람들과   다양한 기술 행사 참석; 무료세미나, 밋업, 깃헙; 다 알아들을 필요는 없음, 핵심적인 것만   직무기업분석     지원가능한 회사의 종류; 모든 회사에 있음            공기업/공무원 전산부서       전산 전문 공기업       민간기업 전산 부서 : 약간의 엔지니어링 업무, 전산지원, 시스템 관리 및 아웃소싱 관리       SW전문 기업 : 특정 분야 엔지니어링 업무           지원하려는 기업의 특성을 먼저 파악; 몇군데 정도는 미리 자세히 알아보고 지원하자   자소서/면접     이력서/자기소개서를 왜 쓰나? 면접에 불러 볼만한 사람을 고르는 것   기술적/사회적 이슈를 한 두개씩 분석하고 이슈들이 가져올 영향을 통찰해 보는 연습, 이슈가 가져올 영향에 대한 자신만의 생각, 기업/직무와도 연관지어서   다른 사람과는 다른 나만의 경험, 지식을 지원하는 회사에 연결지어          2부 QnA   삼성SDS와 현대카드     삼성SDS; 대기업/공공기관에 필요한 소프트웨어 개발이기 때문에 안정성이 중요   현대카드; 개발 관련 체계는 부족하지만 좀더 트렌디한 것들   국비교육      학원이 기술습득에는 빠르긴 한데, 그 외 추가적인 공부를 하는게 좋다   알고리즘 공부     한이음 프로젝트 경험   기업이 중요하게 생각하는 역량      협업(소통)능력 »&gt; 응용업무지식 &gt; 기초업무지식 &gt; 다양한 경험과 생각 ; 임베디드sw 직무에 안드로이드 경험만 있을 경우, 임베디드sw와 안드로이드 공통 기술적 지식   프로젝트를 통한 역량 어필     프로젝트 경험 = 기술적인 지식&amp;경험 - 포트폴리오 정리; 회사를 5개 정도 미리 선정하고 관련 프로젝트를 미리 해보면 더 좋다; 경험과 관심 어필 가능   소규모 개인 프로젝트라도 많이 해보는 것 vs. 규모가 있는 협업 프로젝트를 조금 해보는 것; 정답이 없는 문제, 둘다 있으면 제일 좋고 기업이기 때문에 협업이 조금더 좋을 수 있음   나이 많고 비전공자인데 SW개발 시작해도 될까?      나이/성별/학력의 장벽이 낮은 분야가 SW분야   의외로 비전공자 많다, 전공자만큼의 지식을 따라잡긴 어려울 수 있다, 기본적인 지식+전공지식 격차를 커버할 수 있는 다른 것이 필요   시작은 미약하나 끝은 창대하리라, 노력과 운 여하에 따라 다른 문제   목표 회사 준비     중점으로 지원할 회사를 5개 정도 미리 준비하자   회사에 대해 자세하게 알아보자   천편일률적인 자소서 중에 한두개 정도 눈에 확 뜨일만한 내용이 있어야   경력     SW분야는 경력이 중요, 신입은 힘들지만 경력에게는 천국   특히 데이터 분야 경력 조금만 있어도 이직 기회 상당히 많다   학벌     대부분 학/석사 차이는 크지 않다, 학위보다 실력이 우선인 영역   그래도 학위가 높으면 좀더 기회가 많다. 일부 분야, 특히 데이터 분석은 석/박사 아니면 힘든 경우도 많아   여러 팀과의 협업     다양한 협업툴; agile 방법론 - Sprint, Kanban, 메신저 slack / Jandi   협업을 잘하는 것 = 소통 능력이 뛰어난 것 = 다른 사람에 관심이 높은 것   SI의 경우 기업 규모별 역할?     현실적으로 규모에 따른 차이는 없음, 프로젝트 마다 다름   2013 코레일 차세대 여객영업시스템 PJT 당시 삼성SDS + 협력사 + 솔루션사; 삼성SDS 100명, 협력사 7~80명, 솔루션  ",
          
        "categories": ["Career","Aidata"],
        "tags": ["Career","BigData","HyndaiCard","Mentor"],
        "url": "https://gitgitwi.github.io"/career/aidata/HyundaiCard_DataEngineer/"",
        "teaser": null
      },
    
      
      {
        "title": "itdaa 현직자 멘토링 (SK C&C)",
        "excerpt":
          
            "멘토님 개인정보는 최대한 삭제했습니다. 문제시 삭제하겠습니다.     Mentor 소개      인문계/경제학 전공   중소기업 개인정보보호 - 개발 및 IT기획, 한국은행, 협회, 카카오 모빌리티 등 거쳐, SK 정보보호팀 화이트해커(국가공인)   주로 시스템/웹/모바일 해킹   유튜브도 운영중   기업 소개 : SK C&amp;C (지주사)   겉보기에 young해보이지만, 지주사이기 때문에 평균연령 40대   부서 소개     윤리경영담당            내부 감사       보안 기획, 보안시스템운영, 보안 관제                    내부자료 유출자 조사, 내부 징계 또는 고소                           SK 내 ICBM 관련 사업이 많아 다룰 기회가 많다            IoT &gt; Cloud &gt; Big data &gt; Mobile           현업 이슈 소개     마윈, ‘현재의 AI는 기계 지능에 불과하다’; 인간이 넣어주는 자료만 처리 가능, 새로운 추론 불가, 착한 데이터인지 나쁜 데이터인지 판단 불가   Deep-Fake; 진짜인지 가짜인지 아직은 구분하지 못하는, 가짜뉴스-진짜뉴스, 피싱/스미싱, 뉴스/영상 조작, 가짜 SNS 계정   RPA; robotics process automation - macro 작업을 통해 회계/세무, PPT작성 등, 개발 부서에서도 RPA가 라이브러리 추천 등   인공지능에 대한 이해 : 모든 직무에 필요, 인공지능은 수학이 아니라 알고리즘이다; 규칙만 알면 할 수 있다, 간단한 인공지능 관련 서적 하나씩 읽고 간단한 아두이노 프로그래밍 해보자   모빌리티 : 최근 IT산업의 트렌드 파악            IBM 등 선두기업 투자; Cloud       손정의 비전펀드의 투자대상; Mobility/Hotel/Cloud/O2O       최근 현대차 공장 가동율 갈수록 낮아짐; Mobility, 공유경제, 전기차 확산으로 내연차 판매 감소; 위기의식       모빌리티 확산 비용 감소-시간 감소-일 감소; 사람만 이동하는 것이 아니라 물류까지 + 우주선?       물류 혁신; 새벽배송, 배민                    배민 어플을 통해 발생한 Big Data를 통해 가맹점 개설 및 컨설팅                             취업을 위한 Tip   비전공자의 관심 어필      학원 강의 수강 X   어떤 프로젝트를 통해 어떤 문제 해결을 위해 노력하고 그 과정에서 어려움을 어떻게 극복했는지, 어떤 것을 얻게 됐는지   기술이 없어도 프로젝트 수행 경험을 통해 어필하자   다양한 프로젝트 조직 가능            잇다에서도 현직자 멘토를 통해 가능하다       프로보노           비전공자의 접근법 : 4차 산업혁명 대표기술            3D 프린팅; 최근 제조업에서 주목하는 기술, 스캐너로 정보를 찍으면 바로 복제 가능; 산업 기술 유출에 기존 3년 6개월 걸리던 것에서 요즘은 1년 7개월 걸림       드론; 미국에서 드론 활용한 정보유출이 많음, 빌딩 스캔       일상생활 중에서 IT 관련 경험; 모든 증권사/보험사/은행사 어플을 깔고 서비스 가입 방식 비교하는 포트폴리오           영어   다양한 분야로 가기 위한 필수 조건, 특히 전문용어 fullname과 definition을 잘 알아두자   Amazon의 면접     9번의 전형   아마존 현직자의 critic에 대해 어떻게 논리적으로 대응할 것인가   왜 다르게 생각하는지 논리적인 설명   다양한 분야에 대한 준비 필요     어떤 분야로 갈 지 정확히 모르기 때문에, 다양하게 준비하는게 좋다   사원/대리급일 때는 한가지 확실히 잘하면서, 다양한 이해와 경험; 전문성에 대한 어필 + ICBM에 대한 관심 어필 + 갈등 관리 경험   IT기업들 분위기   NAVER     태생이 portal-정부의 규제-보수적   스타트업의 분위기를 다시 살리려 했으나, 팀제도/직급제 부활   Kakao     근본x, 다양한 팀이 합쳐져서 된 회사, 소도시의 연합 느낌   부서 간 소통이 많지도 않고 co-work이 안됨   현재도 스타트업의 분위기-개발자를 건드리지 않음, 다만 이직률 46%, 연합 없이 계속되는 M&amp;A, 질서가 없음   SK      겉으로는 cool/young하려 하지만   의류제조업 기반 -&gt; 보수적   하이닉스 등 M&amp;A로 큰 회사   전 계열사 Cloud화   LG     사내벤처 장려-creative   보수적이지도 오픈되지도 않은   S/L/삼 중 이직률 가장 낮음   석박사/유학 지원 가장 잘되어있음   임직원의 발전 장려하는 분위기   삼성     매뉴얼 중시, 협업 중시   발전사/통신사 IT부서 : 지능형 전력망 도입   IT - ICT의 구분     크게 구분되지 않지만, ICT가 좀더 생활밀착   ex) 키오스크; 비용절감 뿐만 아니라, big data 생성 가능, 쿠폰 제공 등   Big Data     현재 Big Data는 시나리오성 data가 중요            폰을 켜고 카카오톡을 켜고 뭘 했는지 일련의 과정           캐시/쿠키 정보 취득을 통해 data 형성   이때 시나리오는 모두 사람이 파악해야; UI/UX/소비자분석/서비스기획 등 기획 관련 부서에서 담당   개발직군에서 보안직군으로 가려면     먼저 위협에 대해 알아야            해킹 사건, 관련 기술 이해 - 공격자의 입장           위험에 대한 인지            충분히 예측/분석/관리/대응 가능한 위험       risk-taking에 대한 방법 - 방어자의 입장           자격증     필요한 것만 있으면 된다   정보처리기사 가장 무난하고 좋음   사설 자격증은 너무 비싸고 크게 의미 없음   일반적인 개발/operation은 생활코딩 수준이면 된다   자율주행차 인식기술     VR   AR   STT; Speech-to-text, 음성인식   TTS; text-to-speech   군집주행     최근 카카오에서 세계표준 만들어 인증받음   다중 객체를 인식해 상황판단   여러 자율주행차가 동시에 driving   GPS 위치데이터가 매우 중요, 자동차뿐만 아니라 앞으로는 스마트 깔창 등 인간 위치 정보도 중요해짐   스마트 깔창     걸을 때 운동에너지를 통해 발전, 배터리에 충전해 시장에서 거래   발바닥 정보를 통해 바이오 정보 제공   etc     IT직무에서도 아날로그적인 업무들이 많다   블로그/브런치 통해 작업물 정리   생활코딩에서 architect에 대해 알아보면 좋다   feedly 앱을 이용해 관련 뉴스 스크랩; RSS 서비스, 구글 검색어 서비스   다양한 생산성 프로그램, notion 추천   애자일 근무            체크리스트; 담당 업무 분배             Conclusion   컴퓨터는 주어진 데이터와 알고리즘을 통해 결과를 만들지만 사람은 데이터 결과를 통해 자신만의 알고리즘을 만들어야  ",
          
        "categories": ["Career","Aidata"],
        "tags": ["Career","Mentoring","BigData","SK C&C","itdaa"],
        "url": "https://gitgitwi.github.io"/career/aidata/SKCnC_Mentor/"",
        "teaser": null
      },
    
      
      {
        "title": "[삼성ClassX] Data만 있으면 Data-driven Business 할 수 있는거야?",
        "excerpt":
          
            "  강의자 : 엄재훈 프로 장소 : 선릉 스파크플러스     1부   Data Science   말만 무성한 것인지?   2010년은 구글이 사실상 처음으로 시작 그런데 실제 주변에서는 보기 힘든 AI, data 사업과 인력 제대로 다루고 있는 기업이나 인력이 아직은 부족하다 삼성에서도 채용을 많이하려고 하지만, 원하는 수준의 인력이 없다   찾아보기 힘든 이유     너무 큰 기대/환상   구현/적용 어려움   시도 X   현실의 AI / DATA와의 수준 차이   아직 단순 업무 자동화, 인간 흉내 수준     그러나 효과는 충분   먼저, Data라는 것이 무엇인지 정확히 인지하고 있어야 함       Data로 Biz를 혁신한다는 것?   제대로 된 Data-Driven Business란?     data 기반 biz 의사 결정을 하는 것   의사 결정의 객관적 근거; 검증된 실험 data를 기반으로 한 의사 결정   이미 실천해 오고 있는 global giants     google; How Google Works?            MAKE ALL DECISIONS WITH DATA           Marissa Mayer’s : 9 Principles of Innovation   Data-Driven Biz Innovation     data라는 명확한 기준이 있기 때문에,   의사결정 권한 위임을 통한 실무자 자율업무 가능   보다 빠른 의사결정으로 빠르게 시장에 대응   주요 영역 : 대부분의 영역에서 가능   Data-Driven Biz Innovation 핵심역량     data            거거익선, 그러나 말 그대로 익선일뿐, 없다고 못하는 것은 아니다       data 또는 예산이 적다면, datafication or sample analysis       어차피 모든 데이터를 가질 순 없다           data scientist            모든 분야, 상황에서 data가 많을 수 없기 때문에 중요도가 더욱 올라감       datafication 효율 제고           누구나 data science 할 수 있는 시대     넘쳐나는 open-source and tools   그러나 툴과 언어가 data science는 아님, data engineering이 data science는 아님       Data Science     hacking skills ; programming   math &amp; Statistics   Substantive Expertise   Data 를 통해 잘못된 해석을 낳을수도 있기 때문에 주의해야!   핵심은 SCIENCE      RESEARCH &amp; EXPERIMENT   data&amp;data scientist가 준비됐다면      AI/BigData는 만능이 아니다   communication, teamwork, interaction.. ⇒  the DataOps Manifesto   data ethics   management-level의 data 역량; 교수님이 박사 논문을 교정해주듯, data가 만든 insight에 대해 오류를 지적해주는 등 올바른 의사결정에 도움줄 수 있는       Data Culture      모두가 하는 data analytics를 위해   data 기반 communication부터 시작 - business value 를 보여줄 수 있는 지표로 - 상호 review를 두려워하면 안됨    2부. Q &amp; A  ",
          
        "categories": ["Career","Aidata"],
        "tags": ["Career","BigData","Samsung ClassX","Seminar"],
        "url": "https://gitgitwi.github.io"/career/aidata/samsung_classx/"",
        "teaser": null
      },
    
      
      {
        "title": "itdaa 현직자 멘토링 (SKT BigData)",
        "excerpt":
          
            "AI / Big Data   왜 AI가 이렇게 유행인가? 경쟁에서 살아남기 위해   AI를 하기 위한 기반이 바로 data   대표적인 사례 : TARGET mart의 소비자 구매 패턴 분석 / Amazon / AlphaGo / 중국 안면인식   어쩔수 없이 쌓이는 데이터가 아닌, 효율적인 비즈니스와 자동화를 위한 데이터   머신러닝 기반 신용평가 모형 개발, 핀테크   데이터가 필요한 이유 : 호기심, 명확한 목표설정, 설득, 서비스 포인트 개선, 순위 비교   데이터를 수집/사용하기 위한 plan   명확한 목표, 개선이 필요한 부분 발견 / 데이터 수집 (입력한 정보, 발생한 정보) / 분석 모형, 예측 / 효과-개선     멘토가 대학원 진학 전후로 준비한 것들           빅콘테스트 (빅데이터 콘테스트) : 토렌트 파일 다운로드 수와 시청률 비교하여 온라인 시청자층과 TV 시청자층 비교            Coursera -Machine Learning, CS224 등 기본적인 공부            자연어 처리 - 텍스트 분석 관련 프로젝트 들            전공자 / Python / R / SQL _(회사에서 많이..) _         현직 이야기..   대시보드 제작 - Shiny, Dash : 할 수 있으면 경험해 보길 추천     데이터 사이언티스트가 되기 위해서..   data scientist를 검색하면 나오는 그림 -      지금은 이전보다 data science의 업무도 세분화/전문화되고 있음,   한 사람이 모든 걸 다할 줄 알 필요는 없음      math &amp; programming은 요즘 누구나 다 어느 정도 한다   쉽게 놓치는 부분 : Soft Skills 와 Communication   선택과 집중: 나의 상황과 원하는 직무를 분석           상상만 하지 말고 일단 해본다            채용공고 활용 : 지금 시장에서 필요로 하는 직군/직무가 뭔지            혼자 모든 걸 다하는 엔터테이너 보다는 전문가가 필요한 시대       Skills           Data Engineering : AWS / GCP            Data Analyst : SQL / Python / R            Machine Learning Engineer : 실제 서비스 운영까지 고려해서 서비스 애플리케이션 개발까지,       ex) Y 업체 채용공고   https://yanolja.in/recruitment/           어떤 Skill이 필요한지 파악하고 준비하고 지원하자            외국 회사는 더욱 세분화해서 채용공고 올림            search on Google “Data Scientist Interview questions“            나만의 창의적인 사례 분석         FAQ   비전공자 / 문과생의 커리어 전환           실질적으로 전공자들과 경쟁하기에 어려움이 있음, 복수전공/대학원 진학을 가장 추천            실제로 전공자 석사 출신이 신입사원의 40% 이상 차지함            그런 상황이 안된다면 본인 전공/전문성을 살려 창의적인 분석 경험을 한다면 인사담당자의 눈길을 사로잡을 수 있을 것; 논문이나 블로그라도..            스스로 아이디어 내서 분석해보기!       자격증      있으면 좋지만 필수는 아님, 공기업은 가점 주지만 사기업은 딱히.. SQLD, ADsP   도메인 지식      대부분 외부에서 알기는 어려움, 일반적인 수준으로만 알아도 됨   중고신입      너무 다양하고 역할에 맞지 않는 경험은 오히려 감점요인   데이터 분석가 지원했는데 FE 개발 1~2년 근무 경험 어필은 X   Hard SKill 보다는 Soft Skill 을 꼭 강조했으면 좋겠다      단순히 Kaggle 잘한다고 뽑히지 않는다   블로그, GitHub      꾸준히 하길..은근 꾸준히 하기가 쉽지 않음, 제대로 하는 사람 잘 못봤다   SNS 통해 지속적인 정보 습득     데이터 분석가의 미래           분석 프로세스의 자동화            각 도메인 별 데이터 전문가 생길 것으로 전망            데이터 분석가 / 머신러닝 AI 엔지니어 구분이 뚜렷해 질 것 : 엔지니어는 좀더 서비스에 집중, 데이터 분석가는 좀더 비즈니스에 집중            그러면서 커뮤니케이션 / Soft Skill의 중요성이 더욱 강해질 것 : 현업과 데이터 분석 간, 간단한 분석은 이미 시중에 나와있는 AWS, Google Cloud 등 만으로도 충분히 해결 가능, 더욱더 높은 수준의 비즈니스적 깊이 요구될 것         QnA           아직까지 실무자 중에 Python과 R 둘 다 쓸 수 있는 사람 많지 않다.            국비과정 /  Online Class의 한계 : 왠지 획일화 되어있을 거 같은 느낌, 남들과 다른 점을 명확히 보여주는 것이 좋겠다      ",
          
        "categories": ["Career","Aidata"],
        "tags": ["Career","BigData","SKT","Mentor"],
        "url": "https://gitgitwi.github.io"/career/aidata/SKT_BigData_Mentor/"",
        "teaser": null
      },
    
      
      {
        "title": "[BOJ.2439/C] lv3. 별 찍기2",
        "excerpt":
          
            "#include &lt;stdio.h&gt;  int main() {     int n, i, j;     scanf(\"%d\", &amp;n);      for(i=1; i&lt;n+1; i++) {         for(j=n-i; j&gt;0; j-- ) {             printf(\" \");         }         for(j=1; j&lt;=i; j++) {             printf(\"*\");         }         printf(\"\\n\");     }      return 0; }   단순해 보이는데 방향 한번 바뀌었다고 생각하는데 시간이..ㅋㅋ   숏코딩 보다가 괜찮은 코드 발견   #include &lt;stdio.h&gt;  int main(void){ \tint i, j, N; \tscanf(\"%d\", &amp;N);  \tfor(i=0;i&lt;N;i++){ \t\tfor(j=0;j&lt;N;j++){ \t\t\tprintf(\"%c\", j&lt;N-i-1?' ':'*'); \t\t}         printf(\"\\n\"); \t} \treturn 0; }  ",
          
        "categories": ["fundamentals","algorithms"],
        "tags": ["algorithms","BOJ","C"],
        "url": "https://gitgitwi.github.io"/fundamentals/algorithms/boj2439/"",
        "teaser": null
      },
    
      
      {
        "title": "[BOJ.10871/Java&C] lv3. X보다 작은 수",
        "excerpt":
          
            "Java로는 바로 풀었는데   import java.io.*;  public class Main {      public static void main(String[] args) throws IOException {          BufferedReader br = new BufferedReader(new InputStreamReader(System.in));         BufferedWriter bw = new BufferedWriter(new OutputStreamWriter(System.out));           String input1 = br.readLine();         String input2 = br.readLine();         String[] cons = input1.split(\" \");         String[] numbers = input2.split(\" \");          for(int i=0; i&lt;Integer.parseInt(cons[0]); i++) {             if(Integer.parseInt(numbers[i])&lt;Integer.parseInt(cons[1])) {                 bw.write(numbers[i]+\" \");             }         }         bw.flush();     } }   C로는 역시 기본 문법이 익숙치 않다보니 조금 헤맴..   처음에 맨 아랫걸로 풀었다가 a[n] value type을 잘못 지정해서 계속 오답처리되고, 바로 밑에 걸로 수정함 ㅠ   배열 넣는 게 4ms 좀더 오래걸리는 것으로 나온다.   #include &lt;stdio.h&gt;  int main() {     int n, x, i;     scanf(\"%d %d\", &amp;n, &amp;x);      for (i = 0; i &lt; n ; i++) {         int o;         scanf(\"%d\", &amp;o);         if (o &lt; x) printf(\"%d \", o);     }     return 0; }   #include &lt;stdio.h&gt;  int main(void) {   int n, x, i;    scanf(\"%d %d\", &amp;n, &amp;x);    int a[n];     for (i = 0; i &lt; n ; i++) {       scanf(\"%d\", &amp;a[i]);       if (a[i] &lt; x) printf(\"%d \", a[i]);    }   return 0; }  ",
          
        "categories": ["fundamentals","algorithms"],
        "tags": ["algorithms","BOJ","Java","C"],
        "url": "https://gitgitwi.github.io"/fundamentals/algorithms/boj10871/"",
        "teaser": null
      },
    
      
      {
        "title": "itdaa 현직자 멘토링 (삼성SDS)",
        "excerpt":
          
            "date: Feb 25, 2020 7:04 PM   멘토분들 성함은 개인정보라 가렸습니다. 문제시 삭제하겠습니다.        멘토 소개           면접관, 사내 멘토링 경험            보안 분야 / 아키텍처 개발, 인프라 운영 3년 정도 - SW개발과는 다른 분야            삼성SDS 소개           6~7년전부터 단순 SI 에서 탈피 노력 - 글로벌 솔루션 기업 지향            그러나 최근 매출 감소로 다시 SI 분야 키우는 상황            직무:             사업 기획 - 운영 - 개발 - 유지보수 - 영업       사업 부서 별로 업무 환경 / 분위기는 많이 다를 수 있다                Q&amp;A      아키텍처는 IT개발과 구체적으로 어떤 차이가 있는지?            직접 코딩은 안하고, 서버 운영-관리           비전공자 - SCSA 로 입사            6개월 간 컴공4년 수준 모두 다뤄야 해서 거의 1주일에 1과목씩 진도, 당시 1기여서 대부분 합격       원래 대학원 준비를 하면서 취업준비 거의 안하다가 하게 되었고 정보처리기사만 땀       비전공자임에도 동기들보다 1년 진급 빨리 할 수 있었던 이유 : 적극적인 의사 표현, 보고서 작성 등                사내에 많은 시험/교육 기회 있음            알고리즘, 데이터 사이언스 분야 ; 자격증 따라고 권유 많이 함..            사내 커뮤니케이션 : 명확하게 - 돌려서 말하지 않기 위해 노력       개발자들의 업무 강도 : 제3자의 입장에서 봤을 때            agile style, 특히 솔루션 개발 쪽은 이전처럼 빡센 느낌은 아닌 듯, 특히 주니어일수록..       신입 때는 최대한 개발 경험을 많이 쌓도록 하는 분위기                EMM ? 대외적인 솔루션 중 가장 매출 높은 솔루션       면접관으로서 조언            의사표현능력 - 질문을 잘 못 알아듣는 경우를 많이 봄, 핵심 포인트만 간략하게 답하는 게 좋다       준비를 많이 한 사람은 티가 난다                시니어급이 아닌 이상 경력 채용은 경력 공채가 거의 다            기본적으로 자율출퇴근제            CI 분야에서 고객사 근무하는 경우는 고객사 환경에 따라            해외근무                       해외 출장은 종종 가는 편, 베트남은 지속적으로 출장 (부by부)                        주재원 : 업무 연관성이 있어야, 없으면 거의 불가능                        삼성SDS 아메리카는 아예 다른 회사, 본사 퇴수 후 아메리카 입사하는 방식                        외국어 능력 - 어플리케이션 개발 때는 1~2선, 현재 솔루션 분야에서는 3~4선 정도라 직접 대화는 거의 없음            OPIC AL 권장, IH까지는 3년마다 계속 OPIC 봐야하나 AL 한번 따면 퇴사때까지 인정해줌            사장님 추천도서              경영/경제 : 디커플링, 화폐혁명       IT : 아마존vs구글 미래전쟁, 딥러닝 첫걸음           스펙은 최소기준만 넘으면 되고 GSAT /  알고리즘 코딩 테스트 준비가 제일 중요해보임  ",
          
        "categories": ["Career"],
        "tags": ["Mentoring","Samsung SDS"],
        "url": "https://gitgitwi.github.io"/career/SDS_Mentoring/"",
        "teaser": null
      },
    
      
      {
        "title": "1강 - 알고리즘 문제해결",
        "excerpt":
          
            "1강 - 알고리즘 문제해결 (problem solving)   ClassName: 기초 알고리즘과 파이썬 코딩  Created: Mar 02, 2020 10:42 PM  제공처: Tacademy   https://www.youtube.com/playlist?list=PL9mhQYIlKEhfg0aLdaO04wYUovLMXY4DU   알고리즘 문제해결 problem solving이란 무엇??   프로그래밍 언어를 통해 시간제한, 메모리 제한에서 주어진 문제 해결   problem solving을 하는 이유      구현 능력 - 본인이 생각하고 있는 내용을 코드로 옮길 수 있는가? 연습을 많이 할수록 늘 수 있다   효율성 - 자주 사용하는 함수의 최적화, 효율적 코드 작성, 시간복잡도와 공간복잡도 계산 연습   절차적 사고 - 전체적인 workflow 설계능력, 자료구조와 알고리즘 학습 필요   디버깅 - 틀린 부분 발견, 예외 케이스 탐색, 에러메시지를 읽는 능력   재미 - 적은 시간으로 연습 가능, 프로젝트와 다르게 짧은 주기로 성취감, 100문제 이상 문제를 풀다보면 풀 수 있는 문제의 수가 기하급수적으로 늘어난다  ",
          
        "categories": ["fundamentals","algorithms"],
        "tags": ["algorithms","LectureNotes","SKTacademy"],
        "url": "https://gitgitwi.github.io"/fundamentals/algorithms/algo1/"",
        "teaser": null
      },
    
      
      {
        "title": "2강 - 알고리즘보다 코딩 I -읽기와 분석 (시간복잡도/공간복잡도 등)",
        "excerpt":
          
            "2강 - 알고리즘보다 코딩 I -읽기와 분석 (시간복잡도/공간복잡도 등)   ClassName: 기초 알고리즘과 파이썬 코딩  Created: Mar 02, 2020 10:56 PM  제공처: Tacademy   파인만 알고리즘 - 가장 유명한 알고리즘   알고리즘 풀이 순서 1 = Read and Analysis   : 어떤 부분에 초첨을 두고, 표현을 할 건지      시간 제한과 메모리 제한 체크            시간복잡도 - 연산을 많이 하는 코드가 시간이 오래 걸림 - 연산은 입력량과 관련! » 입력을 보고 시간을 대충 계산할 수 있어야                           연산과 * 연산 속도는 큰 차이, 모든 연산이 아닌 break 문 등 확인, 최악의 경우-최선의 경우 확인, 서버 속도와 컴퓨터 속도의 차                       그래서 Big-O Notation 점근적 표기법 사용                        이 점근적 표현법은 시간-공간 차원에서 각각 다룰 수 있음,       파이썬 기준 1초에 100만 번 이상의 연산은 불안정할 수 있음       따라서 시간제한 1초, 입력값 10억인 경우 단순 반복문으로는 풀 수 없음           일단은 생각나는대로 표현   중간 과정에 반드시 필요한 로직 생각   예제 입력과 예제 출력 매칭   본격적인 풀이 팁      입력과 초기화 팁            Map과 Comprehension                    대표적인 입력                             수                    num = int ( input () )                              문자열                    string = input ()  char_list = list( input() )                              배열                    lst = list( map( int, input().split() ) )                                  map(x,y)는 x 함수를 y 원소에 모두 적용한 map 객체 반환       char_list 내용을 문자열로 만들고 싶다면 join method       list의 초기화는 comprehension으로            1st_1d = [ 0 for _ in range(N) ]  1st_2d = [ [ 0 for _ in range(N) ] for j in range(N) ]           에러 메시지 이해하기            맞았습니다 / AC : 모든 test case를 시간제한-메모리제한에 맞춰 통과       틀렸습니다 / WA : 특정 test case에 대해 정답이 틀리거나 컴파일 에러       컴파일 에러 CE : 보통 틀린 문법에 의해 생김; 오타       런타임 에러 RE : 돌아가는 과정 상 에러; 0으로 나눗셈, 잘못된 메모리 참조 등, 주로 배열 길이 잘못 했을 때       메모리 초과 MLE : 효율적인 메모리 관리 필요       시간 초과 TLE : 더 좋은 알고리즘 또는 최적화 필요       출력 에러 : 없는 경우도 존재, 디버깅 과정 코드 확인 필요           추상화와 기능 분리 : 함수            test case 많은 문제, 기능 분리되는 문제 등 문제들은 적절하게 함수로 분할하여 가독성 높이고 main method 를 가볍게       main method 는 psudo-code느낌으로 가볍게 짜고, 각각에 대해 함수로 처리           가독성 : indent를 줄이자            조건문, 반복문, 함수 모두 줄일 부분 존재       다중 반복문 사용시, 수학적 방법을 이용해 가볍게 변경       안되는 경우 continue를 통해 배제하여 반복문 내부 indent 줄이기            for i in range(N):  \tif state :   \t\tprocess()   #위에 것 대신에 아래것   for i in range(N) :   \tif not state : continue  \tprocess()           불필요한 else 제거        def function(x) :   \tif x :  \t\treturn True  \telse :   \t\treturn False   # if x 를 충족하여 return 하면 아래 else 필요 없으므로   def function(x) :  \tif x : return True  \treturn False   # 또는 if else 3항 연산자 활용   def function(x) :   \treturn True if x else False           명명법 통일            snake       camel       pascal : camel 과 같지만 첫글자도 대문자          ",
          
        "categories": ["fundamentals","algorithms"],
        "tags": ["algorithms","LectureNotes","SKTacademy"],
        "url": "https://gitgitwi.github.io"/fundamentals/algorithms/algo2/"",
        "teaser": null
      },
    
      
      {
        "title": "3강 - 알고리즘보다 코딩 II - 수학 (진수와진법/최대공약수/최소공배수/소인수분해, 재귀함수)",
        "excerpt":
          
            "3강 - 알고리즘보다 코딩 II - 수학 (진수와진법/최대공약수/최소공배수/소인수분해, 재귀함수)   ClassName: 기초 알고리즘과 파이썬 코딩  Created: Mar 03, 2020 2:40 PM  제공처: Tacademy   수학   포함-배제 등 중고등 수학 응용           진수와 진법 : 2진수, 10진수, N진수       숫자로 구성된 문자열을 N진법에 맞게 변환하기?       이론적인 방법 ; 각자리수 *  N의 거듭제곱 합 - 거듭제곱 때문에 연산량이 많아짐        def stoi (s, n) :  \tret = 0  \tl = len(s)  \tfor i in range (l) : ret += int(s[i]) * n ** (l-i-1)  \treturn ret                 보다 간편한 방법        def stoi (s, n) :  \tret = 0  \tfor i in s : ret = ret*n + int (i)  \treturn ret                      거듭 제곱 연산       거듭제곱을 하게 되면 시간복잡도 급증 - 시간초과       그래서 이진수를 활용! - 거듭제곱은 거듭제곱 간의 곱으로 표현 가능            최대공약수 GCD &amp; 최소공배수 LCM             최대공약수 GCD를 구하면 최소공배수 LCM은 0(1)에 구할 수 있다       GCD 구하는 2가지 방법 - 둘 다 정식 풀이법은 아님        # 1부터 체크  def gcd (a, b) :  \tret = 0  \tfor i in range (min (a, b)) :  \t\tif a % i == and b % i == 0: ret = i  \treturn ret           min (a, b) 부터 체크 - 시간복잡도가 min(a, b) 로 정해져 있어 조금더 빠름        def gcd (a, b) :  \tfor i in range( min (a, b), 0, -1 ) :  \t\tif a % i == 0 and b % i == 0 :  \t\t\treturn i           유클리드 호제법 - 그냥 외워서 사용하는 것을 추천              def gcd (a, b) :  \treturn b if a % b==0 else gcd(b, a % b)                소수와 소인수 분해       여러가지 소수 판별법과 소인수 분해   2부터 N-1까지 ; O(N)   def isPrime (N) : \tfor i in range (2, N) : \t\tif N % i == 0 : return False \treturn True   2부터 sqrt(N)까지 ; O(sqrt(N))   def isPrime (N) : \ti = 2 \twhile i * i &lt;= N : \t\tif N % i == 0 : return False \t\ti += 1 \treturn True   에라토스테네스의 체   1 제거 - 2를 제외한 2의 배수 제거 - 3을 제외한 3의 배수 제거 - 5를 제외한 5의 배수 제거..   몇 가지만 제거해도 상당수 숫자가 제거됨   N까지 소수를 구하기 위해서 sqrt(N)까지 소수를 이용하면 가능!   def era (N) : \tck, p = [False for _ in range(N+1)], [] \tfor i in range(2, N+1) : \t\tif ck[i] == True : continue \t\tp.append(i) \t\tfor j in range(i*i, N+1, i) : \t\t\tck[j] = True \treturn ck, p   분할 정복 Divide &amp; Conquer   문제 분해, 재귀함수 활용           하노이탑       간단한 정리              마지막 기둥이 움직이기 위해서는 나머지 모든 것이 한 곳에 있어야       그러면 N개 중 N-1개를 기둥 2에 보내는 것이 우선       N번째 기둥을 3번에 보내고       N-1개 기둥을 다시 기둥 3에 보낸다       기둥 1에서 기둥2로 보내는 과정과 기둥2에서 기둥3으로 보내는 과정은 같아                  def hanoi (st, ed, sz) :  \tif sz == 1 : return print(st, ed)  \thanoi (st, 6-st-ed, sz-1)  \tprint (st, ed)  \thanoi (6-st-ed, ed, sz-1)   n = int (input())  print(2**n-1)  hanoi(1, 3, n)           재귀 함수 설계 시 최소조건 - 탈출 조건을 분명하게   분할 정복에 사용하기 위해서 줄어든 문제 조건을 표현할 parameter  ",
          
        "categories": ["fundamentals","algorithms"],
        "tags": ["algorithms","LectureNotes","SKTacademy"],
        "url": "https://gitgitwi.github.io"/fundamentals/algorithms/algo3/"",
        "teaser": null
      },
    
      
      {
        "title": "4강 - 자료구조와 알고리즘 I - sort (select/bubble/quick/merge/radix)",
        "excerpt":
          
            "4강 - 자료구조와 알고리즘 I - sort (select/bubble/quick/merge/radix)   ClassName: 기초 알고리즘과 파이썬 코딩  Created: Mar 03, 2020 3:33 PM  제공처: Tacademy   파이썬에서는 sort / sorted 함수를 통해 간단하게 정렬 가능   다만 정렬하는 원리에 대해서는 반드시 알아야 함   selection sort   O ( N^2 )   bubble sort   O ( N^2 )   quick sort   기준이 되는 숫자 기준으로 작은 수와 큰 수를 각각 왼쪽 - 오른쪽으로 보냄   분류된 숫자열 안에서도 동일한 분류 계속   이론상 O( NlogN ) 그러나 최악의 경우 O ( N^2 ) ; unstable한 sort   merge sort   전체 수열을 절반씩 계속 분할하여 2개씩 비교하여 정렬, 다시 합치면서 ‘2 pointer 정렬’   O ( NlogN ) ; stable 하지만 memory가 많이 필요해 질 수 있음   radix sort   메모리가 충분히 넉넉할 때 쓸 수 있는 sort   길이만큼 배열을 만들고 인덱스에 맞게 1씩 할당, 같은 수 중복일 경우 중복된 수만큼 할당   앞에서부터 꺼내오면서 정렬  ",
          
        "categories": ["fundamentals","algorithms"],
        "tags": ["algorithms","LectureNotes","SKTacademy"],
        "url": "https://gitgitwi.github.io"/fundamentals/algorithms/algo4/"",
        "teaser": null
      },
    
      
      {
        "title": "5강 - 자료구조와 알고리즘 II - Stack/Queue/Deque",
        "excerpt":
          
            "5강 - 자료구조와 알고리즘 II - stack/queue/deque   ClassName: 기초 알고리즘과 파이썬 코딩  Created: Mar 03, 2020 3:54 PM  제공처: Tacademy   자료구조 : 자료를 저장하는 방법론, 규칙      효율성 : 대부분의 자료구조마다 특화된 용도가 있음   추상화 : 언어에 국한되지 않고 쓸 수 있는 것   재사용성 : 라이브러리 제공 ; python에서는 Collection   STACK : FILO ; First In Last Out   python에 특별한 라이브러리 없고, 배열 통해 사용   알고리즘 퀴즈에서 나올수 있는 유형은 한정되어 있다 ; 대표적으로 괄호 문제만 잘 해결하면 나머지는 유사하게 풀이 가능   풀이 :      비어있는 지 체크   남아 있는 자료의 개수   QUEUE : FIFO; First In First Out   풀이 : stack과 유사      비어있는 지 체크   남아있는 자료 개수   Stack 과 Queue를 사용하는 이유 : 필요없는 데이터의 메모리 확보   DEQUE : stack + queue   양방향으로 출입 가능; stack은 한쪽으로만 출입 - queue는 한쪽은 입 한쪽은 출   요세푸스 문제  ",
          
        "categories": ["fundamentals","algorithms"],
        "tags": ["algorithms","LectureNotes","SKTacademy"],
        "url": "https://gitgitwi.github.io"/fundamentals/algorithms/algo5/"",
        "teaser": null
      },
    
      
      {
        "title": "6강 - 자료구조와 알고리즘 III - graph/tree/heap/BST",
        "excerpt":
          
            "6강 - 자료구조와 알고리즘 III - graph/tree/heap/BST   ClassName: 기초 알고리즘과 파이썬 코딩  Created: Mar 03, 2020 4:17 PM  제공처: Tacademy   Graph           노드 Node와 간선 Edge로 구성            들어오는 간선 수 indegree            나가는 간선 수 outdegree            저장방법 : 인접 행렬            방향성, 가중치 추가             다만 행렬에 0이 많은 그래프, sparse한 그래프라면 인접리스트 사용           Tree           특수한 구조를 가진 그래프            Node, Edge로 구성 - 모든 Node 가 연결            상위-하위 관계를 나눌 수 있음            Cycle이 없음            구조에 대한 명칭              Parent - Child       Ancestor - Descendant       Root - Leaf ; root는 항상 하나                Tree - subtree            트리의 높이            저장방식이 자유로움              부모만 저장 : O(N) 1차원 배열방식, 부모가 없으면 root node       자식들 저장 :  인접리스트 방식, 자식이 없으면 leaf node, 순환하기 좋음           Binary Tree   부모 노트가 X 이면, 왼쪽 노트가 2X, 오른쪽 노드가 2X+1      Heap : 우선순위가 가장 높은 값을 root노드로,   BST; Binary Search Tree : 입력되는 대로 첫숫자보다 크면 오른쪽 작으면 왼쪽 - set 계열 데이터 구조에서 사용  ",
          
        "categories": ["fundamentals","algorithms"],
        "tags": ["algorithms","LectureNotes","SKTacademy"],
        "url": "https://gitgitwi.github.io"/fundamentals/algorithms/algo6/"",
        "teaser": null
      },
    
      
      {
        "title": "7강 - 자료구조와 알고리즘 IV - DFS/BFS",
        "excerpt":
          
            "7강 - 자료구조와 알고리즘 IV - DFS/BFS   ClassName: 기초 알고리즘과 파이썬 코딩  Created: Mar 03, 2020 4:46 PM  제공처: Tacademy   DFS Depth First Search ; 깊이 우선 탐색   전수조사에서 주로 사용, Stack 방식과 유사, 컴퓨터 메모리 관리가 대부분 stack 방식   BFS Breadth First Search ; 너비 우선 탐색   Queue 방식과 유사   ✻ 알고리즘 대회 및 코딩 테스트를 준비하는 방법      많이 풀기 : 최소 200문제 이상, 1000개 이상 풀다보면 삼성/카카오 등 국내 코테는 왠만하면 패스 가능할 정도   암기하기 : 일부 문제들은 그냥 전형적인 유형 반복되기도, 종만북 등 기본 서적 내용은 반드시 숙지   주기적으로 체크하기  ",
          
        "categories": ["fundamentals","algorithms"],
        "tags": ["algorithms","LectureNotes","SKTacademy"],
        "url": "https://gitgitwi.github.io"/fundamentals/algorithms/algo7/"",
        "teaser": null
      },
    
      
      {
        "title": "[Programmers/Hash] 완주하지 못한 선수",
        "excerpt":
          
            "Created: Mar 04, 2020 2:19 PM  Status: Solved  language: Python  level: Basic  출처: Programmers  코딩테스트 연습 - 완주하지 못한 선수 | 프로그래머스     Tries   완주 못한 선수 찾다가 내가 완주 못할 듯..ㅋㅋ   1st solution : 기본 test case 는 통과하는데, 채점을 하면 RE + 시간초과..   def solution(participant, completion):     for i in completion :         for j in participant :             if i == j :                 participant.remove(j)      return participant[0]      test case의 간단한 예 말고 대량 data나 중복이 다수인 data가 들어오면 잘 안먹히는 게 아닐까 싶다.   def solution(participant, completion):     for i in participant :         for j in completion :             if i == j :                 participant.remove(i)      return participant[0]      단순하게 for문의 바깥 배열과 안쪽 배열을 바꾸면 그냥 틀려버린다.   for j in range(len(completion)) :   for i in range(len(participant)) :     if participant[i] == completion[j] :        print(\"parti : \", participant[i], \" compl : \", completion[j])       del participant[i]      index로 처리해서 중간에 요소 제거를 하게되면, index가 망가져서 계속 range 에러가 나는 듯   index로 접근하려면 아예 다른 방법을 찾아야 할 것 같다   2nd Solution   def solution(participant, completion):     temp = participant[:]      for j in completion :         temp.remove(j)      return temp[0]      remove를 통해 그냥 없애버리기   정확성은 맞았는데 효율성이 문제..   def solution(participant, completion):          for j in completion :         participant.remove(j)      return participant[0]      temp를 생성하지 않고 바로 participant 배열에서 지웠는데   시간이 아주 조금 더 줄기는 했지만 효율성은 계속 실패   여기서 뭘 더 줄여야하는거지..ㅋㅋ   def solution(participant, completion):          participant.sort()     completion.sort()          for j in completion :         participant.remove(j)      return participant[0]      sort를 하고 비교하니 시간이 조금 더 줄어들긴 했다        Solution   두 배열 sort한 후 처음부터 비교하고, 중간에 답나오면 바로 break하여 시간 단축   배열의 data 양이 적을 때는 조금 더 오래 걸리지만, 양이 아주 많을 때는 시간이 단축되는 듯하다   def solution(participant, completion):          participant.sort()     completion.sort()     a = \"\"          for i in range(len(completion)):         a = participant[len(participant)-1]         if participant[i] != completion[i] :             a = participant[i]             break     return a      Other Solutions   Hash 활용   원래 hash로 분류된 문제라 이렇게 하는게 정석이 아니었을까 싶음..   아직 Hash를 잘 모르기 때문에..ㅎㅎ   def solution(participant, completion):     answer = ''     temp = 0     dic = {}     for part in participant:         dic[hash(part)] = part         temp += int(hash(part))     for com in completion:         temp -= hash(com)     answer = dic[temp]      return answer   Collection의 Counter 객체 활용   이것도 collection-counter 다 아직 안배운 내용들이라..   이번 기회에 배워놔야겠다   import collections  def solution(participant, completion):     answer = collections.Counter(participant) - collections.Counter(completion)     return list(answer.keys())[0]  ",
          
        "categories": ["fundamentals","algorithms"],
        "tags": ["algorithms","Programmers","Python"],
        "url": "https://gitgitwi.github.io"/fundamentals/algorithms/01-programmers-hash-42576/"",
        "teaser": null
      },
    
      
      {
        "title": "[Programmers/BF] 모의고사",
        "excerpt":
          
            " Created: Mar 04, 2020 9:33 PM  Status: Solved  language: Python  level: Basic  출처: Programmers     Tries   def solution(answers):     person1 = [1, 2, 3, 4, 5]     person2 = [2, 1, 2, 3, 2, 4, 2, 5]     person3 = [3, 3, 1, 1, 2, 2, 4, 4, 5, 5]      c1, c2, c3 = 0, 0, 0     a1, a2, a3 = 1, 2, 3      for i in range(len(answers)) :         if answers[i] == person1[i%5] : c1 += 1         if answers[i] == person2[i%8] : c2 += 1         if answers[i] == person3[i%10] : c3 += 1      temp = [c1, c2, c3]     temp.sort()      temp[temp.index(c1)] = 1     temp[temp.index(c2)] = 2     temp[temp.index(c3)] = 3      answer = [temp[2]]      if (temp[1] == temp[2]) and (temp[0] &lt; temp[1]) :         answer.append(temp[1])         answer.sort()     if (c1==c2==c3) :          answer = [1,2,3]      return answer      정답 개수 산출은 금방인데 이거를 다시 사람 번호로 바꾸는게 어려운 듯..   저기에서 먼저 c1-c2-c3를 비교하고 key에 해당하는 a1 - a2- a3를 집어넣어야 했는데,   순서가 잘못되었다..   def solution(answers):     person1 = [1, 2, 3, 4, 5]     person2 = [2, 1, 2, 3, 2, 4, 2, 5]     person3 = [3, 3, 1, 1, 2, 2, 4, 4, 5, 5]      temp = [0, 0, 0]      for i in range(len(answers)) :         if answers[i] == person1[i%5] : temp[0] += 1         if answers[i] == person2[i%8] : temp[1] += 1         if answers[i] == person3[i%10] : temp[2] += 1      answer = []     answer.append(temp.index(temp[0])+1)          if (temp[0] == temp[1]) and (temp[1] &lt; temp[0]) :         answer.append(temp.index(temp[1])+1)     if (temp[0] == temp[1] == temp[2]) :          answer = [1,2,3]      answer.sort(reverse=False)          return answer      temp list의 index를 가지고 접근..나름 좀더 깔끔한 방법이라 생각했는데 더 틀리네..???   아 temp list는 정렬이 된 상태가 아니기 때문에 이전처럼 비교를 하면 안된다는 거를 놓쳤다   def solution(answers):     person1 = [1, 2, 3, 4, 5]     person2 = [2, 1, 2, 3, 2, 4, 2, 5]     person3 = [3, 3, 1, 1, 2, 2, 4, 4, 5, 5]      temp = [0, 0, 0]      for i in range(len(answers)) :         if answers[i] == person1[i%5] : temp[0] += 1         if answers[i] == person2[i%8] : temp[1] += 1         if answers[i] == person3[i%10] : temp[2] += 1      temp2 = sorted(temp)     temp2.reverse()          answer = []     answer.append(temp.index(temp2[0])+1)          if (temp2[0] == temp2[1]) and (temp2[1] &gt; temp2[2]) :         answer.append(temp.index(temp[1])+1)     if (temp[0] == temp[1] == temp[2]) :          answer = [1,2,3]      answer.sort(reverse=False)          return answer      다시 첫번째 풀이 때와 동일한 점수..   뭔가 놓친 조건이 있는건가..   test case로 [5, 4, 3, 2, 1, 5, 4, 3, 2, 1] 을 넣어 보니 왜 틀렸는지 알 수 있었다   answers = [5, 4, 3, 2, 1, 5, 4, 3, 2, 1]  person1 = [1, 2, 3, 4, 5] person2 = [2, 1, 2, 3, 2, 4, 2, 5] person3 = [3, 3, 1, 1, 2, 2, 4, 4, 5, 5]  temp = [0, 0, 0]  for i in range(len(answers)) : \tif answers[i] == person1[i%5] : temp[0] += 1 \tif answers[i] == person2[i%8] : temp[1] += 1 \tif answers[i] == person3[i%10] : temp[2] += 1  print(\"temp : \", temp)  temp2 = sorted(temp) temp2.reverse() print(\"temp2 : \", temp2)  answer = [] answer.append(temp.index(temp2[0])+1)  if (temp2[0] == temp2[1]) and (temp2[1] &gt; temp2[2]) : \tanswer.append(temp.index(temp2[1])+1) \tanswer.sort(reverse=False) if (temp[0] == temp[1] == temp[2]) :  \tanswer = [1,2,3]  print(\"answer : \", answer)  &gt;&gt;&gt;  temp :  [2, 2, 1] temp2 :  [2, 2, 1] answer :  [1, 1]   temp.index(temp2[1]+1)처럼 단순히 index를 호출하게 되면   앞에서부터 차례로 해당 value를 갖는 index를 찾기 때문에,   중복값에 대해 동일한 index를 계속 호출하게 되는 것..        Solution   def solution(answers):     person1 = [1, 2, 3, 4, 5]     person2 = [2, 1, 2, 3, 2, 4, 2, 5]     person3 = [3, 3, 1, 1, 2, 2, 4, 4, 5, 5]      temp = [0, 0, 0]      for i in range(len(answers)) :         if answers[i] == person1[i%5] : temp[0] += 1         if answers[i] == person2[i%8] : temp[1] += 1         if answers[i] == person3[i%10] : temp[2] += 1      temp2 = sorted(temp)     temp2.reverse()          answer = []          if temp2[0] &gt; temp2[1] :         answer.append(temp.index(temp2[0])+1)         return answer          if (temp2[0] == temp2[1]) and (temp2[1] &gt; temp2[2]) :         for i in range(len(temp)) :             if temp[i] == temp2[0] :                 answer.append(i+1)         answer.sort(reverse=False)         return answer          if (temp2[0] == temp2[1] == temp2[2]) :          answer = [1,2,3]         return answer      indent가 무려 4번이나 들어가는 아주 지저분한 if 문을 통해서 해결..   max() 함수를 알았다면 이 방법으로도 훨씬 깔끔하게 해결할 수 있었을 거 같다        Other Solutions   enumerate 를 활용한 풀이들   아직 모르는 게 너무 많네..   def solution(answers):     pattern1 = [1,2,3,4,5]     pattern2 = [2,1,2,3,2,4,2,5]     pattern3 = [3,3,1,1,2,2,4,4,5,5]     score = [0, 0, 0]     result = []      for idx, answer in enumerate(answers):         if answer == pattern1[idx%len(pattern1)]:             score[0] += 1         if answer == pattern2[idx%len(pattern2)]:             score[1] += 1         if answer == pattern3[idx%len(pattern3)]:             score[2] += 1      for idx, s in enumerate(score):         if s == max(score):             result.append(idx+1)      return result   def solution(answers):     p = [[1, 2, 3, 4, 5],          [2, 1, 2, 3, 2, 4, 2, 5],          [3, 3, 1, 1, 2, 2, 4, 4, 5, 5]]     s = [0] * len(p)      for q, a in enumerate(answers):         for i, v in enumerate(p):             if a == v[q % len(v)]:                 s[i] += 1     return [i + 1 for i, v in enumerate(s) if v == max(s)]  ",
          
        "categories": ["fundamentals","algorithms"],
        "tags": ["algorithms","Programmers","Python"],
        "url": "https://gitgitwi.github.io"/fundamentals/algorithms/02-programmers-bruteforce/"",
        "teaser": null
      },
    
      
      {
        "title": "Lecture 0401 analyze KOWEPS data using ggplot",
        "excerpt":
          
            "한국 복지패널데이터 분석      경제활동, 생활실태, 복지욕구 등 수천 개 변수 정보로 구성   foreign : 통계 파일 SPSS 로드할 수 있는 package   # install.packages(\"foreign\") library(foreign) library(dplyr)   ## ## Attaching package: 'dplyr'  ## The following objects are masked from 'package:stats': ## ##     filter, lag  ## The following objects are masked from 'package:base': ## ##     intersect, setdiff, setequal, union   library(ggplot2) library(readxl) library(extrafont)   ## Registering fonts with R   # font_import() # font_import(pattern = \"Nanum\") theme_update(text=element_text(family=\"NanumBarunGothic\"))   rawdata &lt;-  read.spss('~/Desktop/johnwi_KNOU/Programming/1. R/handouts/0401/Data/Koweps_hpc10_2015_beta1.sav', to.data.frame = T)   ## Warning in read.spss(\"~/Desktop/johnwi_KNOU/Programming/1. R/handouts/0401/Data/ ## Koweps_hpc10_2015_beta1.sav\", : ~/Desktop/johnwi_KNOU/Programming/1. R/handouts/ ## 0401/Data/Koweps_hpc10_2015_beta1.sav: Compression bias (0) is not the usual ## value of 100   복사본 만들어 원본 보호   data &lt;- rawdata   데이터 검토   dim(data)   ## [1] 16664   957   str(data)   ## 'data.frame':    16664 obs. of  957 variables: ##  $ h10_id          : num  1 2 3 4 4 6 6 6 6 6 ... ##  $ h10_ind         : num  1 1 1 1 1 1 1 1 1 1 ... ##  $ h10_sn          : num  1 1 1 1 1 1 1 1 1 1 ... ##  $ h10_merkey      : num  10101 20101 30101 40101 40101 ... ##  $ h_new           : num  0 0 0 0 0 0 0 0 0 0 ... ##  $ h10_cobf        : num  NA NA NA NA NA NA NA NA NA NA ... ##  $ h10_reg5        : num  1 1 1 1 1 1 1 1 1 1 ... ##  $ h10_reg7        : num  1 1 1 1 1 1 1 1 1 1 ... ##  $ h10_din         : num  864 600 1571 3579 3579 ... ##  $ h10_cin         : num  864 600 1619 3687 3687 ... ##  $ h10_flag        : num  0 0 0 0 0 0 0 0 0 0 ... ##  $ p10_wgl         : num  777 960 1059 1012 1075 ... ##  $ p10_wsl         : num  0.257 0.317 0.35 0.334 0.355 ... ##  $ p10_wgc         : num  764 949 1048 992 1057 ... ##  $ p10_wsc         : num  0.252 0.314 0.346 0.328 0.349 ... ##  $ h10_hc          : num  2 2 1 1 1 1 1 1 1 1 ... ##  $ nh1001_1        : num  NA NA NA NA NA NA NA NA NA NA ... ##  $ nh1001_2        : num  NA NA NA NA NA NA NA NA NA NA ... ##  $ h1001_1         : num  1 1 1 2 2 5 5 5 5 5 ... ##  $ h10_pind        : num  1 1 1 1 4 1 1 1 1 1 ... ##  $ h10_pid         : num  101 201 301 401 402 601 602 603 604 605 ... ##  $ h10_g1          : num  1 1 1 1 2 1 2 3 4 5 ... ##  $ h10_g2          : num  10 10 10 10 2 10 20 11 1 2 ... ##  $ h10_g3          : num  2 2 1 1 2 1 2 2 1 2 ... ##  $ h10_g4          : num  1936 1945 1948 1942 1923 ... ##  $ h10_g6          : num  2 4 3 7 2 6 5 3 4 4 ... ##  $ h10_g7          : num  0 5 5 3 0 5 5 1 5 5 ... ##  $ h10_g8          : num  0 0 0 0 0 0 0 0 0 0 ... ##  $ h10_g9          : num  0 0 0 0 0 0 0 0 0 0 ... ##  $ h10_g10         : num  2 2 2 3 2 1 1 0 1 1 ... ##  $ h10_g11         : num  2 2 2 1 1 1 1 1 1 1 ... ##  $ h10_g12         : num  1 1 1 1 1 1 1 1 1 1 ... ##  $ h1001_110       : num  1 1 1 5 5 5 5 5 5 5 ... ##  $ h1001_5aq1      : num  0 0 0 0 0 0 0 0 0 0 ... ##  $ h1001_5aq2      : num  0 0 0 0 0 0 0 0 0 0 ... ##  $ h1001_5aq3      : num  0 0 0 0 0 0 0 0 0 0 ... ##  $ h1001_5aq4      : num  0 0 0 0 0 0 0 0 0 0 ... ##  $ h10_med1        : num  1 1 1 1 2 1 2 3 4 5 ... ##  $ h10_med2        : num  3 4 3 3 4 3 5 2 3 3 ... ##  $ h10_med3        : num  60 28 12 3 6 5 0 3 0 14 ... ##  $ h10_med4        : num  0 0 0 0 0 0 5 0 0 0 ... ##  $ h10_med5        : num  0 0 0 0 0 0 23 0 0 0 ... ##  $ h10_med6        : num  0 0 0 0 0 0 1 0 0 0 ... ##  $ h10_med7        : num  3 2 2 1 1 2 1 2 0 2 ... ##  $ h10_med8        : num  0 1 0 1 1 1 1 0 0 1 ... ##  $ h10_g9_1        : num  3 3 3 3 3 3 3 0 0 3 ... ##  $ h10_med9        : num  8 5 7 3 15 23 1 0 0 6 ... ##  $ h10_med10       : num  0 0 0 0 0 1 1 1 0 0 ... ##  $ h10_eco1        : num  1 1 1 1 2 1 2 3 4 5 ... ##  $ h10_eco2        : num  2 3 1 1 3 1 1 0 3 3 ... ##  $ h10_eco3        : num  NA NA NA NA NA NA NA NA NA NA ... ##  $ h10_eco4        : num  9 9 2 2 9 6 9 NA 9 9 ... ##  $ h10_eco4_1      : num  NA NA NA NA NA NA NA NA NA NA ... ##  $ h10_eco5_1      : num  NA NA 1 1 NA NA NA NA NA NA ... ##  $ h10_eco6        : num  NA NA 2 2 NA NA NA NA NA NA ... ##  $ h10_eco_7_1     : num  NA NA 1 1 NA NA NA NA NA NA ... ##  $ h10_eco_7_2     : num  NA NA 2 2 NA NA NA NA NA NA ... ##  $ h10_eco_7_3     : num  NA NA 1 3 NA NA NA NA NA NA ... ##  $ h10_eco8        : num  NA NA 75 42 NA 46 NA NA NA NA ... ##  $ h10_eco9        : num  NA NA 942 762 NA 530 NA NA NA NA ... ##  $ h10_eco10       : num  NA NA 3 2 NA 1 NA NA NA NA ... ##  $ h10_eco11       : num  10 10 NA NA 10 NA 6 NA 10 10 ... ##  $ h10_soc1        : num  1 1 1 1 2 1 2 3 4 5 ... ##  $ h10_soc_2       : num  0 0 0 1 0 2 0 0 0 0 ... ##  $ h10_soc_3       : num  NA NA NA NA NA 1 NA NA NA NA ... ##  $ h10_soc_4       : num  NA NA NA NA NA 2 NA NA NA NA ... ##  $ h10_soc_5       : num  NA NA NA NA NA 1 NA NA NA NA ... ##  $ h10_soc_6       : num  NA NA NA NA NA NA NA NA NA NA ... ##  $ h10_soc_7       : num  NA NA NA NA NA NA NA NA NA NA ... ##  $ h10_soc_8       : num  NA NA NA NA NA NA NA NA NA NA ... ##  $ h10_soc_9       : num  NA NA NA NA NA 0 NA NA NA NA ... ##  $ h10_soc_10      : num  NA NA NA NA NA 0 NA NA NA NA ... ##  $ h10_soc_11      : num  NA NA NA NA NA NA NA NA NA NA ... ##  $ h10_soc8        : num  0 0 1 2 0 0 0 0 0 0 ... ##  $ h10_soc9        : num  0 0 1 2 0 0 0 0 0 0 ... ##  $ h10_soc11       : num  0 0 2 2 0 0 0 0 0 0 ... ##  $ h10_soc10       : num  0 0 2 2 0 0 0 0 0 0 ... ##  $ h10_soc_12      : num  4 4 4 4 4 4 4 4 4 4 ... ##  $ h10_soc_13      : num  4 4 1 3 4 3 4 4 4 4 ... ##  $ h1005_1         : num  1 1 1 1 1 1 1 1 1 1 ... ##  $ h1005_3aq1      : num  2 2 1 2 2 2 2 2 2 2 ... ##  $ h1005_2         : num  NA NA NA NA NA NA NA NA NA NA ... ##  $ h1005_3         : num  NA NA NA NA NA NA NA NA NA NA ... ##  $ h1005_4         : num  2 2 2 2 2 2 2 2 2 2 ... ##  $ h1005_5         : num  NA NA NA NA NA NA NA NA NA NA ... ##  $ h1005_6         : num  NA NA NA NA NA NA NA NA NA NA ... ##  $ h1005_7         : num  0 0 0 0 0 1 1 1 1 1 ... ##  $ nh1005_8        : num  4 3 3 3 3 3 3 3 3 3 ... ##  $ nh1005_9        : num  5 4 3 3 3 4 4 4 4 4 ... ##  $ h1005_3aq2      : num  0 0 0 0 0 11 11 11 11 11 ... ##  $ h1006_aq1       : num  2 2 2 2 2 2 2 2 2 2 ... ##  $ h1006_1         : num  2 2 2 1 1 2 2 2 2 2 ... ##  $ h1006_2         : num  3 3 1 3 3 3 3 3 3 3 ... ##  $ h1006_4         : num  2 3 1 3 3 3 3 3 3 3 ... ##  $ h1006_5         : num  33 198 23 73 73 82 82 82 82 82 ... ##  $ h1006_3         : num  2 1 3 1 1 1 1 1 1 1 ... ##  $ h1006_6         : num  5000 60000 200 20000 20000 50700 50700 50700 50700 50700 ... ##  $ h1006_8         : num  1 1 1 1 1 1 1 1 1 1 ... ##  $ h1006_9         : num  88 4 88 88 88 88 88 88 88 88 ... ##   [list output truncated] ##  - attr(*, \"variable.labels\")= Named chr  \"\\xb0\\xa1\\xb1\\xb8 \\xc6г\\xce ID(h10_id)\" \"\\xb0\\xa1\\xb1\\xb8\\xbb\\xfd\\xbc\\xba\\xc2\\xf7\\xbc\\xf6(h10_ind)\" \"\\xb0\\xa1\\xb1\\xb8\\xbaи\\xae\\xc0\\u03f7ù\\xf8ȣ(h10_sn)\" \"\\xc6гΰ\\xa3 \\xb0\\xa1\\xb1\\xb8\\xb8\\xd3\\xc1\\xf6 Ű\\xba\\xaf\\xbc\\xf6(h10_merkey)\" ... ##   ..- attr(*, \"names\")= chr  \"h10_id\" \"h10_ind\" \"h10_sn\" \"h10_merkey\" ...   table (is.na(data))   ## ##   FALSE    TRUE ## 6213913 9733535   head(data)   ##   h10_id h10_ind h10_sn h10_merkey h_new h10_cobf h10_reg5 h10_reg7 h10_din ## 1      1       1      1      10101     0       NA        1        1     864 ## 2      2       1      1      20101     0       NA        1        1     600 ## 3      3       1      1      30101     0       NA        1        1    1571 ## 4      4       1      1      40101     0       NA        1        1    3579 ## 5      4       1      1      40101     0       NA        1        1    3579 ## 6      6       1      1      60101     0       NA        1        1    3030 ##   h10_cin h10_flag   p10_wgl   p10_wsl   p10_wgc   p10_wsc h10_hc nh1001_1 ## 1     864        0  776.9947 0.2567795  763.7189 0.2523922      2       NA ## 2     600        0  959.6458 0.3171417  949.2291 0.3136992      2       NA ## 3    1619        0 1059.1559 0.3500276 1047.6591 0.3462281      1       NA ## 4    3687        0 1012.1599 0.3344964  991.5721 0.3276926      1       NA ## 5    3687        0 1075.4212 0.3554029 1057.0466 0.3493305      1       NA ## 6    3486        0 2243.9456 0.7415743 2211.1575 0.7307386      1       NA ##   nh1001_2 h1001_1 h10_pind h10_pid h10_g1 h10_g2 h10_g3 h10_g4 h10_g6 h10_g7 ## 1       NA       1        1     101      1     10      2   1936      2      0 ## 2       NA       1        1     201      1     10      2   1945      4      5 ## 3       NA       1        1     301      1     10      1   1948      3      5 ## 4       NA       2        1     401      1     10      1   1942      7      3 ## 5       NA       2        4     402      2      2      2   1923      2      0 ## 6       NA       5        1     601      1     10      1   1962      6      5 ##   h10_g8 h10_g9 h10_g10 h10_g11 h10_g12 h1001_110 h1001_5aq1 h1001_5aq2 ## 1      0      0       2       2       1         1          0          0 ## 2      0      0       2       2       1         1          0          0 ## 3      0      0       2       2       1         1          0          0 ## 4      0      0       3       1       1         5          0          0 ## 5      0      0       2       1       1         5          0          0 ## 6      0      0       1       1       1         5          0          0 ##   h1001_5aq3 h1001_5aq4 h10_med1 h10_med2 h10_med3 h10_med4 h10_med5 h10_med6 ## 1          0          0        1        3       60        0        0        0 ## 2          0          0        1        4       28        0        0        0 ## 3          0          0        1        3       12        0        0        0 ## 4          0          0        1        3        3        0        0        0 ## 5          0          0        2        4        6        0        0        0 ## 6          0          0        1        3        5        0        0        0 ##   h10_med7 h10_med8 h10_g9_1 h10_med9 h10_med10 h10_eco1 h10_eco2 h10_eco3 ## 1        3        0        3        8         0        1        2       NA ## 2        2        1        3        5         0        1        3       NA ## 3        2        0        3        7         0        1        1       NA ## 4        1        1        3        3         0        1        1       NA ## 5        1        1        3       15         0        2        3       NA ## 6        2        1        3       23         1        1        1       NA ##   h10_eco4 h10_eco4_1 h10_eco5_1 h10_eco6 h10_eco_7_1 h10_eco_7_2 h10_eco_7_3 ## 1        9         NA         NA       NA          NA          NA          NA ## 2        9         NA         NA       NA          NA          NA          NA ## 3        2         NA          1        2           1           2           1 ## 4        2         NA          1        2           1           2           3 ## 5        9         NA         NA       NA          NA          NA          NA ## 6        6         NA         NA       NA          NA          NA          NA ##   h10_eco8 h10_eco9 h10_eco10 h10_eco11 h10_soc1 h10_soc_2 h10_soc_3 h10_soc_4 ## 1       NA       NA        NA        10        1         0        NA        NA ## 2       NA       NA        NA        10        1         0        NA        NA ## 3       75      942         3        NA        1         0        NA        NA ## 4       42      762         2        NA        1         1        NA        NA ## 5       NA       NA        NA        10        2         0        NA        NA ## 6       46      530         1        NA        1         2         1         2 ##   h10_soc_5 h10_soc_6 h10_soc_7 h10_soc_8 h10_soc_9 h10_soc_10 h10_soc_11 ## 1        NA        NA        NA        NA        NA         NA         NA ## 2        NA        NA        NA        NA        NA         NA         NA ## 3        NA        NA        NA        NA        NA         NA         NA ## 4        NA        NA        NA        NA        NA         NA         NA ## 5        NA        NA        NA        NA        NA         NA         NA ## 6         1        NA        NA        NA         0          0         NA ##   h10_soc8 h10_soc9 h10_soc11 h10_soc10 h10_soc_12 h10_soc_13 h1005_1 ## 1        0        0         0         0          4          4       1 ## 2        0        0         0         0          4          4       1 ## 3        1        1         2         2          4          1       1 ## 4        2        2         2         2          4          3       1 ## 5        0        0         0         0          4          4       1 ## 6        0        0         0         0          4          3       1 ##   h1005_3aq1 h1005_2 h1005_3 h1005_4 h1005_5 h1005_6 h1005_7 nh1005_8 nh1005_9 ## 1          2      NA      NA       2      NA      NA       0        4        5 ## 2          2      NA      NA       2      NA      NA       0        3        4 ## 3          1      NA      NA       2      NA      NA       0        3        3 ## 4          2      NA      NA       2      NA      NA       0        3        3 ## 5          2      NA      NA       2      NA      NA       0        3        3 ## 6          2      NA      NA       2      NA      NA       1        3        4 ##   h1005_3aq2 h1006_aq1 h1006_1 h1006_2 h1006_4 h1006_5 h1006_3 h1006_6 h1006_8 ## 1          0         2       2       3       2      33       2    5000       1 ## 2          0         2       2       3       3     198       1   60000       1 ## 3          0         2       2       1       1      23       3     200       1 ## 4          0         2       1       3       3      73       1   20000       1 ## 5          0         2       1       3       3      73       1   20000       1 ## 6         11         2       2       3       3      82       1   50700       1 ##   h1006_9 h1006_aq2 h1006_aq3 h1006_10 h1006_11 h1006_12 h1006_13 h1006_14 ## 1      88         0         0        1        1        1        2        1 ## 2       4         0         0        1        1        1        2        1 ## 3      88         0         0        1        2        2        2        1 ## 4      88         0         0        1        1        1        2        1 ## 5      88         0         0        1        1        1        2        1 ## 6      88         0         0        1        2        2        2        1 ##   h1006_21 h1006_22 h1006_23 h1006_24 h1006_25 h1006_27 h1006_30 h1006_33 ## 1        1        1        1        1        5        2        2        2 ## 2        1        1        1        1        5        2        2        2 ## 3        1        1        1        1        5        2        2        2 ## 4        1        1        1        1        5        2        2        2 ## 5        1        1        1        1        5        2        2        2 ## 6        1        1        1        1        5        2        2        2 ##   h1006_36 h1006_39 h1006_3aq1 h1007_3aq1 h1007_3aq2 h1007_5aq1 h1007_3aq3 ## 1        2        2          2         23          3          0          0 ## 2        2        2          2         20          2          0          0 ## 3        2        2          2         20         10          0         20 ## 4        2        2          2         30         15          0          0 ## 5        2        2          2         30         15          0          0 ## 6        2        2          2         40          3          0          0 ##   h1007_3aq4 h1007_3aq5 h1007_6aq1 h1007_3aq6 h1007_5aq2 h1007_3aq7 h1007_3aq8 ## 1        0.0          8        5.0        3.0          0          4         16 ## 2        0.0          6        2.7        0.5          0          2          4 ## 3        0.0          6        3.0        1.0          0          2          3 ## 4        0.0         11        7.3        2.0          0          4         14 ## 5        0.0         11        7.3        2.0          0          4         14 ## 6        0.2         15        9.3        2.0          0          8         43 ##   h1007_3aq9 h1007_3aq10 h1007_3aq11 h1007_5aq3 h1007_5aq4 h1007_3aq13 ## 1          0           0           1          1          2          13 ## 2          0           0           1          2          3           7 ## 3          0           0           1          3          3          14 ## 4          0           0           2          3         11          36 ## 5          0           0           2          3         11          36 ## 6          2          10           2         25         12          68 ##   h1007_6aq4 h1007_6aq6 h1007_3aq14 h1007_3aq15 h1007_3aq16 h1007_3aq17 h1007_4 ## 1        0.0        0.0           0           0           0           0       0 ## 2        1.7        0.0           0           0           0           0       0 ## 3        1.7        0.0           0           0           0           0       0 ## 4       25.0        2.5           0           0           0           0       1 ## 5       25.0        2.5           0           0           0           0       1 ## 6        2.5       10.0           0           0           0           0       6 ##   h1007_6aq7 h1007_6aq8 h1007_6aq9 h1007_6aq10 h1007_6aq11 h1007_5 h1007_6aq12 ## 1          0        0.0        0.0           0           0       0           0 ## 2          0        0.0        0.0           0           0       0           0 ## 3          0        0.0        0.0           0           0       4           0 ## 4          0        1.0        0.0           0           0       8           0 ## 5          0        1.0        0.0           0           0       8           0 ## 6          0        4.1        1.8           0           0      32          15 ##   h1007_6aq13 h1007_6aq14 h1007_9 h1009_9 h1009_6aq4 h10_inc1 h10_inc2_1 ## 1         0.0         0.0      74      50        100        1          0 ## 2         0.0         0.0      48      48         70        1          0 ## 3         3.6         0.7      87      87        100        1          0 ## 4         8.0         0.0     137     150        200        1          0 ## 5         8.0         0.0     137     150        200        2          0 ## 6        17.0         0.0     268     200        300        1          0 ##   h10_inc2_2 h10_inc3_1 h10_inc3_2 h10_inc4_1 h10_inc4_2 h10_inc5_1 h10_inc5_2 ## 1         NA          0         NA          0         NA          0         NA ## 2         NA          0         NA          0         NA          0         NA ## 3         NA          1         12          0         NA          0         NA ## 4         NA          1         12          0         NA          0         NA ## 5         NA          0         NA          0         NA          0         NA ## 6         NA          0         NA          1         12          0         NA ##   h10_inc6_1 h10_inc6_2 h10_inc7_1 h10_inc7_2 h1008_106 h1008_107 h1008_108 ## 1          0         NA          1         12         0         0         0 ## 2          0         NA          1         12         0         0         0 ## 3          0         NA          0         NA         0         1         0 ## 4          0         NA          0         NA         0         1         0 ## 5          0         NA          1         12         0         1         0 ## 6          0         NA          0         NA         0         0         1 ##   h1008_109 h1008_110 h1008_111 h10_inc2_3 h10_inc2 h10_inc3_6 h10_inc3 ## 1         0         0         1          1       NA          1       NA ## 2         0         0         1          1       NA          1       NA ## 3         0         0         0          1       NA          1     1440 ## 4         0         0         1          1       NA          1     2400 ## 5         0         0         1          2       NA          2       NA ## 6         0         0         3          1       NA          1       NA ##   h10_inc4_7 h10_inc4 h10_inc4_8 h10_inc4_9 h1008_155 h1008_156 h1008_157 ## 1          1       NA          1         NA        NA        NA        NA ## 2          1       NA          1         NA        NA        NA        NA ## 3          1       NA          1         NA        NA        NA        NA ## 4          1       NA          1         NA        NA        NA        NA ## 5          2       NA          2         NA        NA        NA        NA ## 6          1     3000          1       3000        NA        NA        NA ##   h1008_158 h1008_160 h1008_159 h1008_3aq3 h1008_161 h1008_162 h1008_163 ## 1        NA        NA        NA         NA        NA        NA        NA ## 2        NA        NA        NA         NA        NA        NA        NA ## 3        NA        NA        NA         NA        NA        NA        NA ## 4        NA        NA        NA         NA        NA        NA        NA ## 5        NA        NA        NA         NA        NA        NA        NA ## 6        NA        NA        NA         NA        NA        NA        NA ##   h1008_164 h1008_166 h1008_165 h1008_3aq4 h1008_167 h1008_168 h1008_169 ## 1        NA        NA        NA         NA        NA        NA        NA ## 2        NA        NA        NA         NA        NA        NA        NA ## 3        NA        NA        NA         NA        NA        NA        NA ## 4        NA        NA        NA         NA        NA        NA        NA ## 5        NA        NA        NA         NA        NA        NA        NA ## 6        NA        NA        NA         NA        NA        NA        NA ##   h1008_170 h10_inc7_3 h10_inc7 h1008_aq9 h1008_aq10 h1008_aq11 h1008_aq12 ## 1        NA          1        0         0          0          0          0 ## 2        NA          1        0         0          0          0          0 ## 3        NA          1        0         0          0          0          0 ## 4        NA          1        0         0          0          0        508 ## 5        NA          2        0         0          0          0        508 ## 6        NA          1        0         0          0          0          0 ##   h1008_aq13 h1008_aq14 h1008_aq15 h1008_6aq1 h1008_aq16 h1008_aq17 h1008_10aq1 ## 1          0          0          0          0          0         59         120 ## 2          0          0          0          0          0          0           0 ## 3          0          0          0          0          0         59         120 ## 4          0          0          0          0          0         59         120 ## 5          0          0          0          0          0         59         120 ## 6          0          0          0          0          0         94         192 ##   h1008_aq19 h1008_aq20 h1008_aq21 h1008_5aq3 h1008_7aq1 h1008_aq22 h1008_7aq2 ## 1          0          0          0          0          0          0          0 ## 2          0          0          0          0          0          0          0 ## 3          0          0          0          0          0          0          0 ## 4          0          0          0          0          0          0          0 ## 5          0          0          0          0          0          0          0 ## 6          0          0          0          0          0          0          0 ##   h1008_aq23 h1008_aq24 h1008_4aq116 h1008_4aq117 h1008_5aq1 h1008_7aq4 ## 1          0          0            0            0          0          0 ## 2          0          0            0            0          0          0 ## 3          0          0            0            0          0          0 ## 4          0          0            0            0          0          0 ## 5          0          0            0            0          0          0 ## 6          0          0            0            0          0          0 ##   h1008_7aq5 h1008_7aq6 h1008_7aq7 h1008_7aq8 h1008_7aq9 h1008_aq25 h1008_7aq10 ## 1          0          0          0          0          0          0           0 ## 2          0          0          0          0          0          0           0 ## 3          0          0          0          0          0          0           0 ## 4          0          0          0          0          0          0           0 ## 5          0          0          0          0          0          0           0 ## 6          0          0          0          0          0          0           0 ##   h1008_aq26 h1008_aq27 h1008_aq28 h1008_aq29 h1008_3aq5 h1008_4aq118 ## 1          0          0          0          0          0            0 ## 2          0          0          0          0          0            0 ## 3          0          0          0          0          0            0 ## 4          0          0          0          0          0            0 ## 5          0          0          0          0          0            0 ## 6          0          0          0          0          0            0 ##   h1008_aq30 h1008_6aq3 h1008_3aq6 h1008_3aq7 nh1008_3aq1 h1008_aq32 h1008_aq33 ## 1          3          0          0        682          NA          0          0 ## 2          0          0          0        600          NA          0          0 ## 3          0          0          0          0          NA          0          0 ## 4          3          0          0          0          NA          0          0 ## 5          3          0          0          0          NA          0          0 ## 6          0          0          0          0          NA          0          0 ##   h1008_aq34 h1008_3aq8 h1008_195 h1008_7aq11 h1009_aq1 h1009_aq2 h1009_aq3 ## 1          3          0         0           0         0         0         0 ## 2          0          0         0           0      7000         0         0 ## 3          0          0         0           0         0         0         0 ## 4        600          0         0           0         0     20000         0 ## 5        600          0         0           0         0     20000         0 ## 6        200          0         0           0         0         0         0 ##   h1009_aq4 h1009_aq5 h1009_aq6 h1009_aq7 h1009_aq8 h1010_aq1 h1010_aq2 ## 1         0         0         0         0         0         0         0 ## 2     24000         0         0         0         0         0         0 ## 3         0         0         0         0         0         0         0 ## 4         0         0         0         0      1920         0         0 ## 5         0         0         0         0      1920         0         0 ## 6     11000         0         0         0         0         0         0 ##   h1010_aq3 h1010_aq4 h1010_aq5 h1010_aq6 h1010_aq7 h1010_aq8 h1010_aq9 ## 1         0         0         0       100         0         0         0 ## 2         0         0         0       200         0         0         0 ## 3         0         0         0       500         0         0         0 ## 4         0         0         0       100         0         0         0 ## 5         0         0         0       100         0         0         0 ## 6         0         0         0       500         0         0         0 ##   h1010_aq10 h1010_aq11 h1010_aq12 h1010_aq13 h1010_aq14 h1010_aq15 h1010_aq16 ## 1          0          0          0          0          0          0          0 ## 2          0          0          0          0          0          0          0 ## 3          0          0          0          0          0          0          0 ## 4          0          0          0          0          0          0          0 ## 5          0          0          0          0          0          0          0 ## 6          0          0          0          0          0          0          0 ##   h1010_aq17 h1010_aq18 h1010_aq19 h1010_aq20 h1010_26 h1010_27 h1010_aq23 ## 1          0          0          0          0        0        0          0 ## 2          0          0          0          0        0        0          0 ## 3          0          0          0          0        0        0          0 ## 4          0          0          0          0        0        0          0 ## 5          0          0          0          0        0        0          0 ## 6          0          0          0          0        1      500          0 ##   h1010_aq24 h1010_aq25 h1010_aq26 h1011_2 h1011_3 h1011_4 h1011_5 h1011_6 ## 1          0          0          0       2       2       2       3       2 ## 2          0          0          0       3       2       2       3       2 ## 3          0          0          0       2       2       2       3       2 ## 4          0          0          0       3       2       2       3       2 ## 5          0          0          0       3       2       2       3       2 ## 6        400          0          0       3       2       2       2       2 ##   h1011_7 h1011_8 h1011_3aq1 h1011_3aq2 h1011_3aq3 h1011_3aq4 h1011_3aq5 ## 1       2       2          2          3          3          2         NA ## 2       2       2          2          3          3          2         NA ## 3       2       2          2          3          3          2         NA ## 4       2       2          2          3          2          2         NA ## 5       2       2          2          3          2          2         NA ## 6       2       2          2          3          2          2         NA ##   h1011_3aq6 h1011_3aq7 h1012_1 nh1012_1 h1012_2 h1012_3 h1012_4 h1012_5 ## 1          2          2       2       NA      NA      NA      NA      NA ## 2          2          2       2       NA      NA      NA      NA      NA ## 3          2          2       2       NA      NA      NA      NA      NA ## 4          2          2       2       NA      NA      NA      NA      NA ## 5          2          2       2       NA      NA      NA      NA      NA ## 6          2          2       2       NA      NA      NA      NA      NA ##   h1012_6 h1012_7 nh1012_7 nh1012_8 h1012_9 h1012_10 h1012_11 h1012_12 h1012_13 ## 1      NA       1       NA       NA      NA       NA       NA       NA       NA ## 2      NA       1       NA       NA      NA       NA       NA       NA       NA ## 3      NA       1       NA       NA      NA       NA       NA       NA       NA ## 4      NA       1       NA       NA      NA       NA       NA       NA       NA ## 5      NA       1       NA       NA      NA       NA       NA       NA       NA ## 6      NA       1       NA       NA      NA       NA       NA       NA       NA ##   h1012_14 h1012_15 h1012_3aq1 h1012_16 h1012_17 h1012_18 h1012_19 h1012_1_4aq1 ## 1       NA       NA         NA       NA       NA       NA       NA            1 ## 2       NA       NA         NA       NA       NA       NA       NA            1 ## 3       NA       NA         NA       NA       NA       NA       NA            1 ## 4       NA       NA         NA       NA       NA       NA       NA            1 ## 5       NA       NA         NA       NA       NA       NA       NA            1 ## 6       NA       NA         NA       NA       NA       NA       NA            2 ##   h1012_1_5aq1 h1012_1_5aq2 h1012_1_5aq3 h1012_1_5aq4 h1012_1_5aq5 h1012_1_4aq2 ## 1            2           NA           NA           NA           NA            1 ## 2            2           NA           NA           NA           NA            1 ## 3            2           NA           NA           NA           NA            1 ## 4            2           NA           NA           NA           NA            2 ## 5            2           NA           NA           NA           NA            2 ## 6            2           NA           NA           NA           NA            1 ##   h1012_1_4aq3 h1013_2 h1013_6 h1013_10 h1013_14 h1013_18 h1013_22 h1013_26 ## 1            2       1       1        2        2        2        2        2 ## 2            2       2       2        2        2        2        2        2 ## 3            2       1       2        2        2        2        2        2 ## 4            2       1       2        2        2        2        2        2 ## 5            2       1       2        2        2        2        2        2 ## 6            2       1       2        2        2        2        2        2 ##   h1013_8aq1 h1013_5aq1 h1013_8aq2 h1013_4aq1 h1013_4aq2 h1013_4aq4 h1013_4aq6 ## 1          2          2          2          2         NA         NA         NA ## 2          2          2          2          2         NA         NA         NA ## 3          2          2          2          2         NA         NA         NA ## 4          2          2          2          2         NA         NA         NA ## 5          2          2          2          2         NA         NA         NA ## 6          2          2          2          2         NA         NA         NA ##   h1013_4aq8 h1013_4aq10 h1013_5aq4 h1013_5aq6 h1013_5aq8 h1013_6aq1 ## 1         NA          NA         NA         NA         NA         NA ## 2         NA          NA         NA         NA         NA         NA ## 3         NA          NA         NA         NA         NA         NA ## 4         NA          NA         NA         NA         NA         NA ## 5         NA          NA         NA         NA         NA         NA ## 6         NA          NA         NA         NA         NA         NA ##   h1013_4aq14 ## 1          NA ## 2          NA ## 3          NA ## 4          NA ## 5          NA ## 6          NA ##                                                                                                                                                                                                                                                       h1013_4aq15 ## 1 .                                                                                                                                                                                                                                                               ## 2 .                                                                                                                                                                                                                                                               ## 3 .                                                                                                                                                                                                                                                               ## 4 .                                                                                                                                                                                                                                                               ## 5 .                                                                                                                                                                                                                                                               ## 6 .                                                                                                                                                                                                                                                               ##   h1013_4aq16 h1013_4aq17 h1013_4aq18 h1013_4aq20 h1013_4aq22 h1013_4aq24 ## 1           2          NA          NA          NA          NA          NA ## 2           2          NA          NA          NA          NA          NA ## 3           2          NA          NA          NA          NA          NA ## 4           2          NA          NA          NA          NA          NA ## 5           2          NA          NA          NA          NA          NA ## 6           2          NA          NA          NA          NA          NA ##   h1013_4aq26 h1013_4aq28 h1013_4aq30 h1013_4aq32 h1014_4 h1014_8 h1014_12 ## 1          NA          NA          NA          NA       1       1        2 ## 2          NA          NA          NA          NA       2       2        2 ## 3          NA          NA          NA          NA       1       2        2 ## 4          NA          NA          NA          NA       1       2        2 ## 5          NA          NA          NA          NA       1       2        2 ## 6          NA          NA          NA          NA       1       2        2 ##   h1014_16 h1014_20 h1014_24 h1014_28 h1014_32 h1014_36 h1014_3aq1 h1014_4aq1 ## 1        2        2        2        2        2        2          2          2 ## 2        2        2        2        2        2        2          2          2 ## 3        2        2        2        2        2        2          2          2 ## 4        2        2        2        2        2        2          2          2 ## 5        2        2        2        2        2        2          2          2 ## 6        2        2        2        2        2        2          2          2 ##   h1015_4 h1015_8 h1015_12 h1015_20 h1015_25 h1015_29 h1015_33 h1015_37 ## 1      NA      NA       NA       NA       NA       NA       NA       NA ## 2      NA      NA       NA       NA       NA       NA       NA       NA ## 3      NA      NA       NA       NA       NA       NA       NA       NA ## 4      NA      NA       NA       NA       NA       NA       NA       NA ## 5      NA      NA       NA       NA       NA       NA       NA       NA ## 6       2       2        2        2        1        2        2        2 ##   h1015_4aq1 h1015_7aq1 h1015_aq1 h1015_40 h1015_41 h1015_42 h1015_43 h1015_44 ## 1         NA         NA        NA       NA       NA       NA       NA       NA ## 2         NA         NA        NA       NA       NA       NA       NA       NA ## 3         NA         NA        NA       NA       NA       NA       NA       NA ## 4         NA         NA        NA       NA       NA       NA       NA       NA ## 5         NA         NA        NA       NA       NA       NA       NA       NA ## 6          2          2         2       NA       NA       NA       NA       NA ##   h1015_45 h1015_46 h1015_47 h1015_48 h1015_49 h1015_50 h1015_51 h1015_52 ## 1       NA       NA       NA       NA       NA       NA       NA       NA ## 2       NA       NA       NA       NA       NA       NA       NA       NA ## 3       NA       NA       NA       NA       NA       NA       NA       NA ## 4       NA       NA       NA       NA       NA       NA       NA       NA ## 5       NA       NA       NA       NA       NA       NA       NA       NA ## 6       NA       NA       NA       NA       NA       NA       NA       NA ##   h1015_53 h1015_54 h1015_55 h1015_56 h1015_57 h1015_60 h1015_aq2 h1015_61 ## 1       NA       NA       NA       NA       NA       NA        NA       NA ## 2       NA       NA       NA       NA       NA       NA        NA       NA ## 3       NA       NA       NA       NA       NA       NA        NA       NA ## 4       NA       NA       NA       NA       NA       NA        NA       NA ## 5       NA       NA       NA       NA       NA       NA        NA       NA ## 6       NA       NA       NA       NA       NA        3         1       10 ##   h1015_62 h1015_63 h1015_66 h1015_67 h1015_68 h1015_aq3 h1015_69 h1015_70 ## 1       NA       NA       NA       NA       NA        NA       NA       NA ## 2       NA       NA       NA       NA       NA        NA       NA       NA ## 3       NA       NA       NA       NA       NA        NA       NA       NA ## 4       NA       NA       NA       NA       NA        NA       NA       NA ## 5       NA       NA       NA       NA       NA        NA       NA       NA ## 6       NA       NA       10        0       NA        NA       NA       NA ##   h1015_71 h1015_74 h1015_75 h1015_76 h1015_aq4 h1015_77 h1015_78 h1015_79 ## 1       NA       NA       NA       NA        NA       NA       NA       NA ## 2       NA       NA       NA       NA        NA       NA       NA       NA ## 3       NA       NA       NA       NA        NA       NA       NA       NA ## 4       NA       NA       NA       NA        NA       NA       NA       NA ## 5       NA       NA       NA       NA        NA       NA       NA       NA ## 6       NA       NA       NA       NA        NA       NA       NA       NA ##   h1015_82 h1015_83 h1015_84 h1015_aq5 h1015_85 h1015_86 h1015_87 h1015_90 ## 1       NA       NA       NA        NA       NA       NA       NA       NA ## 2       NA       NA       NA        NA       NA       NA       NA       NA ## 3       NA       NA       NA        NA       NA       NA       NA       NA ## 4       NA       NA       NA        NA       NA       NA       NA       NA ## 5       NA       NA       NA        NA       NA       NA       NA       NA ## 6       NA       NA       NA        NA       NA       NA       NA       NA ##   h1015_91 h1015_92 h1015_aq6 h1015_93 h1015_94 h1015_95 h1015_98 h1015_99 ## 1       NA       NA        NA       NA       NA       NA       NA       NA ## 2       NA       NA        NA       NA       NA       NA       NA       NA ## 3       NA       NA        NA       NA       NA       NA       NA       NA ## 4       NA       NA        NA       NA       NA       NA       NA       NA ## 5       NA       NA        NA       NA       NA       NA       NA       NA ## 6       NA       NA        NA       NA       NA       NA       NA       NA ##   h1015_100 h1015_aq7 h1015_101 h1015_102 h1015_103 h1015_106 h1015_107 ## 1        NA        NA        NA        NA        NA        NA        NA ## 2        NA        NA        NA        NA        NA        NA        NA ## 3        NA        NA        NA        NA        NA        NA        NA ## 4        NA        NA        NA        NA        NA        NA        NA ## 5        NA        NA        NA        NA        NA        NA        NA ## 6        NA        NA        NA        NA        NA        NA        NA ##   h1016_6aq1 h1016_6aq4 h1016_8 h1016_24 h1016_4aq1 h1016_4aq4 h1016_32 ## 1         NA         NA      NA       NA         NA         NA       NA ## 2         NA         NA      NA       NA         NA         NA       NA ## 3         NA         NA      NA       NA         NA         NA       NA ## 4         NA         NA      NA       NA         NA         NA       NA ## 5         NA         NA      NA       NA         NA         NA       NA ## 6         NA         NA      NA       NA         NA         NA       NA ##   h1016_36 h1016_40 h1016_4aq7 h1016_56 h1016_60 h1016_64 h1017_1 h1017_2 ## 1       NA       NA         NA       NA       NA       NA       7       4 ## 2       NA       NA         NA       NA       NA       NA       4       0 ## 3       NA       NA         NA       NA       NA       NA       0      NA ## 4       NA       NA         NA       NA       NA       NA       4       1 ## 5       NA       NA         NA       NA       NA       NA       4       1 ## 6       NA       NA         NA       NA       NA       NA       4       1 ##   h1017_3 h1017_4 h1017_5 h1017_6 h1017_7 p10_fnum p10_tq p10_cp p1001_1 ## 1       4       2       3       1       1        1      3      1       2 ## 2       2       2       3       2       2        1      3      1       2 ## 3       2       1       2       1       1        1      3      1       2 ## 4       2       2       3       1       1        1      3      1       1 ## 5       2       2       3       1       1        2      3      1       2 ## 6       3       1       2       2       1        1      3      1       2 ##   p1001_2 p1001_aq1 p1001_3 p1001_4 p1001_5 p1001_6 p1001_10 p1001_11 p1001_12 ## 1      NA        NA      NA      NA      NA      NA       NA       NA       NA ## 2      NA        NA      NA      NA      NA      NA       NA       NA       NA ## 3      NA        NA      NA      NA      NA      NA       NA       NA       NA ## 4       1        NA       1       0      12     508       NA       NA       NA ## 5      NA        NA      NA      NA      NA      NA       NA       NA       NA ## 6      NA        NA      NA      NA      NA      NA       NA       NA       NA ##   p1001_13 p1001_14 p1001_7 p1001_8 p1001_9 p1001_15 p1001_16 p1001_17 p1001_18 ## 1       NA       NA      NA      NA      NA        2       NA       NA       NA ## 2       NA       NA      NA      NA      NA        2       NA       NA       NA ## 3       NA       NA      NA      NA      NA        2       NA       NA       NA ## 4       NA       NA      NA      NA      NA        2       NA       NA       NA ## 5       NA       NA      NA      NA      NA        2       NA       NA       NA ## 6       NA       NA      NA      NA      NA        2       NA       NA       NA ##   p1001_19 p1001_20 p1001_21 p1001_22 p1001_23 p1001_24 p1001_25 p1001_27 ## 1       NA        2       NA       NA       NA       NA       NA        2 ## 2       NA        2       NA       NA       NA       NA       NA        2 ## 3       NA        2       NA       NA       NA       NA       NA        2 ## 4       NA        2       NA       NA       NA       NA       NA        2 ## 5       NA        2       NA       NA       NA       NA       NA        2 ## 6       NA        2       NA       NA       NA       NA       NA        2 ##   p1001_28 p1001_29 p1001_30 p1001_31 p1001_32 p1001_33 p1001_34 p1002_1 ## 1       NA       NA       NA        2       NA       NA       NA       4 ## 2       NA       NA       NA        2       NA       NA       NA       4 ## 3       NA       NA       NA        2       NA       NA       NA       1 ## 4       NA       NA       NA        2       NA       NA       NA       1 ## 5       NA       NA       NA        2       NA       NA       NA       4 ## 6       NA       NA       NA        2       NA       NA       NA       2 ##   p1002_2 p1002_3 p1002_4 p1002_5 p1002_6 p1002_7 p1002_8 p1002_8aq1 p1002_9 ## 1      NA      NA      NA      NA      NA      NA      NA         NA      NA ## 2      NA      NA      NA      NA      NA      NA      NA         NA      NA ## 3       2      NA    2013       1      12      15      84        120      NA ## 4       1      16    2014      10      12      22      40        200      NA ## 5      NA      NA      NA      NA      NA      NA      NA         NA      NA ## 6       2      NA    2000       3      12      22      35         NA      NA ##   p1002_8aq2 p1002_4aq1 p1002_10 p1002_11 p1002_12 p1002_8aq3 p1002_8aq4 ## 1         NA         NA        2       NA       NA         NA         NA ## 2         NA         NA        2       NA       NA         NA         NA ## 3         NA          1       NA       NA       NA         NA         NA ## 4         NA          1       NA       NA       NA         NA         NA ## 5         NA         NA        2       NA       NA         NA         NA ## 6         NA         NA       NA       NA       NA         NA         NA ##   p1002_31 p1002_4aq2 p1002_4aq3 p1002_4aq4 p1002_8aq5 p1002_8aq6 p1002_8aq7 ## 1       NA          2         NA         NA          0          0          0 ## 2       NA          2         NA         NA          0          0          0 ## 3       NA         NA         NA         NA          0          0          0 ## 4       NA         NA         NA         NA          0          0          0 ## 5       NA          2         NA         NA          0          0          0 ## 6       NA         NA         NA         NA          0          0          0 ##   p1002_8aq8 p1002_8aq9 p1002_8aq10 p1002_8aq11 p1002_8aq12 p1002_8aq13 ## 1          0          0           0           0           0           0 ## 2          0          0           0           0           0           0 ## 3          0          0           0           0           0           0 ## 4          0          0           0           0           0           0 ## 5          0          0           0           0           0           0 ## 6          0          0           0           0           0           0 ##   p1002_8aq14 p1002_8aq15 p1002_aq2 p1002_aq3 p1002_aq4 p1002_aq5 p1003_1 ## 1           0           0         0        NA        NA        NA       2 ## 2           0           0         0        NA        NA        NA       2 ## 3           0           0         0        NA        NA        NA       2 ## 4           0           0         0        NA        NA        NA       2 ## 5           0           0         0        NA        NA        NA       2 ## 6           0           0         0        NA        NA        NA       1 ##   p1003_2 p1003_5 p1003_6 p1003_7 p1003_8 p1003_9 p1003_10 p1003_11 p1003_12 ## 1       0       2       3       3       4       3        2        3        3 ## 2       0       1       3       1       4       3        3        3        3 ## 3       2       3       2       1       3       3        3        3        3 ## 4       2       4       4       3       3       3        3        3        4 ## 5       0       4       4       3       3       3        3        3        4 ## 6       2       2       2       4       4       4        3        3        3 ##   p1004_1 p1004_2 p1004_3 p1004_4 p1004_5 p1004_6 p1004_7 p1004_8 p1004_9 ## 1       1       4       2       2      NA      NA       2      NA      NA ## 2       2       4       3       2      NA      NA       2      NA      NA ## 3       2       4       3       2      NA      NA       2      NA      NA ## 4       2       4       3       2      NA      NA       2      NA      NA ## 5       3       4       3       2      NA      NA       2      NA      NA ## 6       2       4       4       2      NA      NA       2      NA      NA ##   p1004_10 p1004_11 p1004_12 p1004_13 p1004_3aq1 p1004_3aq2 p1004_3aq3 ## 1       NA       NA       NA       NA          4          4          5 ## 2       NA       NA       NA       NA          5          2          5 ## 3       NA       NA       NA       NA          2          2          4 ## 4       NA       NA       NA       NA          3          2          4 ## 5       NA       NA       NA       NA          4          2          4 ## 6       NA       NA       NA       NA          4          3          4 ##   p1004_3aq4 p1004_3aq5 p1004_3aq6 p1004_3aq7 p1004_3aq8 p1005_3aq1 p1005_3aq2 ## 1          4          2          1          1          1         NA         NA ## 2          1          5          5          4          4         NA         NA ## 3          2          4          2          2          2         NA         NA ## 4          2          4          2          2          2         NA         NA ## 5          3          4          2          2          2         NA         NA ## 6          2          4          2          4          4         NA         NA ##   p1005_3aq3 p1005_3aq4 p1005_3aq5 p1005_3aq6 p1005_3aq7 p1005_3aq8 p1005_3aq9 ## 1         NA         NA          2         NA         NA         NA          1 ## 2         NA         NA          2         NA         NA         NA          1 ## 3         NA         NA          2         NA         NA         NA          1 ## 4         NA         NA          2         NA         NA         NA          1 ## 5         NA         NA          2         NA         NA         NA          1 ## 6         NA         NA          2         NA         NA         NA          1 ##   p1005_3aq10 p1005_2 p1005_3 p1005_4aq1 p1005_4aq2 p1005_4aq3 p1005_4aq4 ## 1          NA       5      NA         NA         NA         NA         NA ## 2          NA       5      NA         NA         NA         NA         NA ## 3          NA       5      NA         NA         NA         NA         NA ## 4          NA       5      NA         NA         NA         NA         NA ## 5          NA       5      NA         NA         NA         NA         NA ## 6          NA       5      NA         NA         NA         NA         NA ##   p1005_4aq5 p1005_4aq6 p1005_4aq7 p1005_4aq8 p1005_5 p1005_6 p1005_7 p1005_8 ## 1         NA         NA         NA         NA      NA      NA      NA      NA ## 2         NA         NA         NA         NA      NA      NA      NA      NA ## 3         NA         NA         NA         NA      NA      NA      NA      NA ## 4         NA         NA         NA         NA      NA      NA      NA      NA ## 5         NA         NA         NA         NA      NA      NA      NA      NA ## 6         NA         NA         NA         NA      NA      NA      NA      NA ##   p1005_3aq11 p1005_9 p1005_10 p1005_11 p1005_12 p1005_13 p1005_14 p1005_15 ## 1           2       1        4        1        2        1        2        4 ## 2           2       2        3        1        2        2        1        3 ## 3           0       1        4        1        1        1        1        4 ## 4           0       1        4        1        1        1        1        4 ## 5           2       1        4        1        1        1        1        4 ## 6           0       2        3        2        2        2        1        2 ##   p1005_16 p1005_17 p1005_18 p1005_19 p1005_20 p1005_21 p1005_22 p1005_23 ## 1        1        1        1        1        2        3        3        1 ## 2        1        1        1        2        2        2        1        2 ## 3        1        1        1        1        2        2        2        2 ## 4        1        1        1        1        4        3        1        4 ## 5        1        1        1        1        2        2        1        2 ## 6        1        2        1        2        2        2        2        2 ##   p1005_24 p1005_25 p1005_26 p1005_27 p1005_28 p1005_29 p1005_4aq9 p1005_4aq10 ## 1        4        2        1        2        3        2          0           0 ## 2        2        2        2        2        1        1          0           0 ## 3        2        2        2        2        1        1          0           0 ## 4        2        3        3        2        1        1          0           0 ## 5        2        2        2        2        1        1          0           0 ## 6        2        2        2        2        1        1          2           1 ##   p1005_4aq11 p1005_aq1 p1005_aq2 p1005_aq3 p1005_aq4 p1005_6aq1 p1005_6aq2 ## 1           0         4         0         5         1         NA         NA ## 2           0         4         0         4         4         NA         NA ## 3           0         3         0         3         0         NA         NA ## 4           0         6         0         5         5         NA         NA ## 5           0         5         0         5         5         NA         NA ## 6           1         6         6         5         0         NA         NA ##   p1005_6aq3 p1005_6aq4 p1005_6aq5 p1005_6aq6 p1005_6aq7 p1005_6aq8 p1005_6aq9 ## 1         NA         NA         NA         NA         NA         NA         NA ## 2         NA         NA         NA         NA         NA         NA         NA ## 3         NA         NA         NA         NA         NA         NA         NA ## 4         NA         NA         NA         NA         NA         NA         NA ## 5         NA         NA         NA         NA         NA         NA         NA ## 6         NA         NA         NA         NA         NA         NA         NA ##   p1005_7aq1 p1005_7aq2 p1005_7aq3 p1007_3aq1 p1007_3aq2 p1007_3aq3 p1007_3aq4 ## 1          2          2          2         NA         NA         NA         NA ## 2          2          2          2         NA         NA         NA         NA ## 3          2          2          2         NA         NA         NA         NA ## 4          2          2          2         NA         NA         NA         NA ## 5          2          2          2         NA         NA         NA         NA ## 6          2          2          2         NA         NA         NA         NA ##   p1007_3aq5 p1007_3aq6 p1007_3aq7 np1006_1 np1006_2 np1006_3 np1006_4 np1006_5 ## 1         NA         NA         NA       NA       NA       NA       NA       NA ## 2         NA         NA         NA       NA       NA       NA       NA       NA ## 3         NA         NA         NA       NA       NA       NA       NA       NA ## 4         NA         NA         NA       NA       NA       NA       NA       NA ## 5         NA         NA         NA       NA       NA       NA       NA       NA ## 6         NA         NA         NA       NA       NA       NA       NA       NA ##   np1006_6 np1006_7 np1006_8 np1006_9 np1006_10 np1006_11 np1006_12 np1006_13 ## 1       NA       NA       NA       NA        NA        NA        NA        NA ## 2       NA       NA       NA       NA        NA        NA        NA        NA ## 3       NA       NA       NA       NA        NA        NA        NA        NA ## 4       NA       NA       NA       NA        NA        NA        NA        NA ## 5       NA       NA       NA       NA        NA        NA        NA        NA ## 6       NA       NA       NA       NA        NA        NA        NA        NA ##   np1006_14 np1006_15 np1006_16 np1006_17 np1006_18 np1006_19 np1006_20 ## 1        NA        NA        NA        NA        NA        NA        NA ## 2        NA        NA        NA        NA        NA        NA        NA ## 3        NA        NA        NA        NA        NA        NA        NA ## 4        NA        NA        NA        NA        NA        NA        NA ## 5        NA        NA        NA        NA        NA        NA        NA ## 6        NA        NA        NA        NA        NA        NA        NA ##   np1006_21 np1006_22 np1006_23 np1006_24 np1006_25 np1006_26 np1006_27 ## 1        NA        NA        NA        NA        NA        NA        NA ## 2        NA        NA        NA        NA        NA        NA        NA ## 3        NA        NA        NA        NA        NA        NA        NA ## 4        NA        NA        NA        NA        NA        NA        NA ## 5        NA        NA        NA        NA        NA        NA        NA ## 6        NA        NA        NA        NA        NA        NA        NA ##   np1006_28 np1006_29 np1006_30 np1006_31 np1006_32 np1006_33 np1006_34 ## 1        NA        NA        NA        NA        NA        NA        NA ## 2        NA        NA        NA        NA        NA        NA        NA ## 3        NA        NA        NA        NA        NA        NA        NA ## 4        NA        NA        NA        NA        NA        NA        NA ## 5        NA        NA        NA        NA        NA        NA        NA ## 6        NA        NA        NA        NA        NA        NA        NA ##   np1006_35 np1006_36 np1006_37 np1006_38 np1006_39 np1006_40 np1006_41 ## 1        NA        NA        NA        NA        NA        NA        NA ## 2        NA        NA        NA        NA        NA        NA        NA ## 3        NA        NA        NA        NA        NA        NA        NA ## 4        NA        NA        NA        NA        NA        NA        NA ## 5        NA        NA        NA        NA        NA        NA        NA ## 6        NA        NA        NA        NA        NA        NA        NA ##   np1006_42 np1006_43 np1006_44 p1006_3aq1 c10_fnum c10_cp c10_grade c1001_1 ## 1        NA        NA        NA         NA       NA     NA        NA      NA ## 2        NA        NA        NA         NA       NA     NA        NA      NA ## 3        NA        NA        NA         NA       NA     NA        NA      NA ## 4        NA        NA        NA         NA       NA     NA        NA      NA ## 5        NA        NA        NA         NA       NA     NA        NA      NA ## 6        NA        NA        NA         NA       NA     NA        NA      NA ##   c1001_2 c1001_3 c1001_4 c1001_5 c1001_6 c1001_7 c1001_8 c1001_9 c1001_10 ## 1      NA      NA      NA      NA      NA      NA      NA      NA       NA ## 2      NA      NA      NA      NA      NA      NA      NA      NA       NA ## 3      NA      NA      NA      NA      NA      NA      NA      NA       NA ## 4      NA      NA      NA      NA      NA      NA      NA      NA       NA ## 5      NA      NA      NA      NA      NA      NA      NA      NA       NA ## 6      NA      NA      NA      NA      NA      NA      NA      NA       NA ##   c1001_11 c1001_12 c1001_13 c1001_7aq5 c1001_7aq6 c1001_7aq7 c1001_7aq8 ## 1       NA       NA       NA         NA         NA         NA         NA ## 2       NA       NA       NA         NA         NA         NA         NA ## 3       NA       NA       NA         NA         NA         NA         NA ## 4       NA       NA       NA         NA         NA         NA         NA ## 5       NA       NA       NA         NA         NA         NA         NA ## 6       NA       NA       NA         NA         NA         NA         NA ##   c1001_4aq1 c1001_4aq2 c1001_4aq3 c1001_4aq4 c1001_4aq5 c1001_4aq6 c1002_1 ## 1         NA         NA         NA         NA         NA         NA      NA ## 2         NA         NA         NA         NA         NA         NA      NA ## 3         NA         NA         NA         NA         NA         NA      NA ## 4         NA         NA         NA         NA         NA         NA      NA ## 5         NA         NA         NA         NA         NA         NA      NA ## 6         NA         NA         NA         NA         NA         NA      NA ##   c1002_2 c1002_3 c1002_4 c1002_5 c1002_6 c1002_7 c1002_8 c1002_9 c1002_10 ## 1      NA      NA      NA      NA      NA      NA      NA      NA       NA ## 2      NA      NA      NA      NA      NA      NA      NA      NA       NA ## 3      NA      NA      NA      NA      NA      NA      NA      NA       NA ## 4      NA      NA      NA      NA      NA      NA      NA      NA       NA ## 5      NA      NA      NA      NA      NA      NA      NA      NA       NA ## 6      NA      NA      NA      NA      NA      NA      NA      NA       NA ##   c1002_11 c1002_12 c1002_13 c1002_14 c1002_15 c1002_16 c1002_17 c1002_18 ## 1       NA       NA       NA       NA       NA       NA       NA       NA ## 2       NA       NA       NA       NA       NA       NA       NA       NA ## 3       NA       NA       NA       NA       NA       NA       NA       NA ## 4       NA       NA       NA       NA       NA       NA       NA       NA ## 5       NA       NA       NA       NA       NA       NA       NA       NA ## 6       NA       NA       NA       NA       NA       NA       NA       NA ##   c1002_19 c1002_20 c1002_21 c1002_22 c1002_23 c1002_24 c1002_25 c1002_26 ## 1       NA       NA       NA       NA       NA       NA       NA       NA ## 2       NA       NA       NA       NA       NA       NA       NA       NA ## 3       NA       NA       NA       NA       NA       NA       NA       NA ## 4       NA       NA       NA       NA       NA       NA       NA       NA ## 5       NA       NA       NA       NA       NA       NA       NA       NA ## 6       NA       NA       NA       NA       NA       NA       NA       NA ##   c1002_4aq1 c1002_27 c1002_28 c1002_29 c1002_30 c1002_31 c1002_32 c1002_33 ## 1         NA       NA       NA       NA       NA       NA       NA       NA ## 2         NA       NA       NA       NA       NA       NA       NA       NA ## 3         NA       NA       NA       NA       NA       NA       NA       NA ## 4         NA       NA       NA       NA       NA       NA       NA       NA ## 5         NA       NA       NA       NA       NA       NA       NA       NA ## 6         NA       NA       NA       NA       NA       NA       NA       NA ##   c1002_34 c1002_35 c1002_36 c1002_37 c1002_38 c1002_39 c1002_40 c1002_41 ## 1       NA       NA       NA       NA       NA       NA       NA       NA ## 2       NA       NA       NA       NA       NA       NA       NA       NA ## 3       NA       NA       NA       NA       NA       NA       NA       NA ## 4       NA       NA       NA       NA       NA       NA       NA       NA ## 5       NA       NA       NA       NA       NA       NA       NA       NA ## 6       NA       NA       NA       NA       NA       NA       NA       NA ##   c1002_42 c1002_43 c1002_44 c1002_45 c1002_46 c1002_47 c1002_48 c1002_49 ## 1       NA       NA       NA       NA       NA       NA       NA       NA ## 2       NA       NA       NA       NA       NA       NA       NA       NA ## 3       NA       NA       NA       NA       NA       NA       NA       NA ## 4       NA       NA       NA       NA       NA       NA       NA       NA ## 5       NA       NA       NA       NA       NA       NA       NA       NA ## 6       NA       NA       NA       NA       NA       NA       NA       NA ##   c1002_50 c1002_51 c1002_52 c1002_53 c1002_54 c1002_55 c1002_56 c1002_57 ## 1       NA       NA       NA       NA       NA       NA       NA       NA ## 2       NA       NA       NA       NA       NA       NA       NA       NA ## 3       NA       NA       NA       NA       NA       NA       NA       NA ## 4       NA       NA       NA       NA       NA       NA       NA       NA ## 5       NA       NA       NA       NA       NA       NA       NA       NA ## 6       NA       NA       NA       NA       NA       NA       NA       NA ##   c1002_58 c1002_4aq2 c1002_59 c1002_60 c1002_61 c1002_62 c1002_63 c1002_64 ## 1       NA         NA       NA       NA       NA       NA       NA       NA ## 2       NA         NA       NA       NA       NA       NA       NA       NA ## 3       NA         NA       NA       NA       NA       NA       NA       NA ## 4       NA         NA       NA       NA       NA       NA       NA       NA ## 5       NA         NA       NA       NA       NA       NA       NA       NA ## 6       NA         NA       NA       NA       NA       NA       NA       NA ##   c1002_65 c1002_66 c1002_67 c1002_68 c1002_69 c1002_70 c1002_71 c1002_72 ## 1       NA       NA       NA       NA       NA       NA       NA       NA ## 2       NA       NA       NA       NA       NA       NA       NA       NA ## 3       NA       NA       NA       NA       NA       NA       NA       NA ## 4       NA       NA       NA       NA       NA       NA       NA       NA ## 5       NA       NA       NA       NA       NA       NA       NA       NA ## 6       NA       NA       NA       NA       NA       NA       NA       NA ##   c1002_73 c1002_74 c1002_75 c1002_76 c1002_77 c1002_7aq1 c1002_7aq2 c1002_7aq3 ## 1       NA       NA       NA       NA       NA         NA         NA         NA ## 2       NA       NA       NA       NA       NA         NA         NA         NA ## 3       NA       NA       NA       NA       NA         NA         NA         NA ## 4       NA       NA       NA       NA       NA         NA         NA         NA ## 5       NA       NA       NA       NA       NA         NA         NA         NA ## 6       NA       NA       NA       NA       NA         NA         NA         NA ##   c1002_7aq4 c1002_7aq5 c1002_7aq6 c1002_7aq7 c1002_7aq8 c1002_7aq9 c1002_7aq10 ## 1         NA         NA         NA         NA         NA         NA          NA ## 2         NA         NA         NA         NA         NA         NA          NA ## 3         NA         NA         NA         NA         NA         NA          NA ## 4         NA         NA         NA         NA         NA         NA          NA ## 5         NA         NA         NA         NA         NA         NA          NA ## 6         NA         NA         NA         NA         NA         NA          NA ##   c1002_7aq11 c1002_7aq12 c1002_7aq13 c1002_7aq14 c1002_78 c1002_79 c1002_80 ## 1          NA          NA          NA          NA       NA       NA       NA ## 2          NA          NA          NA          NA       NA       NA       NA ## 3          NA          NA          NA          NA       NA       NA       NA ## 4          NA          NA          NA          NA       NA       NA       NA ## 5          NA          NA          NA          NA       NA       NA       NA ## 6          NA          NA          NA          NA       NA       NA       NA ##   c1002_81 c1002_82 c1002_83 c1002_84 c1002_85 c1002_86 c1002_87 c1002_88 ## 1       NA       NA       NA       NA       NA       NA       NA       NA ## 2       NA       NA       NA       NA       NA       NA       NA       NA ## 3       NA       NA       NA       NA       NA       NA       NA       NA ## 4       NA       NA       NA       NA       NA       NA       NA       NA ## 5       NA       NA       NA       NA       NA       NA       NA       NA ## 6       NA       NA       NA       NA       NA       NA       NA       NA ##   c1002_89 c1002_90 c1002_91 c1002_92 c1002_93 c1002_94 c1002_95 c1002_96 ## 1       NA       NA       NA       NA       NA       NA       NA       NA ## 2       NA       NA       NA       NA       NA       NA       NA       NA ## 3       NA       NA       NA       NA       NA       NA       NA       NA ## 4       NA       NA       NA       NA       NA       NA       NA       NA ## 5       NA       NA       NA       NA       NA       NA       NA       NA ## 6       NA       NA       NA       NA       NA       NA       NA       NA ##   c1002_97 c1002_98 c1002_4aq3 c1002_4aq4 c1002_4aq5 c1002_4aq6 c1002_4aq7 ## 1       NA       NA         NA         NA         NA         NA         NA ## 2       NA       NA         NA         NA         NA         NA         NA ## 3       NA       NA         NA         NA         NA         NA         NA ## 4       NA       NA         NA         NA         NA         NA         NA ## 5       NA       NA         NA         NA         NA         NA         NA ## 6       NA       NA         NA         NA         NA         NA         NA ##   c1002_4aq8 c1002_7aq15 c1003_4aq1 c1003_4aq2 c1003_4aq3 c1003_4aq4 c1003_4aq5 ## 1         NA          NA         NA         NA         NA         NA         NA ## 2         NA          NA         NA         NA         NA         NA         NA ## 3         NA          NA         NA         NA         NA         NA         NA ## 4         NA          NA         NA         NA         NA         NA         NA ## 5         NA          NA         NA         NA         NA         NA         NA ## 6         NA          NA         NA         NA         NA         NA         NA ##   c1003_4aq6 c1003_4aq7 c1003_4aq8 c1003_4aq9 c1003_6 c1003_7 c1003_8 c1003_9 ## 1         NA         NA         NA         NA      NA      NA      NA      NA ## 2         NA         NA         NA         NA      NA      NA      NA      NA ## 3         NA         NA         NA         NA      NA      NA      NA      NA ## 4         NA         NA         NA         NA      NA      NA      NA      NA ## 5         NA         NA         NA         NA      NA      NA      NA      NA ## 6         NA         NA         NA         NA      NA      NA      NA      NA ##   c1003_13 c1003_14 c1003_15 c1004_4aq1 c1004_4aq2 c1004_4aq3 c1004_4aq4 ## 1       NA       NA       NA         NA         NA         NA         NA ## 2       NA       NA       NA         NA         NA         NA         NA ## 3       NA       NA       NA         NA         NA         NA         NA ## 4       NA       NA       NA         NA         NA         NA         NA ## 5       NA       NA       NA         NA         NA         NA         NA ## 6       NA       NA       NA         NA         NA         NA         NA ##   c1004_4aq5 c1004_4aq6 c1004_1 c1004_2 c1004_3 c1004_4 c1004_5 c1004_6 c1004_7 ## 1         NA         NA      NA      NA      NA      NA      NA      NA      NA ## 2         NA         NA      NA      NA      NA      NA      NA      NA      NA ## 3         NA         NA      NA      NA      NA      NA      NA      NA      NA ## 4         NA         NA      NA      NA      NA      NA      NA      NA      NA ## 5         NA         NA      NA      NA      NA      NA      NA      NA      NA ## 6         NA         NA      NA      NA      NA      NA      NA      NA      NA ##   c1004_8 c1004_9 c1004_10 c1004_4aq7 c1004_4aq8 c1005_12 c1005_13 c1005_14 ## 1      NA      NA       NA         NA         NA       NA       NA       NA ## 2      NA      NA       NA         NA         NA       NA       NA       NA ## 3      NA      NA       NA         NA         NA       NA       NA       NA ## 4      NA      NA       NA         NA         NA       NA       NA       NA ## 5      NA      NA       NA         NA         NA       NA       NA       NA ## 6      NA      NA       NA         NA         NA       NA       NA       NA ##   c1005_15 c1005_16 c1005_17 c1005_4aq1 c1005_18 c1005_19 c1005_7aq1 c1005_7aq2 ## 1       NA       NA       NA         NA                           NA         NA ## 2       NA       NA       NA         NA                           NA         NA ## 3       NA       NA       NA         NA                           NA         NA ## 4       NA       NA       NA         NA                           NA         NA ## 5       NA       NA       NA         NA                           NA         NA ## 6       NA       NA       NA         NA                           NA         NA ##   c1005_7aq3 c1005_7aq4 c1005_7aq5 c1005_7aq6 c1005_7aq7 c1005_7aq8 c1005_7aq9 ## 1         NA         NA         NA         NA         NA         NA         NA ## 2         NA         NA         NA         NA         NA         NA         NA ## 3         NA         NA         NA         NA         NA         NA         NA ## 4         NA         NA         NA         NA         NA         NA         NA ## 5         NA         NA         NA         NA         NA         NA         NA ## 6         NA         NA         NA         NA         NA         NA         NA ##   c1005_7aq10 c1005_7aq11 c1005_7aq12 c1005_7aq13 c1005_7aq14 c1005_7aq15 ## 1          NA          NA          NA          NA          NA          NA ## 2          NA          NA          NA          NA          NA          NA ## 3          NA          NA          NA          NA          NA          NA ## 4          NA          NA          NA          NA          NA          NA ## 5          NA          NA          NA          NA          NA          NA ## 6          NA          NA          NA          NA          NA          NA ##   c1005_7aq16 c1005_7aq17 c1005_7aq18 c1005_7aq19 c1005_7aq20 c1005_20 c1005_21 ## 1          NA          NA          NA          NA          NA       NA       NA ## 2          NA          NA          NA          NA          NA       NA       NA ## 3          NA          NA          NA          NA          NA       NA       NA ## 4          NA          NA          NA          NA          NA       NA       NA ## 5          NA          NA          NA          NA          NA       NA       NA ## 6          NA          NA          NA          NA          NA       NA       NA ##   c1005_22 c1005_23 c1005_24 c1005_25 c1005_26 c1005_27 c1005_28 c1005_29 ## 1       NA       NA       NA       NA       NA       NA       NA       NA ## 2       NA       NA       NA       NA       NA       NA       NA       NA ## 3       NA       NA       NA       NA       NA       NA       NA       NA ## 4       NA       NA       NA       NA       NA       NA       NA       NA ## 5       NA       NA       NA       NA       NA       NA       NA       NA ## 6       NA       NA       NA       NA       NA       NA       NA       NA ##   c1005_30 c1005_31 c1005_32 c1005_36 c1005_4aq2 c1005_38 c1005_4aq3 c1005_40 ## 1       NA       NA       NA       NA         NA       NA         NA       NA ## 2       NA       NA       NA       NA         NA       NA         NA       NA ## 3       NA       NA       NA       NA         NA       NA         NA       NA ## 4       NA       NA       NA       NA         NA       NA         NA       NA ## 5       NA       NA       NA       NA         NA       NA         NA       NA ## 6       NA       NA       NA       NA         NA       NA         NA       NA ##   c1005_10aq1 c1005_42 c1005_4aq4 c1005_44 c1005_4aq5 c1005_46 c1005_4aq6 ## 1          NA       NA         NA       NA         NA       NA         NA ## 2          NA       NA         NA       NA         NA       NA         NA ## 3          NA       NA         NA       NA         NA       NA         NA ## 4          NA       NA         NA       NA         NA       NA         NA ## 5          NA       NA         NA       NA         NA       NA         NA ## 6          NA       NA         NA       NA         NA       NA         NA ##   c1005_48 c1005_4aq7 c1005_4aq8 c1005_4aq9 c1005_4aq10 c1005_4aq11 c1005_4aq12 ## 1       NA         NA         NA         NA          NA          NA          NA ## 2       NA         NA         NA         NA          NA          NA          NA ## 3       NA         NA         NA         NA          NA          NA          NA ## 4       NA         NA         NA         NA          NA          NA          NA ## 5       NA         NA         NA         NA          NA          NA          NA ## 6       NA         NA         NA         NA          NA          NA          NA ##   c1005_4aq13 c1005_4aq14 c1005_4aq15 c1007_4aq1 c1007_4aq2 c1007_7aq1 ## 1          NA          NA          NA         NA         NA         NA ## 2          NA          NA          NA         NA         NA         NA ## 3          NA          NA          NA         NA         NA         NA ## 4          NA          NA          NA         NA         NA         NA ## 5          NA          NA          NA         NA         NA         NA ## 6          NA          NA          NA         NA         NA         NA ##   c1007_7aq2 c1007_7aq3 c1007_4aq3 c1007_4aq4 c1007_4aq5 c1007_4aq6 c1007_4aq7 ## 1         NA         NA         NA         NA         NA         NA         NA ## 2         NA         NA         NA         NA         NA         NA         NA ## 3         NA         NA         NA         NA         NA         NA         NA ## 4         NA         NA         NA         NA         NA         NA         NA ## 5         NA         NA         NA         NA         NA         NA         NA ## 6         NA         NA         NA         NA         NA         NA         NA ##   c1007_4aq8 c1007_4aq9 c1007_4aq10 c1007_4aq11 c1007_4aq12 c1007_4aq13 ## 1         NA         NA          NA          NA          NA          NA ## 2         NA         NA          NA          NA          NA          NA ## 3         NA         NA          NA          NA          NA          NA ## 4         NA         NA          NA          NA          NA          NA ## 5         NA         NA          NA          NA          NA          NA ## 6         NA         NA          NA          NA          NA          NA ##   c1007_4aq14 c1007_4aq15 c1007_4aq16 c1007_4aq17 c1007_4aq18 c1007_4aq19 ## 1          NA          NA          NA          NA          NA          NA ## 2          NA          NA          NA          NA          NA          NA ## 3          NA          NA          NA          NA          NA          NA ## 4          NA          NA          NA          NA          NA          NA ## 5          NA          NA          NA          NA          NA          NA ## 6          NA          NA          NA          NA          NA          NA ##   c1007_4aq20 c1007_4aq21 c1007_4aq22 c1007_4aq23 h10_pers_income1 ## 1          NA          NA          NA          NA               NA ## 2          NA          NA          NA          NA               NA ## 3          NA          NA          NA          NA               NA ## 4          NA          NA          NA          NA               NA ## 5          NA          NA          NA          NA               NA ## 6          NA          NA          NA          NA               NA ##   h10_pers_income2 h10_pers_income3 h10_pers_income4 h10_pers_income5 ## 1               NA               NA                0               NA ## 2               NA               NA                0               NA ## 3             1440               NA                0               NA ## 4             2400               NA                0               NA ## 5               NA               NA                0               NA ## 6               NA             3000                0               NA   tail(data)   ##       h10_id h10_ind h10_sn h10_merkey h_new h10_cobf h10_reg5 h10_reg7 h10_din ## 16659   9800       7      1   98000701     1       NA        4        5    9764 ## 16660   9800       7      1   98000701     1       NA        4        5    9764 ## 16661   9800       7      1   98000701     1       NA        4        5    9764 ## 16662   9800       7      1   98000701     1       NA        4        5    9764 ## 16663   9800       7      1   98000701     1       NA        4        5    9764 ## 16664   9800       7      1   98000701     1       NA        4        5    9764 ##       h10_cin h10_flag   p10_wgl   p10_wsl   p10_wgc   p10_wsc h10_hc nh1001_1 ## 16659   11600        0  560.9736 0.1853893  602.8348 0.1992235      1       NA ## 16660   11600        0  536.4383 0.1772810  525.2045 0.1735685      1       NA ## 16661   11600        0  687.1090 0.2270743  679.6506 0.2246095      1       NA ## 16662   11600        0 1262.0316 0.4170735 1248.3326 0.4125463      1       NA ## 16663   11600        0  578.4468 0.1911638  572.1679 0.1890888      1       NA ## 16664   11600        0  554.8621 0.1833696  548.8392 0.1813792      1       NA ##       nh1001_2 h1001_1 h10_pind h10_pid h10_g1 h10_g2 h10_g3 h10_g4 h10_g6 ## 16659       NA       6        7  980001      1     10      1   1967      5 ## 16660       NA       6        7  980002      2     20      2   1967      5 ## 16661       NA       6        7  980003      3     11      2   1992      5 ## 16662       NA       6        7  980004      4     12      1   1995      5 ## 16663       NA       6        7  980005      5     13      2   1998      5 ## 16664       NA       6        7  980006      6     14      1   2001      4 ##       h10_g7 h10_g8 h10_g9 h10_g10 h10_g11 h10_g12 h1001_110 h1001_5aq1 ## 16659      5      0      0       1       1       1         5          0 ## 16660      5      0      0       1       1       1         5          0 ## 16661      5      0      0       5       1       1         5          0 ## 16662      5      0      0       5       1       1         5          0 ## 16663      1      0      0       0       1       1         5          0 ## 16664      1      0      0       0       1       1         5          0 ##       h1001_5aq2 h1001_5aq3 h1001_5aq4 h10_med1 h10_med2 h10_med3 h10_med4 ## 16659          0          0          0        1        2       38        1 ## 16660          0          0          0        2        1        0        0 ## 16661          0          0          0        3        1        0        0 ## 16662          0          0          0        4        1        3        0 ## 16663          0          0          0        5        1        0        0 ## 16664          0          0          0        6        1        4        0 ##       h10_med5 h10_med6 h10_med7 h10_med8 h10_g9_1 h10_med9 h10_med10 h10_eco1 ## 16659        1        1        2        1        0       30         6        1 ## 16660        0        0        0        1        0        0         6        2 ## 16661        0        0        0        0        0        0         2        3 ## 16662        0        0        2        0        0        0         1        4 ## 16663        0        0        0        0        0        0         2        5 ## 16664        0        0        2        0        0       30         2        6 ##       h10_eco2 h10_eco3 h10_eco4 h10_eco4_1 h10_eco5_1 h10_eco6 h10_eco_7_1 ## 16659        1       NA        6         NA         NA       NA          NA ## 16660        1       NA        9         NA         NA       NA          NA ## 16661        1       NA        1         NA          1        2           2 ## 16662        1       NA        9         NA         NA       NA          NA ## 16663        1       NA        9         NA         NA       NA          NA ## 16664        0       NA       NA         NA         NA       NA          NA ##       h10_eco_7_2 h10_eco_7_3 h10_eco8 h10_eco9 h10_eco10 h10_eco11 h10_soc1 ## 16659          NA          NA       49      874         1        NA        1 ## 16660          NA          NA       NA       NA        NA         6        2 ## 16661           1          NA       21      314         7        NA        3 ## 16662          NA          NA       NA       NA        NA         5        4 ## 16663          NA          NA       NA       NA        NA         3        5 ## 16664          NA          NA       NA       NA        NA        NA        6 ##       h10_soc_2 h10_soc_3 h10_soc_4 h10_soc_5 h10_soc_6 h10_soc_7 h10_soc_8 ## 16659         2         1         2         2         1         5         9 ## 16660         0        NA        NA        NA        NA        NA        NA ## 16661         2         1         1         1        NA        NA        NA ## 16662         0        NA        NA        NA        NA        NA        NA ## 16663         0        NA        NA        NA        NA        NA        NA ## 16664         0        NA        NA        NA        NA        NA        NA ##       h10_soc_9 h10_soc_10 h10_soc_11 h10_soc8 h10_soc9 h10_soc11 h10_soc10 ## 16659        NA         NA         NA        0        0         0         0 ## 16660        NA         NA         NA        0        0         0         0 ## 16661         0          0         NA        1        1         1         2 ## 16662        NA         NA         NA        0        0         0         0 ## 16663        NA         NA         NA        0        0         0         0 ## 16664        NA         NA         NA        0        0         0         0 ##       h10_soc_12 h10_soc_13 h1005_1 h1005_3aq1 h1005_2 h1005_3 h1005_4 h1005_5 ## 16659          4          3       1          2      NA      NA       2      NA ## 16660          4          4       1          2      NA      NA       2      NA ## 16661          4          1       1          2      NA      NA       2      NA ## 16662          4          4       1          2      NA      NA       2      NA ## 16663          4          4       1          2      NA      NA       2      NA ## 16664          4          4       1          2      NA      NA       2      NA ##       h1005_6 h1005_7 nh1005_8 nh1005_9 h1005_3aq2 h1006_aq1 h1006_1 h1006_2 ## 16659      NA       0        4        4         82         1       5       3 ## 16660      NA       0        4        4         82         1       5       3 ## 16661      NA       0        4        4         82         1       5       3 ## 16662      NA       0        4        4         82         1       5       3 ## 16663      NA       0        4        4         82         1       5       3 ## 16664      NA       0        4        4         82         1       5       3 ##       h1006_4 h1006_5 h1006_3 h1006_6 h1006_8 h1006_9 h1006_aq2 h1006_aq3 ## 16659       3     112       2    6000       1      88         0         0 ## 16660       3     112       2    6000       1      88         0         0 ## 16661       3     112       2    6000       1      88         0         0 ## 16662       3     112       2    6000       1      88         0         0 ## 16663       3     112       2    6000       1      88         0         0 ## 16664       3     112       2    6000       1      88         0         0 ##       h1006_10 h1006_11 h1006_12 h1006_13 h1006_14 h1006_21 h1006_22 h1006_23 ## 16659        1        1        1        2        1        1        1        1 ## 16660        1        1        1        2        1        1        1        1 ## 16661        1        1        1        2        1        1        1        1 ## 16662        1        1        1        2        1        1        1        1 ## 16663        1        1        1        2        1        1        1        1 ## 16664        1        1        1        2        1        1        1        1 ##       h1006_24 h1006_25 h1006_27 h1006_30 h1006_33 h1006_36 h1006_39 h1006_3aq1 ## 16659        1        5        2        2        2        2        2          2 ## 16660        1        5        2        2        2        2        2          2 ## 16661        1        5        2        2        2        2        2          2 ## 16662        1        5        2        2        2        2        2          2 ## 16663        1        5        2        2        2        2        2          2 ## 16664        1        5        2        2        2        2        2          2 ##       h1007_3aq1 h1007_3aq2 h1007_5aq1 h1007_3aq3 h1007_3aq4 h1007_3aq5 ## 16659        140         72          1          0         22         16 ## 16660        140         72          1          0         22         16 ## 16661        140         72          1          0         22         16 ## 16662        140         72          1          0         22         16 ## 16663        140         72          1          0         22         16 ## 16664        140         72          1          0         22         16 ##       h1007_6aq1 h1007_3aq6 h1007_5aq2 h1007_3aq7 h1007_3aq8 h1007_3aq9 ## 16659        6.5         19          0         57         19          5 ## 16660        6.5         19          0         57         19          5 ## 16661        6.5         19          0         57         19          5 ## 16662        6.5         19          0         57         19          5 ## 16663        6.5         19          0         57         19          5 ## 16664        6.5         19          0         57         19          5 ##       h1007_3aq10 h1007_3aq11 h1007_5aq3 h1007_5aq4 h1007_3aq13 h1007_6aq4 ## 16659           0          17         64         37         190         10 ## 16660           0          17         64         37         190         10 ## 16661           0          17         64         37         190         10 ## 16662           0          17         64         37         190         10 ## 16663           0          17         64         37         190         10 ## 16664           0          17         64         37         190         10 ##       h1007_6aq6 h1007_3aq14 h1007_3aq15 h1007_3aq16 h1007_3aq17 h1007_4 ## 16659          5           0          13           0           0     105 ## 16660          5           0          13           0           0     105 ## 16661          5           0          13           0           0     105 ## 16662          5           0          13           0           0     105 ## 16663          5           0          13           0           0     105 ## 16664          5           0          13           0           0     105 ##       h1007_6aq7 h1007_6aq8 h1007_6aq9 h1007_6aq10 h1007_6aq11 h1007_5 ## 16659          3        1.2          5        95.8           0      48 ## 16660          3        1.2          5        95.8           0      48 ## 16661          3        1.2          5        95.8           0      48 ## 16662          3        1.2          5        95.8           0      48 ## 16663          3        1.2          5        95.8           0      48 ## 16664          3        1.2          5        95.8           0      48 ##       h1007_6aq12 h1007_6aq13 h1007_6aq14 h1007_9 h1009_9 h1009_6aq4 h10_inc1 ## 16659        13.7        32.6         1.5     825     500        800        1 ## 16660        13.7        32.6         1.5     825     500        800        2 ## 16661        13.7        32.6         1.5     825     500        800        3 ## 16662        13.7        32.6         1.5     825     500        800        4 ## 16663        13.7        32.6         1.5     825     500        800        5 ## 16664        13.7        32.6         1.5     825     500        800        6 ##       h10_inc2_1 h10_inc2_2 h10_inc3_1 h10_inc3_2 h10_inc4_1 h10_inc4_2 ## 16659          0         NA          0         NA          1         12 ## 16660          0         NA          0         NA          0         NA ## 16661          1         12          0         NA          0         NA ## 16662          0         NA          1          7          0         NA ## 16663          0         NA          0         NA          0         NA ## 16664         NA         NA         NA         NA         NA         NA ##       h10_inc5_1 h10_inc5_2 h10_inc6_1 h10_inc6_2 h10_inc7_1 h10_inc7_2 ## 16659          0         NA          0         NA          0         NA ## 16660          0         NA          0         NA          1         12 ## 16661          0         NA          0         NA          0         NA ## 16662          0         NA          0         NA          1          5 ## 16663          0         NA          0         NA          1         12 ## 16664         NA         NA         NA         NA         NA         NA ##       h1008_106 h1008_107 h1008_108 h1008_109 h1008_110 h1008_111 h10_inc2_3 ## 16659         1         1         1         0         0         3          1 ## 16660         1         1         1         0         0         3          2 ## 16661         1         1         1         0         0         3          3 ## 16662         1         1         1         0         0         3          4 ## 16663         1         1         1         0         0         3          5 ## 16664         1         1         1         0         0         3          6 ##       h10_inc2 h10_inc3_6 h10_inc3 h10_inc4_7 h10_inc4 h10_inc4_8 h10_inc4_9 ## 16659       NA          1       NA          1     7163          1       7163 ## 16660       NA          2       NA          2       NA          2         NA ## 16661     3630          3       NA          3       NA          3         NA ## 16662       NA          4      700          4       NA          4         NA ## 16663       NA          5       NA          5       NA          5         NA ## 16664       NA          6       NA          6       NA          6         NA ##       h1008_155 h1008_156 h1008_157 h1008_158 h1008_160 h1008_159 h1008_3aq3 ## 16659        NA        NA        NA        NA        NA        NA         NA ## 16660        NA        NA        NA        NA        NA        NA         NA ## 16661        NA        NA        NA        NA        NA        NA         NA ## 16662        NA        NA        NA        NA        NA        NA         NA ## 16663        NA        NA        NA        NA        NA        NA         NA ## 16664        NA        NA        NA        NA        NA        NA         NA ##       h1008_161 h1008_162 h1008_163 h1008_164 h1008_166 h1008_165 h1008_3aq4 ## 16659        NA        NA        NA        NA        NA        NA         NA ## 16660        NA        NA        NA        NA        NA        NA         NA ## 16661        NA        NA        NA        NA        NA        NA         NA ## 16662        NA        NA        NA        NA        NA        NA         NA ## 16663        NA        NA        NA        NA        NA        NA         NA ## 16664        NA        NA        NA        NA        NA        NA         NA ##       h1008_167 h1008_168 h1008_169 h1008_170 h10_inc7_3 h10_inc7 h1008_aq9 ## 16659        NA        NA        NA        NA          1        0         0 ## 16660        NA        NA        NA        NA          2        0         0 ## 16661        NA        NA        NA        NA          3        0         0 ## 16662        NA        NA        NA        NA          4        0         0 ## 16663        NA        NA        NA        NA          5        0         0 ## 16664        NA        NA        NA        NA          6        0         0 ##       h1008_aq10 h1008_aq11 h1008_aq12 h1008_aq13 h1008_aq14 h1008_aq15 ## 16659          0          0          0          0          0          0 ## 16660          0          0          0          0          0          0 ## 16661          0          0          0          0          0          0 ## 16662          0          0          0          0          0          0 ## 16663          0          0          0          0          0          0 ## 16664          0          0          0          0          0          0 ##       h1008_6aq1 h1008_aq16 h1008_aq17 h1008_10aq1 h1008_aq19 h1008_aq20 ## 16659          0          0          0           0          0          0 ## 16660          0          0          0           0          0          0 ## 16661          0          0          0           0          0          0 ## 16662          0          0          0           0          0          0 ## 16663          0          0          0           0          0          0 ## 16664          0          0          0           0          0          0 ##       h1008_aq21 h1008_5aq3 h1008_7aq1 h1008_aq22 h1008_7aq2 h1008_aq23 ## 16659          0          0          0          0          0          0 ## 16660          0          0          0          0          0          0 ## 16661          0          0          0          0          0          0 ## 16662          0          0          0          0          0          0 ## 16663          0          0          0          0          0          0 ## 16664          0          0          0          0          0          0 ##       h1008_aq24 h1008_4aq116 h1008_4aq117 h1008_5aq1 h1008_7aq4 h1008_7aq5 ## 16659          0            0            0          0          0          0 ## 16660          0            0            0          0          0          0 ## 16661          0            0            0          0          0          0 ## 16662          0            0            0          0          0          0 ## 16663          0            0            0          0          0          0 ## 16664          0            0            0          0          0          0 ##       h1008_7aq6 h1008_7aq7 h1008_7aq8 h1008_7aq9 h1008_aq25 h1008_7aq10 ## 16659          0          0          0          0          0           0 ## 16660          0          0          0          0          0           0 ## 16661          0          0          0          0          0           0 ## 16662          0          0          0          0          0           0 ## 16663          0          0          0          0          0           0 ## 16664          0          0          0          0          0           0 ##       h1008_aq26 h1008_aq27 h1008_aq28 h1008_aq29 h1008_3aq5 h1008_4aq118 ## 16659          0          0          0          0          0            0 ## 16660          0          0          0          0          0            0 ## 16661          0          0          0          0          0            0 ## 16662          0          0          0          0          0            0 ## 16663          0          0          0          0          0            0 ## 16664          0          0          0          0          0            0 ##       h1008_aq30 h1008_6aq3 h1008_3aq6 h1008_3aq7 nh1008_3aq1 h1008_aq32 ## 16659          4          0          0          0          NA          0 ## 16660          4          0          0          0          NA          0 ## 16661          4          0          0          0          NA          0 ## 16662          4          0          0          0          NA          0 ## 16663          4          0          0          0          NA          0 ## 16664          4          0          0          0          NA          0 ##       h1008_aq33 h1008_aq34 h1008_3aq8 h1008_195 h1008_7aq11 h1009_aq1 ## 16659          0        107          0         0           0      3000 ## 16660          0        107          0         0           0      3000 ## 16661          0        107          0         0           0      3000 ## 16662          0        107          0         0           0      3000 ## 16663          0        107          0         0           0      3000 ## 16664          0        107          0         0           0      3000 ##       h1009_aq2 h1009_aq3 h1009_aq4 h1009_aq5 h1009_aq6 h1009_aq7 h1009_aq8 ## 16659         0         0      5000         0         0         0       300 ## 16660         0         0      5000         0         0         0       300 ## 16661         0         0      5000         0         0         0       300 ## 16662         0         0      5000         0         0         0       300 ## 16663         0         0      5000         0         0         0       300 ## 16664         0         0      5000         0         0         0       300 ##       h1010_aq1 h1010_aq2 h1010_aq3 h1010_aq4 h1010_aq5 h1010_aq6 h1010_aq7 ## 16659     12000         0         0         0         0       500         0 ## 16660     12000         0         0         0         0       500         0 ## 16661     12000         0         0         0         0       500         0 ## 16662     12000         0         0         0         0       500         0 ## 16663     12000         0         0         0         0       500         0 ## 16664     12000         0         0         0         0       500         0 ##       h1010_aq8 h1010_aq9 h1010_aq10 h1010_aq11 h1010_aq12 h1010_aq13 ## 16659         0         0          0          0          0          0 ## 16660         0         0          0          0          0          0 ## 16661         0         0          0          0          0          0 ## 16662         0         0          0          0          0          0 ## 16663         0         0          0          0          0          0 ## 16664         0         0          0          0          0          0 ##       h1010_aq14 h1010_aq15 h1010_aq16 h1010_aq17 h1010_aq18 h1010_aq19 ## 16659          0          0          0          0          0          0 ## 16660          0          0          0          0          0          0 ## 16661          0          0          0          0          0          0 ## 16662          0          0          0          0          0          0 ## 16663          0          0          0          0          0          0 ## 16664          0          0          0          0          0          0 ##       h1010_aq20 h1010_26 h1010_27 h1010_aq23 h1010_aq24 h1010_aq25 h1010_aq26 ## 16659          0        2      250          0       6000          0          0 ## 16660          0        2      250          0       6000          0          0 ## 16661          0        2      250          0       6000          0          0 ## 16662          0        2      250          0       6000          0          0 ## 16663          0        2      250          0       6000          0          0 ## 16664          0        2      250          0       6000          0          0 ##       h1011_2 h1011_3 h1011_4 h1011_5 h1011_6 h1011_7 h1011_8 h1011_3aq1 ## 16659       2       2       2       2       2       2       2          2 ## 16660       2       2       2       2       2       2       2          2 ## 16661       2       2       2       2       2       2       2          2 ## 16662       2       2       2       2       2       2       2          2 ## 16663       2       2       2       2       2       2       2          2 ## 16664       2       2       2       2       2       2       2          2 ##       h1011_3aq2 h1011_3aq3 h1011_3aq4 h1011_3aq5 h1011_3aq6 h1011_3aq7 h1012_1 ## 16659          3          3          2         NA          2          2       2 ## 16660          3          3          2         NA          2          2       2 ## 16661          3          3          2         NA          2          2       2 ## 16662          3          3          2         NA          2          2       2 ## 16663          3          3          2         NA          2          2       2 ## 16664          3          3          2         NA          2          2       2 ##       nh1012_1 h1012_2 h1012_3 h1012_4 h1012_5 h1012_6 h1012_7 nh1012_7 ## 16659       NA      NA      NA      NA      NA      NA       1       NA ## 16660       NA      NA      NA      NA      NA      NA       1       NA ## 16661       NA      NA      NA      NA      NA      NA       1       NA ## 16662       NA      NA      NA      NA      NA      NA       1       NA ## 16663       NA      NA      NA      NA      NA      NA       1       NA ## 16664       NA      NA      NA      NA      NA      NA       1       NA ##       nh1012_8 h1012_9 h1012_10 h1012_11 h1012_12 h1012_13 h1012_14 h1012_15 ## 16659       NA      NA       NA       NA       NA       NA       NA       NA ## 16660       NA      NA       NA       NA       NA       NA       NA       NA ## 16661       NA      NA       NA       NA       NA       NA       NA       NA ## 16662       NA      NA       NA       NA       NA       NA       NA       NA ## 16663       NA      NA       NA       NA       NA       NA       NA       NA ## 16664       NA      NA       NA       NA       NA       NA       NA       NA ##       h1012_3aq1 h1012_16 h1012_17 h1012_18 h1012_19 h1012_1_4aq1 h1012_1_5aq1 ## 16659         NA       NA       NA       NA       NA            2            2 ## 16660         NA       NA       NA       NA       NA            2            2 ## 16661         NA       NA       NA       NA       NA            2            2 ## 16662         NA       NA       NA       NA       NA            2            2 ## 16663         NA       NA       NA       NA       NA            2            2 ## 16664         NA       NA       NA       NA       NA            2            2 ##       h1012_1_5aq2 h1012_1_5aq3 h1012_1_5aq4 h1012_1_5aq5 h1012_1_4aq2 ## 16659           NA           NA           NA           NA            1 ## 16660           NA           NA           NA           NA            1 ## 16661           NA           NA           NA           NA            1 ## 16662           NA           NA           NA           NA            1 ## 16663           NA           NA           NA           NA            1 ## 16664           NA           NA           NA           NA            1 ##       h1012_1_4aq3 h1013_2 h1013_6 h1013_10 h1013_14 h1013_18 h1013_22 h1013_26 ## 16659            2       2       2        2        2        2        2        2 ## 16660            2       2       2        2        2        2        2        2 ## 16661            2       2       2        2        2        2        2        2 ## 16662            2       2       2        2        2        2        2        2 ## 16663            2       2       2        2        2        2        2        2 ## 16664            2       2       2        2        2        2        2        2 ##       h1013_8aq1 h1013_5aq1 h1013_8aq2 h1013_4aq1 h1013_4aq2 h1013_4aq4 ## 16659          2          2          2          2         NA         NA ## 16660          2          2          2          2         NA         NA ## 16661          2          2          2          2         NA         NA ## 16662          2          2          2          2         NA         NA ## 16663          2          2          2          2         NA         NA ## 16664          2          2          2          2         NA         NA ##       h1013_4aq6 h1013_4aq8 h1013_4aq10 h1013_5aq4 h1013_5aq6 h1013_5aq8 ## 16659         NA         NA          NA         NA         NA         NA ## 16660         NA         NA          NA         NA         NA         NA ## 16661         NA         NA          NA         NA         NA         NA ## 16662         NA         NA          NA         NA         NA         NA ## 16663         NA         NA          NA         NA         NA         NA ## 16664         NA         NA          NA         NA         NA         NA ##       h1013_6aq1 h1013_4aq14 ## 16659         NA          NA ## 16660         NA          NA ## 16661         NA          NA ## 16662         NA          NA ## 16663         NA          NA ## 16664         NA          NA ##                                                                                                                                                                                                                                                           h1013_4aq15 ## 16659 .                                                                                                                                                                                                                                                               ## 16660 .                                                                                                                                                                                                                                                               ## 16661 .                                                                                                                                                                                                                                                               ## 16662 .                                                                                                                                                                                                                                                               ## 16663 .                                                                                                                                                                                                                                                               ## 16664 .                                                                                                                                                                                                                                                               ##       h1013_4aq16 h1013_4aq17 h1013_4aq18 h1013_4aq20 h1013_4aq22 h1013_4aq24 ## 16659           2          NA          NA          NA          NA          NA ## 16660           2          NA          NA          NA          NA          NA ## 16661           2          NA          NA          NA          NA          NA ## 16662           2          NA          NA          NA          NA          NA ## 16663           2          NA          NA          NA          NA          NA ## 16664           2          NA          NA          NA          NA          NA ##       h1013_4aq26 h1013_4aq28 h1013_4aq30 h1013_4aq32 h1014_4 h1014_8 h1014_12 ## 16659          NA          NA          NA          NA      NA      NA       NA ## 16660          NA          NA          NA          NA      NA      NA       NA ## 16661          NA          NA          NA          NA      NA      NA       NA ## 16662          NA          NA          NA          NA      NA      NA       NA ## 16663          NA          NA          NA          NA      NA      NA       NA ## 16664          NA          NA          NA          NA      NA      NA       NA ##       h1014_16 h1014_20 h1014_24 h1014_28 h1014_32 h1014_36 h1014_3aq1 ## 16659       NA       NA       NA       NA       NA       NA         NA ## 16660       NA       NA       NA       NA       NA       NA         NA ## 16661       NA       NA       NA       NA       NA       NA         NA ## 16662       NA       NA       NA       NA       NA       NA         NA ## 16663       NA       NA       NA       NA       NA       NA         NA ## 16664       NA       NA       NA       NA       NA       NA         NA ##       h1014_4aq1 h1015_4 h1015_8 h1015_12 h1015_20 h1015_25 h1015_29 h1015_33 ## 16659         NA       2       2        2        2        1        1        2 ## 16660         NA       2       2        2        2        1        1        2 ## 16661         NA       2       2        2        2        1        1        2 ## 16662         NA       2       2        2        2        1        1        2 ## 16663         NA       2       2        2        2        1        1        2 ## 16664         NA       2       2        2        2        1        1        2 ##       h1015_37 h1015_4aq1 h1015_7aq1 h1015_aq1 h1015_40 h1015_41 h1015_42 ## 16659        2          2          2         2       NA       NA       NA ## 16660        2          2          2         2       NA       NA       NA ## 16661        2          2          2         2       NA       NA       NA ## 16662        2          2          2         2       NA       NA       NA ## 16663        2          2          2         2       NA       NA       NA ## 16664        2          2          2         2       NA       NA       NA ##       h1015_43 h1015_44 h1015_45 h1015_46 h1015_47 h1015_48 h1015_49 h1015_50 ## 16659       NA       NA       NA       NA       NA       NA       NA       NA ## 16660       NA       NA       NA       NA       NA       NA       NA       NA ## 16661       NA       NA       NA       NA       NA       NA       NA       NA ## 16662       NA       NA       NA       NA       NA       NA       NA       NA ## 16663       NA       NA       NA       NA       NA       NA       NA       NA ## 16664       NA       NA       NA       NA       NA       NA       NA       NA ##       h1015_51 h1015_52 h1015_53 h1015_54 h1015_55 h1015_56 h1015_57 h1015_60 ## 16659       NA       NA       NA       NA       NA       NA       NA        5 ## 16660       NA       NA       NA       NA       NA       NA       NA        5 ## 16661       NA       NA       NA       NA       NA       NA       NA        5 ## 16662       NA       NA       NA       NA       NA       NA       NA        5 ## 16663       NA       NA       NA       NA       NA       NA       NA        5 ## 16664       NA       NA       NA       NA       NA       NA       NA        5 ##       h1015_aq2 h1015_61 h1015_62 h1015_63 h1015_66 h1015_67 h1015_68 h1015_aq3 ## 16659         2       NA       NA       NA       NA       NA        6         2 ## 16660         2       NA       NA       NA       NA       NA        6         2 ## 16661         2       NA       NA       NA       NA       NA        6         2 ## 16662         2       NA       NA       NA       NA       NA        6         2 ## 16663         2       NA       NA       NA       NA       NA        6         2 ## 16664         2       NA       NA       NA       NA       NA        6         2 ##       h1015_69 h1015_70 h1015_71 h1015_74 h1015_75 h1015_76 h1015_aq4 h1015_77 ## 16659       NA       NA       NA       NA       NA       NA        NA       NA ## 16660       NA       NA       NA       NA       NA       NA        NA       NA ## 16661       NA       NA       NA       NA       NA       NA        NA       NA ## 16662       NA       NA       NA       NA       NA       NA        NA       NA ## 16663       NA       NA       NA       NA       NA       NA        NA       NA ## 16664       NA       NA       NA       NA       NA       NA        NA       NA ##       h1015_78 h1015_79 h1015_82 h1015_83 h1015_84 h1015_aq5 h1015_85 h1015_86 ## 16659       NA       NA       NA       NA       NA        NA       NA       NA ## 16660       NA       NA       NA       NA       NA        NA       NA       NA ## 16661       NA       NA       NA       NA       NA        NA       NA       NA ## 16662       NA       NA       NA       NA       NA        NA       NA       NA ## 16663       NA       NA       NA       NA       NA        NA       NA       NA ## 16664       NA       NA       NA       NA       NA        NA       NA       NA ##       h1015_87 h1015_90 h1015_91 h1015_92 h1015_aq6 h1015_93 h1015_94 h1015_95 ## 16659       NA       NA       NA       NA        NA       NA       NA       NA ## 16660       NA       NA       NA       NA        NA       NA       NA       NA ## 16661       NA       NA       NA       NA        NA       NA       NA       NA ## 16662       NA       NA       NA       NA        NA       NA       NA       NA ## 16663       NA       NA       NA       NA        NA       NA       NA       NA ## 16664       NA       NA       NA       NA        NA       NA       NA       NA ##       h1015_98 h1015_99 h1015_100 h1015_aq7 h1015_101 h1015_102 h1015_103 ## 16659       NA       NA        NA        NA        NA        NA        NA ## 16660       NA       NA        NA        NA        NA        NA        NA ## 16661       NA       NA        NA        NA        NA        NA        NA ## 16662       NA       NA        NA        NA        NA        NA        NA ## 16663       NA       NA        NA        NA        NA        NA        NA ## 16664       NA       NA        NA        NA        NA        NA        NA ##       h1015_106 h1015_107 h1016_6aq1 h1016_6aq4 h1016_8 h1016_24 h1016_4aq1 ## 16659        NA        NA         NA         NA      NA       NA         NA ## 16660        NA        NA         NA         NA      NA       NA         NA ## 16661        NA        NA         NA         NA      NA       NA         NA ## 16662        NA        NA         NA         NA      NA       NA         NA ## 16663        NA        NA         NA         NA      NA       NA         NA ## 16664        NA        NA         NA         NA      NA       NA         NA ##       h1016_4aq4 h1016_32 h1016_36 h1016_40 h1016_4aq7 h1016_56 h1016_60 ## 16659         NA       NA       NA       NA         NA       NA       NA ## 16660         NA       NA       NA       NA         NA       NA       NA ## 16661         NA       NA       NA       NA         NA       NA       NA ## 16662         NA       NA       NA       NA         NA       NA       NA ## 16663         NA       NA       NA       NA         NA       NA       NA ## 16664         NA       NA       NA       NA         NA       NA       NA ##       h1016_64 h1017_1 h1017_2 h1017_3 h1017_4 h1017_5 h1017_6 h1017_7 p10_fnum ## 16659       NA       0      NA       2       1       4       1       1        1 ## 16660       NA       0      NA       2       1       4       1       1        2 ## 16661       NA       0      NA       2       1       4       1       1        3 ## 16662       NA       0      NA       2       1       4       1       1        4 ## 16663       NA       0      NA       2       1       4       1       1       NA ## 16664       NA       0      NA       2       1       4       1       1       NA ##       p10_tq p10_cp p1001_1 p1001_2 p1001_aq1 p1001_3 p1001_4 p1001_5 p1001_6 ## 16659      3      1       2      NA        NA      NA      NA      NA      NA ## 16660      3      1       2      NA        NA      NA      NA      NA      NA ## 16661      3      1       2      NA        NA      NA      NA      NA      NA ## 16662      4      1       2      NA        NA      NA      NA      NA      NA ## 16663     NA     NA      NA      NA        NA      NA      NA      NA      NA ## 16664     NA     NA      NA      NA        NA      NA      NA      NA      NA ##       p1001_10 p1001_11 p1001_12 p1001_13 p1001_14 p1001_7 p1001_8 p1001_9 ## 16659       NA       NA       NA       NA       NA      NA      NA      NA ## 16660       NA       NA       NA       NA       NA      NA      NA      NA ## 16661       NA       NA       NA       NA       NA      NA      NA      NA ## 16662       NA       NA       NA       NA       NA      NA      NA      NA ## 16663       NA       NA       NA       NA       NA      NA      NA      NA ## 16664       NA       NA       NA       NA       NA      NA      NA      NA ##       p1001_15 p1001_16 p1001_17 p1001_18 p1001_19 p1001_20 p1001_21 p1001_22 ## 16659        2       NA       NA       NA       NA        2       NA       NA ## 16660        2       NA       NA       NA       NA        2       NA       NA ## 16661        2       NA       NA       NA       NA        2       NA       NA ## 16662        2       NA       NA       NA       NA        2       NA       NA ## 16663       NA       NA       NA       NA       NA       NA       NA       NA ## 16664       NA       NA       NA       NA       NA       NA       NA       NA ##       p1001_23 p1001_24 p1001_25 p1001_27 p1001_28 p1001_29 p1001_30 p1001_31 ## 16659       NA       NA       NA        2       NA       NA       NA        2 ## 16660       NA       NA       NA        2       NA       NA       NA        2 ## 16661       NA       NA       NA        2       NA       NA       NA        2 ## 16662       NA       NA       NA        2       NA       NA       NA        2 ## 16663       NA       NA       NA       NA       NA       NA       NA       NA ## 16664       NA       NA       NA       NA       NA       NA       NA       NA ##       p1001_32 p1001_33 p1001_34 p1002_1 p1002_2 p1002_3 p1002_4 p1002_5 ## 16659       NA       NA       NA       2       2      NA    2003       1 ## 16660       NA       NA       NA       4      NA      NA      NA      NA ## 16661       NA       NA       NA       1       2      NA    2009      11 ## 16662       NA       NA       NA       4      NA      NA      NA      NA ## 16663       NA       NA       NA      NA      NA      NA      NA      NA ## 16664       NA       NA       NA      NA      NA      NA      NA      NA ##       p1002_6 p1002_7 p1002_8 p1002_8aq1 p1002_9 p1002_8aq2 p1002_4aq1 p1002_10 ## 16659      12      25      NA         NA      10         NA         NA       NA ## 16660      NA      NA      NA         NA      NA         NA         NA        2 ## 16661      12      20      40      302.5      NA         NA          1       NA ## 16662      NA      NA      NA         NA      NA         NA         NA        2 ## 16663      NA      NA      NA         NA      NA         NA         NA       NA ## 16664      NA      NA      NA         NA      NA         NA         NA       NA ##       p1002_11 p1002_12 p1002_8aq3 p1002_8aq4 p1002_31 p1002_4aq2 p1002_4aq3 ## 16659       NA       NA         NA         NA       NA         NA         NA ## 16660       NA       NA         NA         NA       NA          2         NA ## 16661       NA       NA         NA         NA       NA         NA         NA ## 16662       NA       NA         NA         NA       NA          1          2 ## 16663       NA       NA         NA         NA       NA         NA         NA ## 16664       NA       NA         NA         NA       NA         NA         NA ##       p1002_4aq4 p1002_8aq5 p1002_8aq6 p1002_8aq7 p1002_8aq8 p1002_8aq9 ## 16659         NA          0          0          0          0          0 ## 16660         NA          0          0          0          0          0 ## 16661         NA          0          0          0          0          0 ## 16662         NA          0          0          0          0          0 ## 16663         NA         NA         NA         NA         NA         NA ## 16664         NA         NA         NA         NA         NA         NA ##       p1002_8aq10 p1002_8aq11 p1002_8aq12 p1002_8aq13 p1002_8aq14 p1002_8aq15 ## 16659           0           0           0           0           0           0 ## 16660           0           0           0           0           0           0 ## 16661           0           0           0           0           0           0 ## 16662           0           0           0           0           0           0 ## 16663          NA          NA          NA          NA          NA          NA ## 16664          NA          NA          NA          NA          NA          NA ##       p1002_aq2 p1002_aq3 p1002_aq4 p1002_aq5 p1003_1 p1003_2 p1003_5 p1003_6 ## 16659         0        NA        NA        NA       1       2       4       3 ## 16660         0        NA        NA        NA       1       0       4       3 ## 16661         0        NA        NA        NA       1       2       4       4 ## 16662        NA        NA        NA        NA       1       2       4       3 ## 16663        NA        NA        NA        NA      NA      NA      NA      NA ## 16664        NA        NA        NA        NA      NA      NA      NA      NA ##       p1003_7 p1003_8 p1003_9 p1003_10 p1003_11 p1003_12 p1004_1 p1004_2 ## 16659       4       4       4        4        4        4       1       4 ## 16660       4       4       4        4        4        4       1       4 ## 16661       4       4       3        4        4        4       1       4 ## 16662       4       4       2        4        4        4       1       4 ## 16663      NA      NA      NA       NA       NA       NA      NA      NA ## 16664      NA      NA      NA       NA       NA       NA      NA      NA ##       p1004_3 p1004_4 p1004_5 p1004_6 p1004_7 p1004_8 p1004_9 p1004_10 p1004_11 ## 16659       2       2      NA      NA       1      NA       1       NA        2 ## 16660       2       2      NA      NA       1      NA      NA        4        7 ## 16661       2       2      NA      NA       2      NA      NA       NA       NA ## 16662       2       2      NA      NA       2      NA      NA       NA       NA ## 16663      NA      NA      NA      NA      NA      NA      NA       NA       NA ## 16664      NA      NA      NA      NA      NA      NA      NA       NA       NA ##       p1004_12 p1004_13 p1004_3aq1 p1004_3aq2 p1004_3aq3 p1004_3aq4 p1004_3aq5 ## 16659       NA       NA          4          4          4          4          2 ## 16660       NA       NA          4          4          3          3          3 ## 16661       NA       NA          4          4          2          2          4 ## 16662       NA       NA          4          4          2          2          4 ## 16663       NA       NA         NA         NA         NA         NA         NA ## 16664       NA       NA         NA         NA         NA         NA         NA ##       p1004_3aq6 p1004_3aq7 p1004_3aq8 p1005_3aq1 p1005_3aq2 p1005_3aq3 ## 16659          3          2          2         NA         NA         NA ## 16660          4          2          2         NA         NA         NA ## 16661          2          2          2         NA         NA         NA ## 16662          2          2          2          3         NA         NA ## 16663         NA         NA         NA         NA         NA         NA ## 16664         NA         NA         NA         NA         NA         NA ##       p1005_3aq4 p1005_3aq5 p1005_3aq6 p1005_3aq7 p1005_3aq8 p1005_3aq9 ## 16659         NA          2         NA         NA         NA          1 ## 16660         NA          2         NA         NA         NA          1 ## 16661         NA          2         NA         NA         NA          1 ## 16662         NA          2         NA         NA         NA          1 ## 16663         NA         NA         NA         NA         NA         NA ## 16664         NA         NA         NA         NA         NA         NA ##       p1005_3aq10 p1005_2 p1005_3 p1005_4aq1 p1005_4aq2 p1005_4aq3 p1005_4aq4 ## 16659          NA       3       5          4          1          1          1 ## 16660          NA       2       2          1          1          1          1 ## 16661          NA       2       4          3          1          1          1 ## 16662          NA       2       4          3          1          1          1 ## 16663          NA      NA      NA         NA         NA         NA         NA ## 16664          NA      NA      NA         NA         NA         NA         NA ##       p1005_4aq5 p1005_4aq6 p1005_4aq7 p1005_4aq8 p1005_5 p1005_6 p1005_7 ## 16659          1          1          1          1       2       2       2 ## 16660          1          1          1          1       2       2       2 ## 16661          1          1          1          1       2       2       2 ## 16662          1          1          1          1       2       2       2 ## 16663         NA         NA         NA         NA      NA      NA      NA ## 16664         NA         NA         NA         NA      NA      NA      NA ##       p1005_8 p1005_3aq11 p1005_9 p1005_10 p1005_11 p1005_12 p1005_13 p1005_14 ## 16659       2           0       1        4        1        1        1        1 ## 16660       2           2       1        4        1        1        1        1 ## 16661       2           2       1        4        1        1        1        1 ## 16662       2           0       1        4        1        1        1        1 ## 16663      NA          NA      NA       NA       NA       NA       NA       NA ## 16664      NA          NA      NA       NA       NA       NA       NA       NA ##       p1005_15 p1005_16 p1005_17 p1005_18 p1005_19 p1005_20 p1005_21 p1005_22 ## 16659        4        1        1        1        1        3        3        1 ## 16660        4        1        1        1        1        3        3        1 ## 16661        4        1        1        1        1        3        3        1 ## 16662        4        1        1        1        1        3        3        1 ## 16663       NA       NA       NA       NA       NA       NA       NA       NA ## 16664       NA       NA       NA       NA       NA       NA       NA       NA ##       p1005_23 p1005_24 p1005_25 p1005_26 p1005_27 p1005_28 p1005_29 p1005_4aq9 ## 16659        4        1        3        3        1        1        1          1 ## 16660        4        1        4        4        1        1        1          1 ## 16661        3        1        4        4        1        1        1          0 ## 16662        3        1        3        3        1        1        1          0 ## 16663       NA       NA       NA       NA       NA       NA       NA         NA ## 16664       NA       NA       NA       NA       NA       NA       NA         NA ##       p1005_4aq10 p1005_4aq11 p1005_aq1 p1005_aq2 p1005_aq3 p1005_aq4 ## 16659           1           1         6         6         6         6 ## 16660           1           1         6         6         6         6 ## 16661           0           0         6         0         0         0 ## 16662           0           0         6         0         0         0 ## 16663          NA          NA        NA        NA        NA        NA ## 16664          NA          NA        NA        NA        NA        NA ##       p1005_6aq1 p1005_6aq2 p1005_6aq3 p1005_6aq4 p1005_6aq5 p1005_6aq6 ## 16659         NA         NA         NA         NA         NA         NA ## 16660         NA         NA         NA         NA         NA         NA ## 16661         NA         NA         NA         NA         NA         NA ## 16662          2         NA         NA          2         NA         NA ## 16663         NA         NA         NA         NA         NA         NA ## 16664         NA         NA         NA         NA         NA         NA ##       p1005_6aq7 p1005_6aq8 p1005_6aq9 p1005_7aq1 p1005_7aq2 p1005_7aq3 ## 16659         NA         NA         NA          2          2          2 ## 16660         NA         NA         NA          2          2          2 ## 16661         NA         NA         NA          2          2          2 ## 16662          2         NA         NA         NA         NA         NA ## 16663         NA         NA         NA         NA         NA         NA ## 16664         NA         NA         NA         NA         NA         NA ##       p1007_3aq1 p1007_3aq2 p1007_3aq3 p1007_3aq4 p1007_3aq5 p1007_3aq6 ## 16659         NA         NA         NA         NA         NA         NA ## 16660         NA         NA         NA         NA         NA         NA ## 16661         NA         NA         NA         NA         NA         NA ## 16662          2         12         33      33310         NA         NA ## 16663         NA         NA         NA         NA         NA         NA ## 16664         NA         NA         NA         NA         NA         NA ##       p1007_3aq7 np1006_1 np1006_2 np1006_3 np1006_4 np1006_5 np1006_6 np1006_7 ## 16659         NA       NA       NA       NA       NA       NA       NA       NA ## 16660         NA       NA       NA       NA       NA       NA       NA       NA ## 16661         NA       NA       NA       NA       NA       NA       NA       NA ## 16662         NA        2        3        1     2014     2014        1     2014 ## 16663         NA       NA       NA       NA       NA       NA       NA       NA ## 16664         NA       NA       NA       NA       NA       NA       NA       NA ##       np1006_8 np1006_9 np1006_10 np1006_11 np1006_12 np1006_13 np1006_14 ## 16659       NA       NA        NA        NA        NA        NA        NA ## 16660       NA       NA        NA        NA        NA        NA        NA ## 16661       NA       NA        NA        NA        NA        NA        NA ## 16662     2014        1        88        88        88        88        88 ## 16663       NA       NA        NA        NA        NA        NA        NA ## 16664       NA       NA        NA        NA        NA        NA        NA ##       np1006_15 np1006_16 np1006_17 np1006_18 np1006_19 np1006_20 np1006_21 ## 16659        NA        NA        NA        NA        NA        NA        NA ## 16660        NA        NA        NA        NA        NA        NA        NA ## 16661        NA        NA        NA        NA        NA        NA        NA ## 16662        88        88        88        88        88        88        88 ## 16663        NA        NA        NA        NA        NA        NA        NA ## 16664        NA        NA        NA        NA        NA        NA        NA ##       np1006_22 np1006_23 np1006_24 np1006_25 np1006_26 np1006_27 np1006_28 ## 16659        NA        NA        NA        NA        NA        NA        NA ## 16660        NA        NA        NA        NA        NA        NA        NA ## 16661        NA        NA        NA        NA        NA        NA        NA ## 16662        88        88        88         0        NA        NA        NA ## 16663        NA        NA        NA        NA        NA        NA        NA ## 16664        NA        NA        NA        NA        NA        NA        NA ##       np1006_29 np1006_30 np1006_31 np1006_32 np1006_33 np1006_34 np1006_35 ## 16659        NA        NA        NA        NA        NA        NA        NA ## 16660        NA        NA        NA        NA        NA        NA        NA ## 16661        NA        NA        NA        NA        NA        NA        NA ## 16662        NA        NA         1        NA         1        NA         1 ## 16663        NA        NA        NA        NA        NA        NA        NA ## 16664        NA        NA        NA        NA        NA        NA        NA ##       np1006_36 np1006_37 np1006_38 np1006_39 np1006_40 np1006_41 np1006_42 ## 16659        NA        NA        NA        NA        NA        NA        NA ## 16660        NA        NA        NA        NA        NA        NA        NA ## 16661        NA        NA        NA        NA        NA        NA        NA ## 16662        NA         1        NA         5         5        10        13 ## 16663        NA        NA        NA        NA        NA        NA        NA ## 16664        NA        NA        NA        NA        NA        NA        NA ##       np1006_43 np1006_44 p1006_3aq1 c10_fnum c10_cp c10_grade c1001_1 c1001_2 ## 16659        NA        NA         NA       NA     NA        NA      NA      NA ## 16660        NA        NA         NA       NA     NA        NA      NA      NA ## 16661        NA        NA         NA       NA     NA        NA      NA      NA ## 16662         2        NA          2       NA     NA        NA      NA      NA ## 16663        NA        NA         NA       NA     NA        NA      NA      NA ## 16664        NA        NA         NA       NA     NA        NA      NA      NA ##       c1001_3 c1001_4 c1001_5 c1001_6 c1001_7 c1001_8 c1001_9 c1001_10 c1001_11 ## 16659      NA      NA      NA      NA      NA      NA      NA       NA       NA ## 16660      NA      NA      NA      NA      NA      NA      NA       NA       NA ## 16661      NA      NA      NA      NA      NA      NA      NA       NA       NA ## 16662      NA      NA      NA      NA      NA      NA      NA       NA       NA ## 16663      NA      NA      NA      NA      NA      NA      NA       NA       NA ## 16664      NA      NA      NA      NA      NA      NA      NA       NA       NA ##       c1001_12 c1001_13 c1001_7aq5 c1001_7aq6 c1001_7aq7 c1001_7aq8 c1001_4aq1 ## 16659       NA       NA         NA         NA         NA         NA         NA ## 16660       NA       NA         NA         NA         NA         NA         NA ## 16661       NA       NA         NA         NA         NA         NA         NA ## 16662       NA       NA         NA         NA         NA         NA         NA ## 16663       NA       NA         NA         NA         NA         NA         NA ## 16664       NA       NA         NA         NA         NA         NA         NA ##       c1001_4aq2 c1001_4aq3 c1001_4aq4 c1001_4aq5 c1001_4aq6 c1002_1 c1002_2 ## 16659         NA         NA         NA         NA         NA      NA      NA ## 16660         NA         NA         NA         NA         NA      NA      NA ## 16661         NA         NA         NA         NA         NA      NA      NA ## 16662         NA         NA         NA         NA         NA      NA      NA ## 16663         NA         NA         NA         NA         NA      NA      NA ## 16664         NA         NA         NA         NA         NA      NA      NA ##       c1002_3 c1002_4 c1002_5 c1002_6 c1002_7 c1002_8 c1002_9 c1002_10 c1002_11 ## 16659      NA      NA      NA      NA      NA      NA      NA       NA       NA ## 16660      NA      NA      NA      NA      NA      NA      NA       NA       NA ## 16661      NA      NA      NA      NA      NA      NA      NA       NA       NA ## 16662      NA      NA      NA      NA      NA      NA      NA       NA       NA ## 16663      NA      NA      NA      NA      NA      NA      NA       NA       NA ## 16664      NA      NA      NA      NA      NA      NA      NA       NA       NA ##       c1002_12 c1002_13 c1002_14 c1002_15 c1002_16 c1002_17 c1002_18 c1002_19 ## 16659       NA       NA       NA       NA       NA       NA       NA       NA ## 16660       NA       NA       NA       NA       NA       NA       NA       NA ## 16661       NA       NA       NA       NA       NA       NA       NA       NA ## 16662       NA       NA       NA       NA       NA       NA       NA       NA ## 16663       NA       NA       NA       NA       NA       NA       NA       NA ## 16664       NA       NA       NA       NA       NA       NA       NA       NA ##       c1002_20 c1002_21 c1002_22 c1002_23 c1002_24 c1002_25 c1002_26 c1002_4aq1 ## 16659       NA       NA       NA       NA       NA       NA       NA         NA ## 16660       NA       NA       NA       NA       NA       NA       NA         NA ## 16661       NA       NA       NA       NA       NA       NA       NA         NA ## 16662       NA       NA       NA       NA       NA       NA       NA         NA ## 16663       NA       NA       NA       NA       NA       NA       NA         NA ## 16664       NA       NA       NA       NA       NA       NA       NA         NA ##       c1002_27 c1002_28 c1002_29 c1002_30 c1002_31 c1002_32 c1002_33 c1002_34 ## 16659       NA       NA       NA       NA       NA       NA       NA       NA ## 16660       NA       NA       NA       NA       NA       NA       NA       NA ## 16661       NA       NA       NA       NA       NA       NA       NA       NA ## 16662       NA       NA       NA       NA       NA       NA       NA       NA ## 16663       NA       NA       NA       NA       NA       NA       NA       NA ## 16664       NA       NA       NA       NA       NA       NA       NA       NA ##       c1002_35 c1002_36 c1002_37 c1002_38 c1002_39 c1002_40 c1002_41 c1002_42 ## 16659       NA       NA       NA       NA       NA       NA       NA       NA ## 16660       NA       NA       NA       NA       NA       NA       NA       NA ## 16661       NA       NA       NA       NA       NA       NA       NA       NA ## 16662       NA       NA       NA       NA       NA       NA       NA       NA ## 16663       NA       NA       NA       NA       NA       NA       NA       NA ## 16664       NA       NA       NA       NA       NA       NA       NA       NA ##       c1002_43 c1002_44 c1002_45 c1002_46 c1002_47 c1002_48 c1002_49 c1002_50 ## 16659       NA       NA       NA       NA       NA       NA       NA       NA ## 16660       NA       NA       NA       NA       NA       NA       NA       NA ## 16661       NA       NA       NA       NA       NA       NA       NA       NA ## 16662       NA       NA       NA       NA       NA       NA       NA       NA ## 16663       NA       NA       NA       NA       NA       NA       NA       NA ## 16664       NA       NA       NA       NA       NA       NA       NA       NA ##       c1002_51 c1002_52 c1002_53 c1002_54 c1002_55 c1002_56 c1002_57 c1002_58 ## 16659       NA       NA       NA       NA       NA       NA       NA       NA ## 16660       NA       NA       NA       NA       NA       NA       NA       NA ## 16661       NA       NA       NA       NA       NA       NA       NA       NA ## 16662       NA       NA       NA       NA       NA       NA       NA       NA ## 16663       NA       NA       NA       NA       NA       NA       NA       NA ## 16664       NA       NA       NA       NA       NA       NA       NA       NA ##       c1002_4aq2 c1002_59 c1002_60 c1002_61 c1002_62 c1002_63 c1002_64 c1002_65 ## 16659         NA       NA       NA       NA       NA       NA       NA       NA ## 16660         NA       NA       NA       NA       NA       NA       NA       NA ## 16661         NA       NA       NA       NA       NA       NA       NA       NA ## 16662         NA       NA       NA       NA       NA       NA       NA       NA ## 16663         NA       NA       NA       NA       NA       NA       NA       NA ## 16664         NA       NA       NA       NA       NA       NA       NA       NA ##       c1002_66 c1002_67 c1002_68 c1002_69 c1002_70 c1002_71 c1002_72 c1002_73 ## 16659       NA       NA       NA       NA       NA       NA       NA       NA ## 16660       NA       NA       NA       NA       NA       NA       NA       NA ## 16661       NA       NA       NA       NA       NA       NA       NA       NA ## 16662       NA       NA       NA       NA       NA       NA       NA       NA ## 16663       NA       NA       NA       NA       NA       NA       NA       NA ## 16664       NA       NA       NA       NA       NA       NA       NA       NA ##       c1002_74 c1002_75 c1002_76 c1002_77 c1002_7aq1 c1002_7aq2 c1002_7aq3 ## 16659       NA       NA       NA       NA         NA         NA         NA ## 16660       NA       NA       NA       NA         NA         NA         NA ## 16661       NA       NA       NA       NA         NA         NA         NA ## 16662       NA       NA       NA       NA         NA         NA         NA ## 16663       NA       NA       NA       NA         NA         NA         NA ## 16664       NA       NA       NA       NA         NA         NA         NA ##       c1002_7aq4 c1002_7aq5 c1002_7aq6 c1002_7aq7 c1002_7aq8 c1002_7aq9 ## 16659         NA         NA         NA         NA         NA         NA ## 16660         NA         NA         NA         NA         NA         NA ## 16661         NA         NA         NA         NA         NA         NA ## 16662         NA         NA         NA         NA         NA         NA ## 16663         NA         NA         NA         NA         NA         NA ## 16664         NA         NA         NA         NA         NA         NA ##       c1002_7aq10 c1002_7aq11 c1002_7aq12 c1002_7aq13 c1002_7aq14 c1002_78 ## 16659          NA          NA          NA          NA          NA       NA ## 16660          NA          NA          NA          NA          NA       NA ## 16661          NA          NA          NA          NA          NA       NA ## 16662          NA          NA          NA          NA          NA       NA ## 16663          NA          NA          NA          NA          NA       NA ## 16664          NA          NA          NA          NA          NA       NA ##       c1002_79 c1002_80 c1002_81 c1002_82 c1002_83 c1002_84 c1002_85 c1002_86 ## 16659       NA       NA       NA       NA       NA       NA       NA       NA ## 16660       NA       NA       NA       NA       NA       NA       NA       NA ## 16661       NA       NA       NA       NA       NA       NA       NA       NA ## 16662       NA       NA       NA       NA       NA       NA       NA       NA ## 16663       NA       NA       NA       NA       NA       NA       NA       NA ## 16664       NA       NA       NA       NA       NA       NA       NA       NA ##       c1002_87 c1002_88 c1002_89 c1002_90 c1002_91 c1002_92 c1002_93 c1002_94 ## 16659       NA       NA       NA       NA       NA       NA       NA       NA ## 16660       NA       NA       NA       NA       NA       NA       NA       NA ## 16661       NA       NA       NA       NA       NA       NA       NA       NA ## 16662       NA       NA       NA       NA       NA       NA       NA       NA ## 16663       NA       NA       NA       NA       NA       NA       NA       NA ## 16664       NA       NA       NA       NA       NA       NA       NA       NA ##       c1002_95 c1002_96 c1002_97 c1002_98 c1002_4aq3 c1002_4aq4 c1002_4aq5 ## 16659       NA       NA       NA       NA         NA         NA         NA ## 16660       NA       NA       NA       NA         NA         NA         NA ## 16661       NA       NA       NA       NA         NA         NA         NA ## 16662       NA       NA       NA       NA         NA         NA         NA ## 16663       NA       NA       NA       NA         NA         NA         NA ## 16664       NA       NA       NA       NA         NA         NA         NA ##       c1002_4aq6 c1002_4aq7 c1002_4aq8 c1002_7aq15 c1003_4aq1 c1003_4aq2 ## 16659         NA         NA         NA          NA         NA         NA ## 16660         NA         NA         NA          NA         NA         NA ## 16661         NA         NA         NA          NA         NA         NA ## 16662         NA         NA         NA          NA         NA         NA ## 16663         NA         NA         NA          NA         NA         NA ## 16664         NA         NA         NA          NA         NA         NA ##       c1003_4aq3 c1003_4aq4 c1003_4aq5 c1003_4aq6 c1003_4aq7 c1003_4aq8 ## 16659         NA         NA         NA         NA         NA         NA ## 16660         NA         NA         NA         NA         NA         NA ## 16661         NA         NA         NA         NA         NA         NA ## 16662         NA         NA         NA         NA         NA         NA ## 16663         NA         NA         NA         NA         NA         NA ## 16664         NA         NA         NA         NA         NA         NA ##       c1003_4aq9 c1003_6 c1003_7 c1003_8 c1003_9 c1003_13 c1003_14 c1003_15 ## 16659         NA      NA      NA      NA      NA       NA       NA       NA ## 16660         NA      NA      NA      NA      NA       NA       NA       NA ## 16661         NA      NA      NA      NA      NA       NA       NA       NA ## 16662         NA      NA      NA      NA      NA       NA       NA       NA ## 16663         NA      NA      NA      NA      NA       NA       NA       NA ## 16664         NA      NA      NA      NA      NA       NA       NA       NA ##       c1004_4aq1 c1004_4aq2 c1004_4aq3 c1004_4aq4 c1004_4aq5 c1004_4aq6 c1004_1 ## 16659         NA         NA         NA         NA         NA         NA      NA ## 16660         NA         NA         NA         NA         NA         NA      NA ## 16661         NA         NA         NA         NA         NA         NA      NA ## 16662         NA         NA         NA         NA         NA         NA      NA ## 16663         NA         NA         NA         NA         NA         NA      NA ## 16664         NA         NA         NA         NA         NA         NA      NA ##       c1004_2 c1004_3 c1004_4 c1004_5 c1004_6 c1004_7 c1004_8 c1004_9 c1004_10 ## 16659      NA      NA      NA      NA      NA      NA      NA      NA       NA ## 16660      NA      NA      NA      NA      NA      NA      NA      NA       NA ## 16661      NA      NA      NA      NA      NA      NA      NA      NA       NA ## 16662      NA      NA      NA      NA      NA      NA      NA      NA       NA ## 16663      NA      NA      NA      NA      NA      NA      NA      NA       NA ## 16664      NA      NA      NA      NA      NA      NA      NA      NA       NA ##       c1004_4aq7 c1004_4aq8 c1005_12 c1005_13 c1005_14 c1005_15 c1005_16 ## 16659         NA         NA       NA       NA       NA       NA       NA ## 16660         NA         NA       NA       NA       NA       NA       NA ## 16661         NA         NA       NA       NA       NA       NA       NA ## 16662         NA         NA       NA       NA       NA       NA       NA ## 16663         NA         NA       NA       NA       NA       NA       NA ## 16664         NA         NA       NA       NA       NA       NA       NA ##       c1005_17 c1005_4aq1 c1005_18 c1005_19 c1005_7aq1 c1005_7aq2 c1005_7aq3 ## 16659       NA         NA                           NA         NA         NA ## 16660       NA         NA                           NA         NA         NA ## 16661       NA         NA                           NA         NA         NA ## 16662       NA         NA                           NA         NA         NA ## 16663       NA         NA                           NA         NA         NA ## 16664       NA         NA                           NA         NA         NA ##       c1005_7aq4 c1005_7aq5 c1005_7aq6 c1005_7aq7 c1005_7aq8 c1005_7aq9 ## 16659         NA         NA         NA         NA         NA         NA ## 16660         NA         NA         NA         NA         NA         NA ## 16661         NA         NA         NA         NA         NA         NA ## 16662         NA         NA         NA         NA         NA         NA ## 16663         NA         NA         NA         NA         NA         NA ## 16664         NA         NA         NA         NA         NA         NA ##       c1005_7aq10 c1005_7aq11 c1005_7aq12 c1005_7aq13 c1005_7aq14 c1005_7aq15 ## 16659          NA          NA          NA          NA          NA          NA ## 16660          NA          NA          NA          NA          NA          NA ## 16661          NA          NA          NA          NA          NA          NA ## 16662          NA          NA          NA          NA          NA          NA ## 16663          NA          NA          NA          NA          NA          NA ## 16664          NA          NA          NA          NA          NA          NA ##       c1005_7aq16 c1005_7aq17 c1005_7aq18 c1005_7aq19 c1005_7aq20 c1005_20 ## 16659          NA          NA          NA          NA          NA       NA ## 16660          NA          NA          NA          NA          NA       NA ## 16661          NA          NA          NA          NA          NA       NA ## 16662          NA          NA          NA          NA          NA       NA ## 16663          NA          NA          NA          NA          NA       NA ## 16664          NA          NA          NA          NA          NA       NA ##       c1005_21 c1005_22 c1005_23 c1005_24 c1005_25 c1005_26 c1005_27 c1005_28 ## 16659       NA       NA       NA       NA       NA       NA       NA       NA ## 16660       NA       NA       NA       NA       NA       NA       NA       NA ## 16661       NA       NA       NA       NA       NA       NA       NA       NA ## 16662       NA       NA       NA       NA       NA       NA       NA       NA ## 16663       NA       NA       NA       NA       NA       NA       NA       NA ## 16664       NA       NA       NA       NA       NA       NA       NA       NA ##       c1005_29 c1005_30 c1005_31 c1005_32 c1005_36 c1005_4aq2 c1005_38 ## 16659       NA       NA       NA       NA       NA         NA       NA ## 16660       NA       NA       NA       NA       NA         NA       NA ## 16661       NA       NA       NA       NA       NA         NA       NA ## 16662       NA       NA       NA       NA       NA         NA       NA ## 16663       NA       NA       NA       NA       NA         NA       NA ## 16664       NA       NA       NA       NA       NA         NA       NA ##       c1005_4aq3 c1005_40 c1005_10aq1 c1005_42 c1005_4aq4 c1005_44 c1005_4aq5 ## 16659         NA       NA          NA       NA         NA       NA         NA ## 16660         NA       NA          NA       NA         NA       NA         NA ## 16661         NA       NA          NA       NA         NA       NA         NA ## 16662         NA       NA          NA       NA         NA       NA         NA ## 16663         NA       NA          NA       NA         NA       NA         NA ## 16664         NA       NA          NA       NA         NA       NA         NA ##       c1005_46 c1005_4aq6 c1005_48 c1005_4aq7 c1005_4aq8 c1005_4aq9 c1005_4aq10 ## 16659       NA         NA       NA         NA         NA         NA          NA ## 16660       NA         NA       NA         NA         NA         NA          NA ## 16661       NA         NA       NA         NA         NA         NA          NA ## 16662       NA         NA       NA         NA         NA         NA          NA ## 16663       NA         NA       NA         NA         NA         NA          NA ## 16664       NA         NA       NA         NA         NA         NA          NA ##       c1005_4aq11 c1005_4aq12 c1005_4aq13 c1005_4aq14 c1005_4aq15 c1007_4aq1 ## 16659          NA          NA          NA          NA          NA         NA ## 16660          NA          NA          NA          NA          NA         NA ## 16661          NA          NA          NA          NA          NA         NA ## 16662          NA          NA          NA          NA          NA         NA ## 16663          NA          NA          NA          NA          NA         NA ## 16664          NA          NA          NA          NA          NA         NA ##       c1007_4aq2 c1007_7aq1 c1007_7aq2 c1007_7aq3 c1007_4aq3 c1007_4aq4 ## 16659         NA         NA         NA         NA         NA         NA ## 16660         NA         NA         NA         NA         NA         NA ## 16661         NA         NA         NA         NA         NA         NA ## 16662         NA         NA         NA         NA         NA         NA ## 16663         NA         NA         NA         NA         NA         NA ## 16664         NA         NA         NA         NA         NA         NA ##       c1007_4aq5 c1007_4aq6 c1007_4aq7 c1007_4aq8 c1007_4aq9 c1007_4aq10 ## 16659         NA         NA         NA         NA         NA          NA ## 16660         NA         NA         NA         NA         NA          NA ## 16661         NA         NA         NA         NA         NA          NA ## 16662         NA         NA         NA         NA         NA          NA ## 16663         NA         NA         NA         NA         NA          NA ## 16664         NA         NA         NA         NA         NA          NA ##       c1007_4aq11 c1007_4aq12 c1007_4aq13 c1007_4aq14 c1007_4aq15 c1007_4aq16 ## 16659          NA          NA          NA          NA          NA          NA ## 16660          NA          NA          NA          NA          NA          NA ## 16661          NA          NA          NA          NA          NA          NA ## 16662          NA          NA          NA          NA          NA          NA ## 16663          NA          NA          NA          NA          NA          NA ## 16664          NA          NA          NA          NA          NA          NA ##       c1007_4aq17 c1007_4aq18 c1007_4aq19 c1007_4aq20 c1007_4aq21 c1007_4aq22 ## 16659          NA          NA          NA          NA          NA          NA ## 16660          NA          NA          NA          NA          NA          NA ## 16661          NA          NA          NA          NA          NA          NA ## 16662          NA          NA          NA          NA          NA          NA ## 16663          NA          NA          NA          NA          NA          NA ## 16664          NA          NA          NA          NA          NA          NA ##       c1007_4aq23 h10_pers_income1 h10_pers_income2 h10_pers_income3 ## 16659          NA               NA               NA             7163 ## 16660          NA               NA               NA               NA ## 16661          NA             3630               NA               NA ## 16662          NA               NA              700               NA ## 16663          NA               NA               NA               NA ## 16664          NA               NA               NA               NA ##       h10_pers_income4 h10_pers_income5 ## 16659                0               NA ## 16660                0               NA ## 16661                0               NA ## 16662                0               NA ## 16663                0               NA ## 16664                0               NA   대규모 데이터는 변수가 많고 변수명이 코드로 되어 있어 전체 데이터 구조를 한눈에 파악 어려움   변수명을 쉬운 단어로 바꿔 분석에 사용할 변수 파악   data &lt;- rename(data,                sex = h10_g3,                birth = h10_g4,                marriage = h10_g10,                religion = h10_g11,                income = p1002_8aq1,                code_job = h10_eco9,                code_region = h10_reg7)   columns name 변경되었는지 확인   names(data)   ##   [1] \"h10_id\"           \"h10_ind\"          \"h10_sn\"           ##   [4] \"h10_merkey\"       \"h_new\"            \"h10_cobf\"         ##   [7] \"h10_reg5\"         \"code_region\"      \"h10_din\"          ##  [10] \"h10_cin\"          \"h10_flag\"         \"p10_wgl\"          ##  [13] \"p10_wsl\"          \"p10_wgc\"          \"p10_wsc\"          ##  [16] \"h10_hc\"           \"nh1001_1\"         \"nh1001_2\"         ##  [19] \"h1001_1\"          \"h10_pind\"         \"h10_pid\"          ##  [22] \"h10_g1\"           \"h10_g2\"           \"sex\"              ##  [25] \"birth\"            \"h10_g6\"           \"h10_g7\"           ##  [28] \"h10_g8\"           \"h10_g9\"           \"marriage\"         ##  [31] \"religion\"         \"h10_g12\"          \"h1001_110\"        ##  [34] \"h1001_5aq1\"       \"h1001_5aq2\"       \"h1001_5aq3\"       ##  [37] \"h1001_5aq4\"       \"h10_med1\"         \"h10_med2\"         ##  [40] \"h10_med3\"         \"h10_med4\"         \"h10_med5\"         ##  [43] \"h10_med6\"         \"h10_med7\"         \"h10_med8\"         ##  [46] \"h10_g9_1\"         \"h10_med9\"         \"h10_med10\"        ##  [49] \"h10_eco1\"         \"h10_eco2\"         \"h10_eco3\"         ##  [52] \"h10_eco4\"         \"h10_eco4_1\"       \"h10_eco5_1\"       ##  [55] \"h10_eco6\"         \"h10_eco_7_1\"      \"h10_eco_7_2\"      ##  [58] \"h10_eco_7_3\"      \"h10_eco8\"         \"code_job\"         ##  [61] \"h10_eco10\"        \"h10_eco11\"        \"h10_soc1\"         ##  [64] \"h10_soc_2\"        \"h10_soc_3\"        \"h10_soc_4\"        ##  [67] \"h10_soc_5\"        \"h10_soc_6\"        \"h10_soc_7\"        ##  [70] \"h10_soc_8\"        \"h10_soc_9\"        \"h10_soc_10\"       ##  [73] \"h10_soc_11\"       \"h10_soc8\"         \"h10_soc9\"         ##  [76] \"h10_soc11\"        \"h10_soc10\"        \"h10_soc_12\"       ##  [79] \"h10_soc_13\"       \"h1005_1\"          \"h1005_3aq1\"       ##  [82] \"h1005_2\"          \"h1005_3\"          \"h1005_4\"          ##  [85] \"h1005_5\"          \"h1005_6\"          \"h1005_7\"          ##  [88] \"nh1005_8\"         \"nh1005_9\"         \"h1005_3aq2\"       ##  [91] \"h1006_aq1\"        \"h1006_1\"          \"h1006_2\"          ##  [94] \"h1006_4\"          \"h1006_5\"          \"h1006_3\"          ##  [97] \"h1006_6\"          \"h1006_8\"          \"h1006_9\"          ## [100] \"h1006_aq2\"        \"h1006_aq3\"        \"h1006_10\"         ## [103] \"h1006_11\"         \"h1006_12\"         \"h1006_13\"         ## [106] \"h1006_14\"         \"h1006_21\"         \"h1006_22\"         ## [109] \"h1006_23\"         \"h1006_24\"         \"h1006_25\"         ## [112] \"h1006_27\"         \"h1006_30\"         \"h1006_33\"         ## [115] \"h1006_36\"         \"h1006_39\"         \"h1006_3aq1\"       ## [118] \"h1007_3aq1\"       \"h1007_3aq2\"       \"h1007_5aq1\"       ## [121] \"h1007_3aq3\"       \"h1007_3aq4\"       \"h1007_3aq5\"       ## [124] \"h1007_6aq1\"       \"h1007_3aq6\"       \"h1007_5aq2\"       ## [127] \"h1007_3aq7\"       \"h1007_3aq8\"       \"h1007_3aq9\"       ## [130] \"h1007_3aq10\"      \"h1007_3aq11\"      \"h1007_5aq3\"       ## [133] \"h1007_5aq4\"       \"h1007_3aq13\"      \"h1007_6aq4\"       ## [136] \"h1007_6aq6\"       \"h1007_3aq14\"      \"h1007_3aq15\"      ## [139] \"h1007_3aq16\"      \"h1007_3aq17\"      \"h1007_4\"          ## [142] \"h1007_6aq7\"       \"h1007_6aq8\"       \"h1007_6aq9\"       ## [145] \"h1007_6aq10\"      \"h1007_6aq11\"      \"h1007_5\"          ## [148] \"h1007_6aq12\"      \"h1007_6aq13\"      \"h1007_6aq14\"      ## [151] \"h1007_9\"          \"h1009_9\"          \"h1009_6aq4\"       ## [154] \"h10_inc1\"         \"h10_inc2_1\"       \"h10_inc2_2\"       ## [157] \"h10_inc3_1\"       \"h10_inc3_2\"       \"h10_inc4_1\"       ## [160] \"h10_inc4_2\"       \"h10_inc5_1\"       \"h10_inc5_2\"       ## [163] \"h10_inc6_1\"       \"h10_inc6_2\"       \"h10_inc7_1\"       ## [166] \"h10_inc7_2\"       \"h1008_106\"        \"h1008_107\"        ## [169] \"h1008_108\"        \"h1008_109\"        \"h1008_110\"        ## [172] \"h1008_111\"        \"h10_inc2_3\"       \"h10_inc2\"         ## [175] \"h10_inc3_6\"       \"h10_inc3\"         \"h10_inc4_7\"       ## [178] \"h10_inc4\"         \"h10_inc4_8\"       \"h10_inc4_9\"       ## [181] \"h1008_155\"        \"h1008_156\"        \"h1008_157\"        ## [184] \"h1008_158\"        \"h1008_160\"        \"h1008_159\"        ## [187] \"h1008_3aq3\"       \"h1008_161\"        \"h1008_162\"        ## [190] \"h1008_163\"        \"h1008_164\"        \"h1008_166\"        ## [193] \"h1008_165\"        \"h1008_3aq4\"       \"h1008_167\"        ## [196] \"h1008_168\"        \"h1008_169\"        \"h1008_170\"        ## [199] \"h10_inc7_3\"       \"h10_inc7\"         \"h1008_aq9\"        ## [202] \"h1008_aq10\"       \"h1008_aq11\"       \"h1008_aq12\"       ## [205] \"h1008_aq13\"       \"h1008_aq14\"       \"h1008_aq15\"       ## [208] \"h1008_6aq1\"       \"h1008_aq16\"       \"h1008_aq17\"       ## [211] \"h1008_10aq1\"      \"h1008_aq19\"       \"h1008_aq20\"       ## [214] \"h1008_aq21\"       \"h1008_5aq3\"       \"h1008_7aq1\"       ## [217] \"h1008_aq22\"       \"h1008_7aq2\"       \"h1008_aq23\"       ## [220] \"h1008_aq24\"       \"h1008_4aq116\"     \"h1008_4aq117\"     ## [223] \"h1008_5aq1\"       \"h1008_7aq4\"       \"h1008_7aq5\"       ## [226] \"h1008_7aq6\"       \"h1008_7aq7\"       \"h1008_7aq8\"       ## [229] \"h1008_7aq9\"       \"h1008_aq25\"       \"h1008_7aq10\"      ## [232] \"h1008_aq26\"       \"h1008_aq27\"       \"h1008_aq28\"       ## [235] \"h1008_aq29\"       \"h1008_3aq5\"       \"h1008_4aq118\"     ## [238] \"h1008_aq30\"       \"h1008_6aq3\"       \"h1008_3aq6\"       ## [241] \"h1008_3aq7\"       \"nh1008_3aq1\"      \"h1008_aq32\"       ## [244] \"h1008_aq33\"       \"h1008_aq34\"       \"h1008_3aq8\"       ## [247] \"h1008_195\"        \"h1008_7aq11\"      \"h1009_aq1\"        ## [250] \"h1009_aq2\"        \"h1009_aq3\"        \"h1009_aq4\"        ## [253] \"h1009_aq5\"        \"h1009_aq6\"        \"h1009_aq7\"        ## [256] \"h1009_aq8\"        \"h1010_aq1\"        \"h1010_aq2\"        ## [259] \"h1010_aq3\"        \"h1010_aq4\"        \"h1010_aq5\"        ## [262] \"h1010_aq6\"        \"h1010_aq7\"        \"h1010_aq8\"        ## [265] \"h1010_aq9\"        \"h1010_aq10\"       \"h1010_aq11\"       ## [268] \"h1010_aq12\"       \"h1010_aq13\"       \"h1010_aq14\"       ## [271] \"h1010_aq15\"       \"h1010_aq16\"       \"h1010_aq17\"       ## [274] \"h1010_aq18\"       \"h1010_aq19\"       \"h1010_aq20\"       ## [277] \"h1010_26\"         \"h1010_27\"         \"h1010_aq23\"       ## [280] \"h1010_aq24\"       \"h1010_aq25\"       \"h1010_aq26\"       ## [283] \"h1011_2\"          \"h1011_3\"          \"h1011_4\"          ## [286] \"h1011_5\"          \"h1011_6\"          \"h1011_7\"          ## [289] \"h1011_8\"          \"h1011_3aq1\"       \"h1011_3aq2\"       ## [292] \"h1011_3aq3\"       \"h1011_3aq4\"       \"h1011_3aq5\"       ## [295] \"h1011_3aq6\"       \"h1011_3aq7\"       \"h1012_1\"          ## [298] \"nh1012_1\"         \"h1012_2\"          \"h1012_3\"          ## [301] \"h1012_4\"          \"h1012_5\"          \"h1012_6\"          ## [304] \"h1012_7\"          \"nh1012_7\"         \"nh1012_8\"         ## [307] \"h1012_9\"          \"h1012_10\"         \"h1012_11\"         ## [310] \"h1012_12\"         \"h1012_13\"         \"h1012_14\"         ## [313] \"h1012_15\"         \"h1012_3aq1\"       \"h1012_16\"         ## [316] \"h1012_17\"         \"h1012_18\"         \"h1012_19\"         ## [319] \"h1012_1_4aq1\"     \"h1012_1_5aq1\"     \"h1012_1_5aq2\"     ## [322] \"h1012_1_5aq3\"     \"h1012_1_5aq4\"     \"h1012_1_5aq5\"     ## [325] \"h1012_1_4aq2\"     \"h1012_1_4aq3\"     \"h1013_2\"          ## [328] \"h1013_6\"          \"h1013_10\"         \"h1013_14\"         ## [331] \"h1013_18\"         \"h1013_22\"         \"h1013_26\"         ## [334] \"h1013_8aq1\"       \"h1013_5aq1\"       \"h1013_8aq2\"       ## [337] \"h1013_4aq1\"       \"h1013_4aq2\"       \"h1013_4aq4\"       ## [340] \"h1013_4aq6\"       \"h1013_4aq8\"       \"h1013_4aq10\"      ## [343] \"h1013_5aq4\"       \"h1013_5aq6\"       \"h1013_5aq8\"       ## [346] \"h1013_6aq1\"       \"h1013_4aq14\"      \"h1013_4aq15\"      ## [349] \"h1013_4aq16\"      \"h1013_4aq17\"      \"h1013_4aq18\"      ## [352] \"h1013_4aq20\"      \"h1013_4aq22\"      \"h1013_4aq24\"      ## [355] \"h1013_4aq26\"      \"h1013_4aq28\"      \"h1013_4aq30\"      ## [358] \"h1013_4aq32\"      \"h1014_4\"          \"h1014_8\"          ## [361] \"h1014_12\"         \"h1014_16\"         \"h1014_20\"         ## [364] \"h1014_24\"         \"h1014_28\"         \"h1014_32\"         ## [367] \"h1014_36\"         \"h1014_3aq1\"       \"h1014_4aq1\"       ## [370] \"h1015_4\"          \"h1015_8\"          \"h1015_12\"         ## [373] \"h1015_20\"         \"h1015_25\"         \"h1015_29\"         ## [376] \"h1015_33\"         \"h1015_37\"         \"h1015_4aq1\"       ## [379] \"h1015_7aq1\"       \"h1015_aq1\"        \"h1015_40\"         ## [382] \"h1015_41\"         \"h1015_42\"         \"h1015_43\"         ## [385] \"h1015_44\"         \"h1015_45\"         \"h1015_46\"         ## [388] \"h1015_47\"         \"h1015_48\"         \"h1015_49\"         ## [391] \"h1015_50\"         \"h1015_51\"         \"h1015_52\"         ## [394] \"h1015_53\"         \"h1015_54\"         \"h1015_55\"         ## [397] \"h1015_56\"         \"h1015_57\"         \"h1015_60\"         ## [400] \"h1015_aq2\"        \"h1015_61\"         \"h1015_62\"         ## [403] \"h1015_63\"         \"h1015_66\"         \"h1015_67\"         ## [406] \"h1015_68\"         \"h1015_aq3\"        \"h1015_69\"         ## [409] \"h1015_70\"         \"h1015_71\"         \"h1015_74\"         ## [412] \"h1015_75\"         \"h1015_76\"         \"h1015_aq4\"        ## [415] \"h1015_77\"         \"h1015_78\"         \"h1015_79\"         ## [418] \"h1015_82\"         \"h1015_83\"         \"h1015_84\"         ## [421] \"h1015_aq5\"        \"h1015_85\"         \"h1015_86\"         ## [424] \"h1015_87\"         \"h1015_90\"         \"h1015_91\"         ## [427] \"h1015_92\"         \"h1015_aq6\"        \"h1015_93\"         ## [430] \"h1015_94\"         \"h1015_95\"         \"h1015_98\"         ## [433] \"h1015_99\"         \"h1015_100\"        \"h1015_aq7\"        ## [436] \"h1015_101\"        \"h1015_102\"        \"h1015_103\"        ## [439] \"h1015_106\"        \"h1015_107\"        \"h1016_6aq1\"       ## [442] \"h1016_6aq4\"       \"h1016_8\"          \"h1016_24\"         ## [445] \"h1016_4aq1\"       \"h1016_4aq4\"       \"h1016_32\"         ## [448] \"h1016_36\"         \"h1016_40\"         \"h1016_4aq7\"       ## [451] \"h1016_56\"         \"h1016_60\"         \"h1016_64\"         ## [454] \"h1017_1\"          \"h1017_2\"          \"h1017_3\"          ## [457] \"h1017_4\"          \"h1017_5\"          \"h1017_6\"          ## [460] \"h1017_7\"          \"p10_fnum\"         \"p10_tq\"           ## [463] \"p10_cp\"           \"p1001_1\"          \"p1001_2\"          ## [466] \"p1001_aq1\"        \"p1001_3\"          \"p1001_4\"          ## [469] \"p1001_5\"          \"p1001_6\"          \"p1001_10\"         ## [472] \"p1001_11\"         \"p1001_12\"         \"p1001_13\"         ## [475] \"p1001_14\"         \"p1001_7\"          \"p1001_8\"          ## [478] \"p1001_9\"          \"p1001_15\"         \"p1001_16\"         ## [481] \"p1001_17\"         \"p1001_18\"         \"p1001_19\"         ## [484] \"p1001_20\"         \"p1001_21\"         \"p1001_22\"         ## [487] \"p1001_23\"         \"p1001_24\"         \"p1001_25\"         ## [490] \"p1001_27\"         \"p1001_28\"         \"p1001_29\"         ## [493] \"p1001_30\"         \"p1001_31\"         \"p1001_32\"         ## [496] \"p1001_33\"         \"p1001_34\"         \"p1002_1\"          ## [499] \"p1002_2\"          \"p1002_3\"          \"p1002_4\"          ## [502] \"p1002_5\"          \"p1002_6\"          \"p1002_7\"          ## [505] \"p1002_8\"          \"income\"           \"p1002_9\"          ## [508] \"p1002_8aq2\"       \"p1002_4aq1\"       \"p1002_10\"         ## [511] \"p1002_11\"         \"p1002_12\"         \"p1002_8aq3\"       ## [514] \"p1002_8aq4\"       \"p1002_31\"         \"p1002_4aq2\"       ## [517] \"p1002_4aq3\"       \"p1002_4aq4\"       \"p1002_8aq5\"       ## [520] \"p1002_8aq6\"       \"p1002_8aq7\"       \"p1002_8aq8\"       ## [523] \"p1002_8aq9\"       \"p1002_8aq10\"      \"p1002_8aq11\"      ## [526] \"p1002_8aq12\"      \"p1002_8aq13\"      \"p1002_8aq14\"      ## [529] \"p1002_8aq15\"      \"p1002_aq2\"        \"p1002_aq3\"        ## [532] \"p1002_aq4\"        \"p1002_aq5\"        \"p1003_1\"          ## [535] \"p1003_2\"          \"p1003_5\"          \"p1003_6\"          ## [538] \"p1003_7\"          \"p1003_8\"          \"p1003_9\"          ## [541] \"p1003_10\"         \"p1003_11\"         \"p1003_12\"         ## [544] \"p1004_1\"          \"p1004_2\"          \"p1004_3\"          ## [547] \"p1004_4\"          \"p1004_5\"          \"p1004_6\"          ## [550] \"p1004_7\"          \"p1004_8\"          \"p1004_9\"          ## [553] \"p1004_10\"         \"p1004_11\"         \"p1004_12\"         ## [556] \"p1004_13\"         \"p1004_3aq1\"       \"p1004_3aq2\"       ## [559] \"p1004_3aq3\"       \"p1004_3aq4\"       \"p1004_3aq5\"       ## [562] \"p1004_3aq6\"       \"p1004_3aq7\"       \"p1004_3aq8\"       ## [565] \"p1005_3aq1\"       \"p1005_3aq2\"       \"p1005_3aq3\"       ## [568] \"p1005_3aq4\"       \"p1005_3aq5\"       \"p1005_3aq6\"       ## [571] \"p1005_3aq7\"       \"p1005_3aq8\"       \"p1005_3aq9\"       ## [574] \"p1005_3aq10\"      \"p1005_2\"          \"p1005_3\"          ## [577] \"p1005_4aq1\"       \"p1005_4aq2\"       \"p1005_4aq3\"       ## [580] \"p1005_4aq4\"       \"p1005_4aq5\"       \"p1005_4aq6\"       ## [583] \"p1005_4aq7\"       \"p1005_4aq8\"       \"p1005_5\"          ## [586] \"p1005_6\"          \"p1005_7\"          \"p1005_8\"          ## [589] \"p1005_3aq11\"      \"p1005_9\"          \"p1005_10\"         ## [592] \"p1005_11\"         \"p1005_12\"         \"p1005_13\"         ## [595] \"p1005_14\"         \"p1005_15\"         \"p1005_16\"         ## [598] \"p1005_17\"         \"p1005_18\"         \"p1005_19\"         ## [601] \"p1005_20\"         \"p1005_21\"         \"p1005_22\"         ## [604] \"p1005_23\"         \"p1005_24\"         \"p1005_25\"         ## [607] \"p1005_26\"         \"p1005_27\"         \"p1005_28\"         ## [610] \"p1005_29\"         \"p1005_4aq9\"       \"p1005_4aq10\"      ## [613] \"p1005_4aq11\"      \"p1005_aq1\"        \"p1005_aq2\"        ## [616] \"p1005_aq3\"        \"p1005_aq4\"        \"p1005_6aq1\"       ## [619] \"p1005_6aq2\"       \"p1005_6aq3\"       \"p1005_6aq4\"       ## [622] \"p1005_6aq5\"       \"p1005_6aq6\"       \"p1005_6aq7\"       ## [625] \"p1005_6aq8\"       \"p1005_6aq9\"       \"p1005_7aq1\"       ## [628] \"p1005_7aq2\"       \"p1005_7aq3\"       \"p1007_3aq1\"       ## [631] \"p1007_3aq2\"       \"p1007_3aq3\"       \"p1007_3aq4\"       ## [634] \"p1007_3aq5\"       \"p1007_3aq6\"       \"p1007_3aq7\"       ## [637] \"np1006_1\"         \"np1006_2\"         \"np1006_3\"         ## [640] \"np1006_4\"         \"np1006_5\"         \"np1006_6\"         ## [643] \"np1006_7\"         \"np1006_8\"         \"np1006_9\"         ## [646] \"np1006_10\"        \"np1006_11\"        \"np1006_12\"        ## [649] \"np1006_13\"        \"np1006_14\"        \"np1006_15\"        ## [652] \"np1006_16\"        \"np1006_17\"        \"np1006_18\"        ## [655] \"np1006_19\"        \"np1006_20\"        \"np1006_21\"        ## [658] \"np1006_22\"        \"np1006_23\"        \"np1006_24\"        ## [661] \"np1006_25\"        \"np1006_26\"        \"np1006_27\"        ## [664] \"np1006_28\"        \"np1006_29\"        \"np1006_30\"        ## [667] \"np1006_31\"        \"np1006_32\"        \"np1006_33\"        ## [670] \"np1006_34\"        \"np1006_35\"        \"np1006_36\"        ## [673] \"np1006_37\"        \"np1006_38\"        \"np1006_39\"        ## [676] \"np1006_40\"        \"np1006_41\"        \"np1006_42\"        ## [679] \"np1006_43\"        \"np1006_44\"        \"p1006_3aq1\"       ## [682] \"c10_fnum\"         \"c10_cp\"           \"c10_grade\"        ## [685] \"c1001_1\"          \"c1001_2\"          \"c1001_3\"          ## [688] \"c1001_4\"          \"c1001_5\"          \"c1001_6\"          ## [691] \"c1001_7\"          \"c1001_8\"          \"c1001_9\"          ## [694] \"c1001_10\"         \"c1001_11\"         \"c1001_12\"         ## [697] \"c1001_13\"         \"c1001_7aq5\"       \"c1001_7aq6\"       ## [700] \"c1001_7aq7\"       \"c1001_7aq8\"       \"c1001_4aq1\"       ## [703] \"c1001_4aq2\"       \"c1001_4aq3\"       \"c1001_4aq4\"       ## [706] \"c1001_4aq5\"       \"c1001_4aq6\"       \"c1002_1\"          ## [709] \"c1002_2\"          \"c1002_3\"          \"c1002_4\"          ## [712] \"c1002_5\"          \"c1002_6\"          \"c1002_7\"          ## [715] \"c1002_8\"          \"c1002_9\"          \"c1002_10\"         ## [718] \"c1002_11\"         \"c1002_12\"         \"c1002_13\"         ## [721] \"c1002_14\"         \"c1002_15\"         \"c1002_16\"         ## [724] \"c1002_17\"         \"c1002_18\"         \"c1002_19\"         ## [727] \"c1002_20\"         \"c1002_21\"         \"c1002_22\"         ## [730] \"c1002_23\"         \"c1002_24\"         \"c1002_25\"         ## [733] \"c1002_26\"         \"c1002_4aq1\"       \"c1002_27\"         ## [736] \"c1002_28\"         \"c1002_29\"         \"c1002_30\"         ## [739] \"c1002_31\"         \"c1002_32\"         \"c1002_33\"         ## [742] \"c1002_34\"         \"c1002_35\"         \"c1002_36\"         ## [745] \"c1002_37\"         \"c1002_38\"         \"c1002_39\"         ## [748] \"c1002_40\"         \"c1002_41\"         \"c1002_42\"         ## [751] \"c1002_43\"         \"c1002_44\"         \"c1002_45\"         ## [754] \"c1002_46\"         \"c1002_47\"         \"c1002_48\"         ## [757] \"c1002_49\"         \"c1002_50\"         \"c1002_51\"         ## [760] \"c1002_52\"         \"c1002_53\"         \"c1002_54\"         ## [763] \"c1002_55\"         \"c1002_56\"         \"c1002_57\"         ## [766] \"c1002_58\"         \"c1002_4aq2\"       \"c1002_59\"         ## [769] \"c1002_60\"         \"c1002_61\"         \"c1002_62\"         ## [772] \"c1002_63\"         \"c1002_64\"         \"c1002_65\"         ## [775] \"c1002_66\"         \"c1002_67\"         \"c1002_68\"         ## [778] \"c1002_69\"         \"c1002_70\"         \"c1002_71\"         ## [781] \"c1002_72\"         \"c1002_73\"         \"c1002_74\"         ## [784] \"c1002_75\"         \"c1002_76\"         \"c1002_77\"         ## [787] \"c1002_7aq1\"       \"c1002_7aq2\"       \"c1002_7aq3\"       ## [790] \"c1002_7aq4\"       \"c1002_7aq5\"       \"c1002_7aq6\"       ## [793] \"c1002_7aq7\"       \"c1002_7aq8\"       \"c1002_7aq9\"       ## [796] \"c1002_7aq10\"      \"c1002_7aq11\"      \"c1002_7aq12\"      ## [799] \"c1002_7aq13\"      \"c1002_7aq14\"      \"c1002_78\"         ## [802] \"c1002_79\"         \"c1002_80\"         \"c1002_81\"         ## [805] \"c1002_82\"         \"c1002_83\"         \"c1002_84\"         ## [808] \"c1002_85\"         \"c1002_86\"         \"c1002_87\"         ## [811] \"c1002_88\"         \"c1002_89\"         \"c1002_90\"         ## [814] \"c1002_91\"         \"c1002_92\"         \"c1002_93\"         ## [817] \"c1002_94\"         \"c1002_95\"         \"c1002_96\"         ## [820] \"c1002_97\"         \"c1002_98\"         \"c1002_4aq3\"       ## [823] \"c1002_4aq4\"       \"c1002_4aq5\"       \"c1002_4aq6\"       ## [826] \"c1002_4aq7\"       \"c1002_4aq8\"       \"c1002_7aq15\"      ## [829] \"c1003_4aq1\"       \"c1003_4aq2\"       \"c1003_4aq3\"       ## [832] \"c1003_4aq4\"       \"c1003_4aq5\"       \"c1003_4aq6\"       ## [835] \"c1003_4aq7\"       \"c1003_4aq8\"       \"c1003_4aq9\"       ## [838] \"c1003_6\"          \"c1003_7\"          \"c1003_8\"          ## [841] \"c1003_9\"          \"c1003_13\"         \"c1003_14\"         ## [844] \"c1003_15\"         \"c1004_4aq1\"       \"c1004_4aq2\"       ## [847] \"c1004_4aq3\"       \"c1004_4aq4\"       \"c1004_4aq5\"       ## [850] \"c1004_4aq6\"       \"c1004_1\"          \"c1004_2\"          ## [853] \"c1004_3\"          \"c1004_4\"          \"c1004_5\"          ## [856] \"c1004_6\"          \"c1004_7\"          \"c1004_8\"          ## [859] \"c1004_9\"          \"c1004_10\"         \"c1004_4aq7\"       ## [862] \"c1004_4aq8\"       \"c1005_12\"         \"c1005_13\"         ## [865] \"c1005_14\"         \"c1005_15\"         \"c1005_16\"         ## [868] \"c1005_17\"         \"c1005_4aq1\"       \"c1005_18\"         ## [871] \"c1005_19\"         \"c1005_7aq1\"       \"c1005_7aq2\"       ## [874] \"c1005_7aq3\"       \"c1005_7aq4\"       \"c1005_7aq5\"       ## [877] \"c1005_7aq6\"       \"c1005_7aq7\"       \"c1005_7aq8\"       ## [880] \"c1005_7aq9\"       \"c1005_7aq10\"      \"c1005_7aq11\"      ## [883] \"c1005_7aq12\"      \"c1005_7aq13\"      \"c1005_7aq14\"      ## [886] \"c1005_7aq15\"      \"c1005_7aq16\"      \"c1005_7aq17\"      ## [889] \"c1005_7aq18\"      \"c1005_7aq19\"      \"c1005_7aq20\"      ## [892] \"c1005_20\"         \"c1005_21\"         \"c1005_22\"         ## [895] \"c1005_23\"         \"c1005_24\"         \"c1005_25\"         ## [898] \"c1005_26\"         \"c1005_27\"         \"c1005_28\"         ## [901] \"c1005_29\"         \"c1005_30\"         \"c1005_31\"         ## [904] \"c1005_32\"         \"c1005_36\"         \"c1005_4aq2\"       ## [907] \"c1005_38\"         \"c1005_4aq3\"       \"c1005_40\"         ## [910] \"c1005_10aq1\"      \"c1005_42\"         \"c1005_4aq4\"       ## [913] \"c1005_44\"         \"c1005_4aq5\"       \"c1005_46\"         ## [916] \"c1005_4aq6\"       \"c1005_48\"         \"c1005_4aq7\"       ## [919] \"c1005_4aq8\"       \"c1005_4aq9\"       \"c1005_4aq10\"      ## [922] \"c1005_4aq11\"      \"c1005_4aq12\"      \"c1005_4aq13\"      ## [925] \"c1005_4aq14\"      \"c1005_4aq15\"      \"c1007_4aq1\"       ## [928] \"c1007_4aq2\"       \"c1007_7aq1\"       \"c1007_7aq2\"       ## [931] \"c1007_7aq3\"       \"c1007_4aq3\"       \"c1007_4aq4\"       ## [934] \"c1007_4aq5\"       \"c1007_4aq6\"       \"c1007_4aq7\"       ## [937] \"c1007_4aq8\"       \"c1007_4aq9\"       \"c1007_4aq10\"      ## [940] \"c1007_4aq11\"      \"c1007_4aq12\"      \"c1007_4aq13\"      ## [943] \"c1007_4aq14\"      \"c1007_4aq15\"      \"c1007_4aq16\"      ## [946] \"c1007_4aq17\"      \"c1007_4aq18\"      \"c1007_4aq19\"      ## [949] \"c1007_4aq20\"      \"c1007_4aq21\"      \"c1007_4aq22\"      ## [952] \"c1007_4aq23\"      \"h10_pers_income1\" \"h10_pers_income2\" ## [955] \"h10_pers_income3\" \"h10_pers_income4\" \"h10_pers_income5\"   데이터 탐색   성별에 따른 월급 차이   분석 절차      변수 검토 및 preprocessing        sex   income        변수 간 상관관계 분석        성별 월급 평균표 만들기   그래프 만들기   변수 검토 및 preprocessing   data$sex   class(data$sex)   ## [1] \"numeric\"   table(data$sex)   ## ##    1    2 ## 7578 9086   table(is.na(data$sex))   ## ## FALSE ## 16664   이상값 및 결측치 없는 것 확인 결측치 있다면 다음과 같이 처리   data$sex &lt;- ifelse(data$sex == 9, NA, data$sex)   preprocessing :   알아보기 쉽게 항목이름 부여   data$sex &lt;- ifelse(data$sex == 1, \"male\", \"female\") table(data$sex)   ## ## female   male ##   9086   7578   qplot(data$sex)      class(data$income)   ## [1] \"numeric\"   datatype이 numeric 이므로 summary로도 확인 해봄   summary(data$income)   ##    Min. 1st Qu.  Median    Mean 3rd Qu.    Max.    NA's ##     0.0   122.0   192.5   241.6   316.6  2400.0   12030   결측치 12030건     확인   qplot(data$income)   ## `stat_bin()` using `bins = 30`. Pick better value with `binwidth`.  ## Warning: Removed 12030 rows containing non-finite values (stat_bin).      qplot(data$income) +xlim(0, 1000)   ## `stat_bin()` using `bins = 30`. Pick better value with `binwidth`.  ## Warning: Removed 12051 rows containing non-finite values (stat_bin).  ## Warning: Removed 2 rows containing missing values (geom_bar).                     결측치 (0       9999)에 대해 NA 입력 결측치 처리 이후 NA 값 확인           data$income &lt;- ifelse(data$income %in% c(0,9999), NA, data$income) table(is.na(data$income))   ## ## FALSE  TRUE ##  4620 12044   income != NA인 경우만 추출하여 group by sex, mean income으로 summarise   sexincome &lt;- data %&gt;% filter(!is.na(income)) %&gt;% group_by(sex) %&gt;% summarise(mean_income = mean(income))  sexincome   ## # A tibble: 2 x 2 ##   sex    mean_income ##   &lt;chr&gt;        &lt;dbl&gt; ## 1 female        163. ## 2 male          312.   시각화 : ggplot   ggplot(data=sexincome, aes(x=sex, y=mean_income)) + geom_col()      나이와 월급의 관계 : 몇살때 월급을 가장 많이 받을까?   class(data$birth)   ## [1] \"numeric\"   summary(data$birth)   ##    Min. 1st Qu.  Median    Mean 3rd Qu.    Max. ##    1907    1946    1966    1968    1988    2014   qplot(data$birth)   ## `stat_bin()` using `bins = 30`. Pick better value with `binwidth`.      table(is.na(data$birth))   ## ## FALSE ## 16664   결측치 없음 확인   이상치 있다면 아래와 같은 작업 수행   data$birth &lt;- ifelse(data$birth == 9999, NA, data$birth) table(is.na(data$birth))   ## ## FALSE ## 16664   파생변수 만들기 : 나이   2015년도 자료이므로 2015년 나이 산출하여 파생변수 만듦   data$age &lt;- 2015-data$birth + 1 summary(data$age)   ##    Min. 1st Qu.  Median    Mean 3rd Qu.    Max. ##    2.00   28.00   50.00   48.43   70.00  109.00   qplot(data$age)   ## `stat_bin()` using `bins = 30`. Pick better value with `binwidth`.      나이와 월급의 관계 분석   나이별 월급 평균 산출   ageincome &lt;- data %&gt;% filter(!is.na(income)) %&gt;% group_by(age) %&gt;%  summarise(mean_income = mean(income)) head(ageincome)   ## # A tibble: 6 x 2 ##     age mean_income ##   &lt;dbl&gt;       &lt;dbl&gt; ## 1    20        121. ## 2    21        106. ## 3    22        130. ## 4    23        142. ## 5    24        134. ## 6    25        145.   시각화   ggplot (data = ageincome, aes(x=age, y=mean_income)) + geom_line()      연령대에 따른 월급 차이      변수 검토 및 preprocessing        age   income        변수간 correlation             연령대별 월급 평균표            나이를 연령대로 categorize       data &lt;- data %&gt;%  mutate(ageg = ifelse(age&lt;30, \"young\", ifelse(age&lt;= 59, \"middle\", \"old\"))) table(data$ageg)   ## ## middle    old  young ##   6049   6281   4334   qplot (data$ageg)      파생변수 생성   연령대별 급여   agegincome &lt;- data %&gt;% filter(!is.na(income)) %&gt;% group_by(ageg) %&gt;% summarise(mean_income = mean(income)) agegincome   ## # A tibble: 3 x 2 ##   ageg   mean_income ##   &lt;chr&gt;        &lt;dbl&gt; ## 1 middle        282. ## 2 old           125. ## 3 young         164.   시각화   연령대별 급여를 ggplot으로 ordered by ageg, mean_income   ggplot(data = agegincome, aes(x=reorder(ageg, mean_income), y=mean_income)) + geom_col()      scale_x_discrete(limits = \"\") ggplot x scale 순서 지정   ggplot(data=agegincome, aes(x=ageg, y=mean_income)) + geom_col() + scale_x_discrete(limits = c(\"young\", \"middle\", \"old\"))      성별, 연령별 급여 차이      변수 검토 및 전처리        age - ageg, ageincome   sex - sexincome   income        변수간 correlation        연령대 및 성별 월급 평균표   그래프로 시각화     sexincome &lt;- data %&gt;%  filter(!is.na(income)) %&gt;% group_by(ageg, sex) %&gt;% summarise(mean_income = mean(income)) sexincome   ## # A tibble: 6 x 3 ## # Groups:   ageg [3] ##   ageg   sex    mean_income ##   &lt;chr&gt;  &lt;chr&gt;        &lt;dbl&gt; ## 1 middle female       188. ## 2 middle male         353. ## 3 old    female        81.5 ## 4 old    male         174. ## 5 young  female       160. ## 6 young  male         171.   stack chart   ggplot(data = sexincome, aes(x=ageg, y=mean_income, fill=sex)) + geom_col() + scale_x_discrete(limits = c(\"young\", \"middle\", \"old\"))      ggplot(data = sexincome, aes(x=ageg, y=mean_income, fill=sex)) + geom_col(position = \"dodge\") + scale_x_discrete(limits = c(\"young\", \"middle\", \"old\"))      sexage &lt;- data %&gt;% filter(!is.na(income)) %&gt;% group_by(age, sex) %&gt;% summarise(mean_income = mean(income)) head(sexage)   ## # A tibble: 6 x 3 ## # Groups:   age [3] ##     age sex    mean_income ##   &lt;dbl&gt; &lt;chr&gt;        &lt;dbl&gt; ## 1    20 female        147. ## 2    20 male           69 ## 3    21 female        107. ## 4    21 male          102. ## 5    22 female        140. ## 6    22 male          118.   시각화   ggplot(data = sexage, aes(x = age, y = mean_income, col = sex )) + geom_line()      직업별 월급 차이      변수 검토 및 preprocessing : job, income   variables correlation : tables, graphs   code_job 변수 검토   class (data$code_job)   ## [1] \"numeric\"   table(data$code_job)   ## ##  111  120  131  132  133  134  135  139  141  149  151  152  153  159  211  212 ##    2   16   10   11    9    3    7   10   35   20   26   18   15   16    8    4 ##  213  221  222  223  224  231  232  233  234  235  236  237  239  241  242  243 ##    3   17   31   12    4   41    5    3    6   48   14    2   29   12    4   63 ##  244  245  246  247  248  251  252  253  254  259  261  271  272  273  274  281 ##    4   33   59   77   38   14  111   24   67  109    4   15   11    4   36   17 ##  283  284  285  286  289  311  312  313  314  320  330  391  392  399  411  412 ##    8   10   26   16    5  140  260  220   84   75   15    4   13   87   47   12 ##  421  422  423  429  431  432  441  442  510  521  522  530  611  612  613  620 ##  124   71    5   14   20   33  154  197  192  353    5  106 1320   11   40    2 ##  630  710  721  722  730  741  742  743  751  752  753  761  762  771  772  773 ##   20   29   30   22   16   27    3   34   34    5   49   69   27   11   61   86 ##  774  780  791  792  799  811  812  819  821  822  823  831  832  841  842  843 ##    7   17    5   21   45   16    1    6    9    9   23    5   17   32   10    4 ##  851  852  853  854  855  861  862  863  864  871  873  874  875  876  881  882 ##   19   13    7   33    9    3   14   17   31    2  257   34   37    2    2    3 ##  891  892  899  910  921  922  930  941  942  951  952  953  991  992  999 1011 ##    8   19   16  102   31   74  289  325   99  125  122   73   45   12  141    2 ## 1012 ##   17   CodeBook에서 import job name -&gt; left_join   list_job &lt;- read_excel(\"~/Desktop/johnwi_KNOU/Programming/1. R/handouts/0401/Data/Koweps_Codebook.xlsx\", col_names = T, sheet = 2)   head(list_job)   ## # A tibble: 6 x 2 ##   code_job job                                 ##      &lt;dbl&gt; &lt;chr&gt;                               ## 1      111 의회의원 고위공무원 및 공공단체임원 ## 2      112 기업고위임원                        ## 3      120 행정 및 경영지원 관리자             ## 4      131 연구 교육 및 법률 관련 관리자       ## 5      132 보험 및 금융 관리자                 ## 6      133 보건 및 사회복지 관련 관리자   tail(list_job)   ## # A tibble: 6 x 2 ##   code_job job                               ##      &lt;dbl&gt; &lt;chr&gt;                             ## 1      953 판매관련 단순 종사원              ## 2      991 농립어업관련 단순 종사원          ## 3      992 계기검침 수금 및 주차 관련 종사원 ## 4      999 기타 서비스관련 단순 종사원       ## 5     1011 장교                              ## 6     1012 장기 부사관 및 준위   dim(list_job)   ## [1] 149   2   data &lt;- left_join(data, list_job, id = \"code_job\")   ## Joining, by = \"code_job\"   data %&gt;%  filter(!is.na(code_job)) %&gt;% select(code_job, job) %&gt;% head(10)   ##    code_job                                job ## 1       942                   경비원 및 검표원 ## 2       762                             전기공 ## 3       530 방문 노점 및 통신 판매 관련 종사자 ## 4       999        기타 서비스관련 단순 종사원 ## 5       312                    경영관련 사무원 ## 6       254             문리 기술 및 예능 강사 ## 7       510                        영업 종사자 ## 8       530 방문 노점 및 통신 판매 관련 종사자 ## 9       286   스포츠 및 레크레이션 관련 전문가 ## 10      521                   매장 판매 종사자   table(is.na(data$code_job))   ## ## FALSE  TRUE ##  7529  9135   직업별 월급 차이 분석   jobincome &lt;- data %&gt;%  filter(!is.na(job) &amp; !is.na(income)) %&gt;% group_by(job) %&gt;% summarise(mean_income = mean(income)) head(jobincome)   ## # A tibble: 6 x 2 ##   job                           mean_income ##   &lt;chr&gt;                               &lt;dbl&gt; ## 1 가사 및 육아 도우미                  80.2 ## 2 간호사                              241. ## 3 건설 및 광업 단순 종사원            190. ## 4 건설 및 채굴 기계운전원             358. ## 5 건설 전기 및 생산 관련 관리자       536. ## 6 건설관련 기능 종사자                247.   top10 &lt;- jobincome %&gt;% arrange(desc(mean_income)) %&gt;% head(10) top10   ## # A tibble: 10 x 2 ##    job                                  mean_income ##    &lt;chr&gt;                                      &lt;dbl&gt; ##  1 금속 재료 공학 기술자 및 시험원             845. ##  2 의료진료 전문가                             844. ##  3 의회의원 고위공무원 및 공공단체임원         750 ##  4 보험 및 금융 관리자                         726. ##  5 제관원 및 판금원                            572. ##  6 행정 및 경영지원 관리자                     564. ##  7 문화 예술 디자인 및 영상 관련 관리자        557. ##  8 연구 교육 및 법률 관련 관리자               550. ##  9 건설 전기 및 생산 관련 관리자               536. ## 10 석유 및 화학물 가공장치 조작원              532.   시각화   ggplot(data = top10, aes(x = reorder(job, mean_income), y = mean_income)) + geom_col() + coord_flip()      bot10 &lt;- jobincome %&gt;% arrange(mean_income) %&gt;% head(10) bot10   ## # A tibble: 10 x 2 ##    job                          mean_income ##    &lt;chr&gt;                              &lt;dbl&gt; ##  1 가사 및 육아 도우미                 80.2 ##  2 임업관련 종사자                     83.3 ##  3 기타 서비스관련 단순 종사원         88.2 ##  4 청소원 및 환경 미화원               88.8 ##  5 약사 및 한약사                      89   ##  6 작물재배 종사자                     92   ##  7 농립어업관련 단순 종사원           102. ##  8 의료 복지 관련 서비스 종사자       104. ##  9 음식관련 단순 종사원               108. ## 10 판매관련 단순 종사원               117.   ggplot(data = bot10, aes(x=reorder(job, -mean_income), y = mean_income)) + geom_col() + coord_flip() + ylim(0, 850)      성별 직업 빈도   남성 직업 순위   jobmale &lt;- data %&gt;% filter(!is.na(job) &amp; sex == \"male\") %&gt;% group_by(job) %&gt;% summarise(n = n()) %&gt;% arrange(desc(n)) %&gt;% head(10) jobmale   ## # A tibble: 10 x 2 ##    job                          n ##    &lt;chr&gt;                    &lt;int&gt; ##  1 작물재배 종사자            640 ##  2 자동차 운전원              251 ##  3 경영관련 사무원            213 ##  4 영업 종사자                141 ##  5 매장 판매 종사자           132 ##  6 제조관련 단순 종사원       104 ##  7 청소원 및 환경 미화원       97 ##  8 건설 및 광업 단순 종사원    95 ##  9 경비원 및 검표원            95 ## 10 행정 사무원                 92   ggplot (data= jobmale, aes(x=reorder(job, n), y = n)) + geom_col() + coord_flip()      female numbers by job   jobfm &lt;- data %&gt;% filter(!is.na(job) &amp; sex == \"female\") %&gt;% group_by(job) %&gt;% summarise(n = n()) %&gt;% arrange(desc(n)) %&gt;% head(10) jobfm   ## # A tibble: 10 x 2 ##    job                              n ##    &lt;chr&gt;                        &lt;int&gt; ##  1 작물재배 종사자                680 ##  2 청소원 및 환경 미화원          228 ##  3 매장 판매 종사자               221 ##  4 제조관련 단순 종사원           185 ##  5 회계 및 경리 사무원            176 ##  6 음식서비스 종사자              149 ##  7 주방장 및 조리사               126 ##  8 가사 및 육아 도우미            125 ##  9 의료 복지 관련 서비스 종사자   121 ## 10 음식관련 단순 종사원           104   ggplot (data= jobfm, aes(x=reorder(job, n), y = n)) + geom_col() + coord_flip()      종교 유무에 따른 이혼율      변수 검토 및 preprocessing : religion, mariage   variables correlations : tables, graphs   about religion   class(data$religion)   ## [1] \"numeric\"   table(data$religion)   ## ##    1    2 ## 8047 8617   data$religion &lt;- ifelse(data$religion == 1, \"yes\", \"no\") table(data$religion)   ## ##   no  yes ## 8617 8047   about marriage      0.비해당(18세 미만) 1.유배우 2.사별 3.이혼 4.별거 5.미혼(18세이상, 미혼모 포함) 6.기타(사망 등)    class (data$marriage)   ## [1] \"numeric\"   table (data$marriage)   ## ##    0    1    2    3    4    5    6 ## 2861 8431 2117  712   84 2433   26   create a new variable about divorce   data$group_marriage &lt;- ifelse (data$marriage == 1, \"marriage\", ifelse(data$marriage == 3, \"divorce\", NA)) table (data$group_marriage)   ## ##  divorce marriage ##      712     8431   table(is.na(data$group_marriage))   ## ## FALSE  TRUE ##  9143  7521   create table about divorce ratio by religion   reli_marry &lt;- data %&gt;% filter(!is.na(group_marriage)) %&gt;% group_by(religion, group_marriage) %&gt;% summarise(n = n()) %&gt;% mutate(tot_group = sum(n)) %&gt;% mutate(pct = round(n/tot_group*100, 1)) reli_marry   ## # A tibble: 4 x 5 ## # Groups:   religion [2] ##   religion group_marriage     n tot_group   pct ##   &lt;chr&gt;    &lt;chr&gt;          &lt;int&gt;     &lt;int&gt; &lt;dbl&gt; ## 1 no       divorce          384      4602   8.3 ## 2 no       marriage        4218      4602  91.7 ## 3 yes      divorce          328      4541   7.2 ## 4 yes      marriage        4213      4541  92.8   count() 활용   reli_marry &lt;- data %&gt;%  filter(!is.na(group_marriage)) %&gt;%  count(religion, group_marriage) %&gt;% group_by(religion ) %&gt;% mutate(pct2 = round(n/sum(n)*100, 1)) reli_marry   ## # A tibble: 4 x 4 ## # Groups:   religion [2] ##   religion group_marriage     n  pct2 ##   &lt;chr&gt;    &lt;chr&gt;          &lt;int&gt; &lt;dbl&gt; ## 1 no       divorce          384   8.3 ## 2 no       marriage        4218  91.7 ## 3 yes      divorce          328   7.2 ## 4 yes      marriage        4213  92.8   create table about divorce ratio   divo &lt;- reli_marry %&gt;%  filter(group_marriage == \"divorce\") %&gt;% select(religion, pct2) divo   ## # A tibble: 2 x 2 ## # Groups:   religion [2] ##   religion  pct2 ##   &lt;chr&gt;    &lt;dbl&gt; ## 1 no         8.3 ## 2 yes        7.2   create col plot   ggplot(data = divo, aes(x=religion, y = pct2) ) + geom_col()      agegmarr &lt;- data %&gt;% filter(!is.na(group_marriage)) %&gt;% group_by(ageg, group_marriage) %&gt;% summarise(n = n()) %&gt;% mutate(tot_group = sum(n))  %&gt;%  mutate(pct = round(n/tot_group*100, 1)) agegmarr   ## # A tibble: 6 x 5 ## # Groups:   ageg [3] ##   ageg   group_marriage     n tot_group   pct ##   &lt;chr&gt;  &lt;chr&gt;          &lt;int&gt;     &lt;int&gt; &lt;dbl&gt; ## 1 middle divorce          437      4918   8.9 ## 2 middle marriage        4481      4918  91.1 ## 3 old    divorce          273      4165   6.6 ## 4 old    marriage        3892      4165  93.4 ## 5 young  divorce            2        60   3.3 ## 6 young  marriage          58        60  96.7   count() 활용   agegmarr2 &lt;- data %&gt;% filter(!is.na(group_marriage)) %&gt;% count(ageg, group_marriage) %&gt;% group_by(ageg) %&gt;% mutate(pct = round(n/sum(n)*100, 1)) agegmarr2   ## # A tibble: 6 x 4 ## # Groups:   ageg [3] ##   ageg   group_marriage     n   pct ##   &lt;chr&gt;  &lt;chr&gt;          &lt;int&gt; &lt;dbl&gt; ## 1 middle divorce          437   8.9 ## 2 middle marriage        4481  91.1 ## 3 old    divorce          273   6.6 ## 4 old    marriage        3892  93.4 ## 5 young  divorce            2   3.3 ## 6 young  marriage          58  96.7   ggplot(data = agegmarr, aes(x=ageg, y = pct, fill = group_marriage)) + geom_col()      create a new variabe ageg_divo only about divorce rate except “young” from agegmarr   ageg_divo &lt;- agegmarr %&gt;% filter( ageg != \"young\" &amp; group_marriage == \"divorce\") %&gt;% select(ageg, pct) ageg_divo   ## # A tibble: 2 x 2 ## # Groups:   ageg [2] ##   ageg     pct ##   &lt;chr&gt;  &lt;dbl&gt; ## 1 middle   8.9 ## 2 old      6.6   ggplot(data = ageg_divo, aes(x = ageg, y = pct)) + geom_col()      Create a new variable `` about divorce ratio by age group,   ageg_reli_marr &lt;- data %&gt;% filter(!is.na(group_marriage) &amp; ageg != \"young\") %&gt;%     group_by(ageg, religion,group_marriage) %&gt;%     summarise(n = n()) %&gt;% mutate(tot = sum(n)) %&gt;% mutate(pct = round(n/tot*100, 1)) ageg_reli_marr   ## # A tibble: 8 x 6 ## # Groups:   ageg, religion [4] ##   ageg   religion group_marriage     n   tot   pct ##   &lt;chr&gt;  &lt;chr&gt;    &lt;chr&gt;          &lt;int&gt; &lt;int&gt; &lt;dbl&gt; ## 1 middle no       divorce          260  2681   9.7 ## 2 middle no       marriage        2421  2681  90.3 ## 3 middle yes      divorce          177  2237   7.9 ## 4 middle yes      marriage        2060  2237  92.1 ## 5 old    no       divorce          123  1884   6.5 ## 6 old    no       marriage        1761  1884  93.5 ## 7 old    yes      divorce          150  2281   6.6 ## 8 old    yes      marriage        2131  2281  93.4   apply count()   ageg_reli_marr2 &lt;- data %&gt;% filter(!is.na(group_marriage) &amp; ageg != \"young\")  %&gt;% count(ageg, religion, group_marriage) %&gt;% group_by(ageg, religion) %&gt;% mutate(pct = n/sum(n)*100) ageg_reli_marr2   ## # A tibble: 8 x 5 ## # Groups:   ageg, religion [4] ##   ageg   religion group_marriage     n   pct ##   &lt;chr&gt;  &lt;chr&gt;    &lt;chr&gt;          &lt;int&gt; &lt;dbl&gt; ## 1 middle no       divorce          260  9.70 ## 2 middle no       marriage        2421 90.3 ## 3 middle yes      divorce          177  7.91 ## 4 middle yes      marriage        2060 92.1 ## 5 old    no       divorce          123  6.53 ## 6 old    no       marriage        1761 93.5 ## 7 old    yes      divorce          150  6.58 ## 8 old    yes      marriage        2131 93.4   ggplot(data = ageg_reli_marr, aes(x = ageg, y = pct, fill = group_marriage)) + geom_col(position = \"dodge\")      df_divo &lt;- ageg_reli_marr %&gt;%  filter(group_marriage ==\"divorce\") %&gt;% select(ageg,religion, pct) df_divo   ## # A tibble: 4 x 3 ## # Groups:   ageg, religion [4] ##   ageg   religion   pct ##   &lt;chr&gt;  &lt;chr&gt;    &lt;dbl&gt; ## 1 middle no         9.7 ## 2 middle yes        7.9 ## 3 old    no         6.5 ## 4 old    yes        6.6   ggplot(data = df_divo, aes(x = ageg, y = pct, fill = religion)) + geom_col(position = \"dodge\")      age group ratio by region   list_codebook &lt;- read_excel(\"~/Desktop/johnwi_KNOU/Programming/1. R/handouts/0401/Data/Koweps_Codebook.xlsx\", col_names = T, sheet = 1) list_codebook   ## # A tibble: 7 x 6 ##   변수명  설명     내용             범위    `모름/무응답` `출처 조사설계서`      ##   &lt;chr&gt;   &lt;chr&gt;    &lt;chr&gt;            &lt;chr&gt;   &lt;chr&gt;         &lt;chr&gt;                  ## 1 h10_g3  성별     \"1.남         2.… N(1~2)  모름/무응답=9 10차 머지데이터_변수명.xlsx… ## 2 h10_g4  태어난 연도… \"년\"             N(1900… 모름/무응답=9999… 10차 머지데이터_변수명.xlsx… ## 3 h10_g10 혼인상태 \"0.비해당(18세 미만)\\… N(0~6)  모름/무응답=9 10차 머지데이터_변수명.xlsx… ## 4 h10_g11 종교     \"1.있음          … N(1~2)  모름/무응답=9 10차 머지데이터_변수명.xlsx… ## 5 h10_ec… 직종     \"직종 코드표 참조\"… N(직종코드… 모름/무응답=9999… 10차 머지데이터_변수명.xlsx… ## 6 p1002_… 일한달의 월 … \"만원\"           N(1~99… 모름/무응답=9999… (2015년 10차 한국복지패널조사) … ## 7 h10_re… 7개 권역별 … \"1. 서울         … N(1~7)  &lt;NA&gt;          (2015년 10차 한국복지패널조사) …   1. 서울 2. 수도권(인천/경기) 3. 부산/경남/울산 4.대구/경북 5. 대전/충남 6. 강원/충북 7.광주/전남/전북/제주도   head(data$code_region)   ## [1] 1 1 1 1 1 1   tail(data$code_region)   ## [1] 5 5 5 5 5 5   data$region &lt;- ifelse(data$code_region == 1, \"서울\",                       ifelse(data$code_region == 2, \"수도권(인천/경기)\",                              ifelse(data$code_region == 3, \"부산/경남/울산\",                                     ifelse(data$code_region == 4, \"대구/경북\",                                            ifelse(data$code_region == 5, \"대전/충남\",                                                   ifelse(data$code_region == 6, \"강원/충북\",                                                          ifelse(data$code_region == 7, \"광주/전남/전북/제주도\", NA)))))))  head(data$region)   ## [1] \"서울\" \"서울\" \"서울\" \"서울\" \"서울\" \"서울\"   tail(data$region)   ## [1] \"대전/충남\" \"대전/충남\" \"대전/충남\" \"대전/충남\" \"대전/충남\" \"대전/충남\"      위의 지역명을 dataframe으로 만들어 처리하는 방법     list_region &lt;- data.frame(code_region = c(1:7),                           region = c(\"서울\", \"수도권(인천/경기)\", \"부산/경남/울산\", \"대구/경북\", \"대전/충남\", \"강원/충북\", \"광주/전남/전북/제주도\")) list_region   ##   code_region                region ## 1           1                  서울 ## 2           2     수도권(인천/경기) ## 3           3        부산/경남/울산 ## 4           4             대구/경북 ## 5           5             대전/충남 ## 6           6             강원/충북 ## 7           7 광주/전남/전북/제주도   data &lt;-  left_join(data, list_region, id = \"code_region\")   ## Joining, by = c(\"code_region\", \"region\")  ## Warning: Column `region` joining character vector and factor, coercing into ## character vector   data %&gt;%  select(code_region, region) %&gt;% head(10)   ##    code_region region ## 1            1   서울 ## 2            1   서울 ## 3            1   서울 ## 4            1   서울 ## 5            1   서울 ## 6            1   서울 ## 7            1   서울 ## 8            1   서울 ## 9            1   서울 ## 10           1   서울   reg_ageg &lt;- data %&gt;%  group_by(region, ageg) %&gt;% summarise(n = n()) %&gt;% mutate(tot = sum(n)) %&gt;% mutate(pct = round(n/tot*100, 2)) head(reg_ageg)   ## # A tibble: 6 x 5 ## # Groups:   region [2] ##   region                ageg       n   tot   pct ##   &lt;chr&gt;                 &lt;chr&gt;  &lt;int&gt; &lt;int&gt; &lt;dbl&gt; ## 1 강원/충북             middle   417  1257  33.2 ## 2 강원/충북             old      555  1257  44.2 ## 3 강원/충북             young    285  1257  22.7 ## 4 광주/전남/전북/제주도 middle   947  2922  32.4 ## 5 광주/전남/전북/제주도 old     1233  2922  42.2 ## 6 광주/전남/전북/제주도 young    742  2922  25.4   ageg_reg &lt;- data %&gt;% filter(!is.na(region)) %&gt;% count (region, ageg) %&gt;% group_by(region) %&gt;% mutate(arrate = round(n / sum(n)*100, 2 )) ageg_reg   ## # A tibble: 21 x 4 ## # Groups:   region [7] ##    region                ageg       n arrate ##    &lt;chr&gt;                 &lt;chr&gt;  &lt;int&gt;  &lt;dbl&gt; ##  1 강원/충북             middle   417   33.2 ##  2 강원/충북             old      555   44.2 ##  3 강원/충북             young    285   22.7 ##  4 광주/전남/전북/제주도 middle   947   32.4 ##  5 광주/전남/전북/제주도 old     1233   42.2 ##  6 광주/전남/전북/제주도 young    742   25.4 ##  7 대구/경북             middle   637   31.3 ##  8 대구/경북             old      928   45.6 ##  9 대구/경북             young    471   23.1 ## 10 대전/충남             middle   548   37.4 ## # … with 11 more rows   ggplot(data = ageg_reg, aes(x=region, y = arrate, fill = ageg)) +geom_col() + coord_flip()      order by elders ratio   list_order_old &lt;- ageg_reg %&gt;% filter(ageg == \"old\") %&gt;%  arrange(arrate) list_order_old   ## # A tibble: 7 x 4 ## # Groups:   region [7] ##   region                ageg      n arrate ##   &lt;chr&gt;                 &lt;chr&gt; &lt;int&gt;  &lt;dbl&gt; ## 1 수도권(인천/경기)     old    1109   29.9 ## 2 서울                  old     805   32.4 ## 3 대전/충남             old     527   35.9 ## 4 부산/경남/울산        old    1124   40.4 ## 5 광주/전남/전북/제주도 old    1233   42.2 ## 6 강원/충북             old     555   44.2 ## 7 대구/경북             old     928   45.6   order &lt;- list_order_old$region order   ## [1] \"수도권(인천/경기)\"     \"서울\"                  \"대전/충남\"             ## [4] \"부산/경남/울산\"        \"광주/전남/전북/제주도\" \"강원/충북\"             ## [7] \"대구/경북\"   ggplot(data = ageg_reg, aes(x=region, y = arrate, fill = ageg)) +geom_col() + coord_flip() + scale_x_discrete(limits = order)     ",
          
        "categories": ["Study","R","Aidata"],
        "tags": ["R","ggplot","bigdata","LectureNotes"],
        "url": "https://gitgitwi.github.io"/study/r/aidata/LN-0401-KOWEPS-data-mini-project/"",
        "teaser": null
      },
    
      
      {
        "title": "Lecture 0402 analyze APTs values around 홍대입구역 using Google Maps API",
        "excerpt":
          
            "Using Google Maps API   install ggmap &amp; import libraries   library(ggplot2) theme_update(text=element_text(family=\"NanumBarunGothic\"))   import csv files   station &lt;- read.csv(\"~/Desktop/johnwi_KNOU/Programming/1. R/handouts/0402/역주소.csv\") head(station)   ##                 역명                    구주소 ## 1               시청     서울 중구 서소문동 27 ## 2         을지로입구  서울 중구 을지로1가 89-1 ## 3          을지로3가  서울 중구 을지로3가 70-1 ## 4          을지로4가 서울 중구 을지로4가 261-1 ## 5 동대문역사문화공원     서울 중구 을지로7가 1 ## 6               신당   서울 중구 신당5동 106-1   apt &lt;- read.csv(\"~/Desktop/johnwi_KNOU/Programming/1. R/handouts/0402/아파트 시세.csv\") head(apt)   ##                     시군구 번지          단지명 전용면적 거래금액 ## 1 서울특별시 마포구 공덕동  371 공덕1삼성래미안   114.88   85,500 ## 2 서울특별시 마포구 공덕동  371 공덕1삼성래미안    59.74   63,900 ## 3 서울특별시 마포구 공덕동  371 공덕1삼성래미안    59.74   65,000 ## 4 서울특별시 마포구 공덕동  371 공덕1삼성래미안    59.74   68,000 ## 5 서울특별시 마포구 공덕동  371 공덕1삼성래미안   114.88   97,000 ## 6 서울특별시 마포구 공덕동  371 공덕1삼성래미안    84.94   84,000   str(station)   ## 'data.frame':    51 obs. of  2 variables: ##  $ 역명  : Factor w/ 51 levels \"강남\",\"강변\",..: 24 43 41 42 12 26 19 38 49 13 ... ##  $ 구주소: Factor w/ 51 levels \"서울 강남구 삼성2동 143-42\",..: 43 45 46 47 48 44 31 32 33 27 ...   station_code &lt;- as.character(station$구주소) head(station_code)   ## [1] \"서울 중구 서소문동 27\"     \"서울 중구 을지로1가 89-1\" ## [3] \"서울 중구 을지로3가 70-1\"  \"서울 중구 을지로4가 261-1\" ## [5] \"서울 중구 을지로7가 1\"     \"서울 중구 신당5동 106-1\"   register_google(\"\")   station_code &lt;- geocode(station_code)   head(station_code)   ## # A tibble: 6 x 2 ##     lon   lat ##   &lt;dbl&gt; &lt;dbl&gt; ## 1  127.  37.6 ## 2  127.  37.6 ## 3  127.  37.6 ## 4  127.  37.6 ## 5  127.  37.6 ## 6  127.  37.6   table(is.na(station_code))   ## ## FALSE ##   102   NA 값 없는지     확인   enc2utf8() : encoding 까지 한번에   station_code &lt;- as.character(station$구주소) %&gt;% enc2utf8() %&gt;%  geocode()   head(station_code)   ## # A tibble: 6 x 2 ##     lon   lat ##   &lt;dbl&gt; &lt;dbl&gt; ## 1  127.  37.6 ## 2  127.  37.6 ## 3  127.  37.6 ## 4  127.  37.6 ## 5  127.  37.6 ## 6  127.  37.6   station_code_final &lt;-  cbind(station, station_code) head(station_code_final)   ##                 역명                    구주소      lon      lat ## 1               시청     서울 중구 서소문동 27 126.9753 37.56389 ## 2         을지로입구  서울 중구 을지로1가 89-1 126.9826 37.56598 ## 3          을지로3가  서울 중구 을지로3가 70-1 126.9935 37.56681 ## 4          을지로4가 서울 중구 을지로4가 261-1 126.9973 37.56639 ## 5 동대문역사문화공원     서울 중구 을지로7가 1 127.0110 37.56728 ## 6               신당   서울 중구 신당5동 106-1 127.0196 37.56565   아파트 실거래가 데이터 가공 (마포구)   apt 전용면적 소수점 제거   apt$전용면적 &lt;- round(apt$전용면적) head(apt)   ##                     시군구 번지          단지명 전용면적 거래금액 ## 1 서울특별시 마포구 공덕동  371 공덕1삼성래미안      115   85,500 ## 2 서울특별시 마포구 공덕동  371 공덕1삼성래미안       60   63,900 ## 3 서울특별시 마포구 공덕동  371 공덕1삼성래미안       60   65,000 ## 4 서울특별시 마포구 공덕동  371 공덕1삼성래미안       60   68,000 ## 5 서울특별시 마포구 공덕동  371 공덕1삼성래미안      115   97,000 ## 6 서울특별시 마포구 공덕동  371 공덕1삼성래미안       85   84,000   count(apt, 전용면적) %&gt;% arrange(desc(n))   ## # A tibble: 106 x 2 ##    전용면적     n ##       &lt;dbl&gt; &lt;int&gt; ##  1       85   434 ##  2       60   223 ##  3      115    90 ##  4       59    79 ##  5       84    43 ##  6       50    31 ##  7      114    24 ##  8       80    17 ##  9      105    16 ## 10       32    15 ## # … with 96 more rows   apt_85 &lt;- subset(apt, 전용면적 == \"85\") head(apt_85)   ##                      시군구 번지          단지명 전용면적 거래금액 ## 6  서울특별시 마포구 공덕동  371 공덕1삼성래미안       85   84,000 ## 12 서울특별시 마포구 공덕동  371 공덕1삼성래미안       85   90,000 ## 14 서울특별시 마포구 공덕동   43 공덕2삼성래미안       85   76,000 ## 19 서울특별시 마포구 공덕동   43 공덕2삼성래미안       85   77,500 ## 20 서울특별시 마포구 공덕동   43 공덕2삼성래미안       85   53,800 ## 21 서울특별시 마포구 공덕동   43 공덕2삼성래미안       85   86,500   APT 단지별 평균거래 금액   gsub(a, b, data=) : change a to b   apt_85$거래금액 &lt;- gsub(\",\", \"\", apt_85$거래금액) head(apt_85)   ##                      시군구 번지          단지명 전용면적 거래금액 ## 6  서울특별시 마포구 공덕동  371 공덕1삼성래미안       85    84000 ## 12 서울특별시 마포구 공덕동  371 공덕1삼성래미안       85    90000 ## 14 서울특별시 마포구 공덕동   43 공덕2삼성래미안       85    76000 ## 19 서울특별시 마포구 공덕동   43 공덕2삼성래미안       85    77500 ## 20 서울특별시 마포구 공덕동   43 공덕2삼성래미안       85    53800 ## 21 서울특별시 마포구 공덕동   43 공덕2삼성래미안       85    86500   as.integer() 통해 거래금액을 casting &gt; aggregate(column, dataset, operation) 통해 그룹연산하여 새 변수에 저장   apt_85_cost &lt;- aggregate(as.integer(거래금액) ~ 단지명, apt_85, mean) head(apt_85_cost)   ##           단지명 as.integer(거래금액) ## 1        (650-0)             50000.00 ## 2       강변타운             44500.00 ## 3 강변힐스테이트             78959.09 ## 4   경남아너스빌             69261.54 ## 5           계룡             56175.00 ## 6           고려             55000.00   apt_85_cost &lt;- rename(apt_85_cost, \"거래금액\" = \"as.integer(거래금액)\") head(apt_85_cost)   ##           단지명 거래금액 ## 1        (650-0) 50000.00 ## 2       강변타운 44500.00 ## 3 강변힐스테이트 78959.09 ## 4   경남아너스빌 69261.54 ## 5           계룡 56175.00 ## 6           고려 55000.00   duplicated() : 중복제거, 중복 값 == TRUE, 처음 값 == FALSE   apt_85 &lt;- apt_85[!duplicated(apt_85$단지명), ] head(apt_85)   ##                      시군구  번지          단지명 전용면적 거래금액 ## 6  서울특별시 마포구 공덕동   371 공덕1삼성래미안       85    84000 ## 14 서울특별시 마포구 공덕동    43 공덕2삼성래미안       85    76000 ## 31 서울특별시 마포구 공덕동   457 공덕3삼성래미안       85    99000 ## 36 서울특별시 마포구 공덕동   476    공덕파크자이       85   117000 ## 39 서울특별시 마포구 공덕동 370-9        공덕현대       85    59000 ## 67 서울특별시 마포구 공덕동   469   래미안공덕5차       85    85000   merge 중복제거한 dataset &amp; 평균거래 dataset by left_join   apt_85 &lt;- left_join(apt_85, apt_85_cost, by = \"단지명\") head(apt_85)   ##                     시군구  번지          단지명 전용면적 거래금액.x 거래금액.y ## 1 서울특별시 마포구 공덕동   371 공덕1삼성래미안       85      84000   87000.00 ## 2 서울특별시 마포구 공덕동    43 공덕2삼성래미안       85      76000   78216.67 ## 3 서울특별시 마포구 공덕동   457 공덕3삼성래미안       85      99000  102333.33 ## 4 서울특별시 마포구 공덕동   476    공덕파크자이       85     117000  117000.00 ## 5 서울특별시 마포구 공덕동 370-9        공덕현대       85      59000   63525.00 ## 6 서울특별시 마포구 공덕동   469   래미안공덕5차       85      85000   90500.00   apt_85 &lt;- apt_85 %&gt;% select(\"단지명\", '시군구',\"번지\",\"전용면적\",\"거래금액.y\")   apt_85 &lt;- rename(apt_85, \"거래금액\" = \"거래금액.y\")   주소 처리 : merge 시군구 &amp; 번지      paste(col1, col2) : 공백과 함께 합치기   paste0(col1, col2) : 공백 없이 합치기   아래에서 별도의 column name 지정하지 않아 .으로 표시됨   apt_add &lt;- paste(apt_85$시군구, apt_85$번지) %&gt;% data.frame() head(apt_add)   ##                                . ## 1   서울특별시 마포구 공덕동 371 ## 2    서울특별시 마포구 공덕동 43 ## 3   서울특별시 마포구 공덕동 457 ## 4   서울특별시 마포구 공덕동 476 ## 5 서울특별시 마포구 공덕동 370-9 ## 6   서울특별시 마포구 공덕동 469   apt_add &lt;- rename(apt_add, \"주소\" = \".\") head(apt_add)   ##                             주소 ## 1   서울특별시 마포구 공덕동 371 ## 2    서울특별시 마포구 공덕동 43 ## 3   서울특별시 마포구 공덕동 457 ## 4   서울특별시 마포구 공덕동 476 ## 5 서울특별시 마포구 공덕동 370-9 ## 6   서울특별시 마포구 공덕동 469   좌표 정보 추가하여 최종 데이터 만들기   apt_add_code &lt;- as.character(apt_add$주소) %&gt;% enc2utf8() %&gt;% geocode()   cbind : bind columns   apt_final &lt;- cbind(apt_85, apt_add, apt_add_code) %&gt;% select(\"단지명\",\"전용면적\",\"거래금액\",\"주소\",lon, lat) head(apt_final)   ##            단지명 전용면적  거래금액                           주소      lon ## 1 공덕1삼성래미안       85  87000.00   서울특별시 마포구 공덕동 371 126.9510 ## 2 공덕2삼성래미안       85  78216.67    서울특별시 마포구 공덕동 43 126.9595 ## 3 공덕3삼성래미안       85 102333.33   서울특별시 마포구 공덕동 457 126.9518 ## 4    공덕파크자이       85 117000.00   서울특별시 마포구 공덕동 476 126.9522 ## 5        공덕현대       85  63525.00 서울특별시 마포구 공덕동 370-9 126.9500 ## 6   래미안공덕5차       85  90500.00   서울특별시 마포구 공덕동 469 126.9522 ##        lat ## 1 37.54671 ## 2 37.55107 ## 3 37.54840 ## 4 37.54687 ## 5 37.54846 ## 6 37.54687   지도 데이터 가져오기   get_googlemap - maptype = c(\"terrain\", \"satellite\", \"roadmap\", \"hybrid\") : 도로지도, 위성지도, 등고선지도     등   mapomap &lt;- get_googlemap(\"mapogu\", maptype = \"roadmap\", zoom = 12)   ggmap(mapomap)      지하철 역 위치 및 아파트 가격 정보 표시   지도생성 - 위치 point 표시 - 정보 text 표시   ggmap(mapomap) +     geom_point(data = station_code_final, aes(x = lon, y = lat), colour = \"brown\", size = 3) +     geom_text(data = station_code_final, aes(label = 역명, vjust = -1), family = \"NanumBarunGothic\")      hongdae_map &lt;- get_googlemap(\"hongdae station\", maptype = \"roadmap\", zoom = 15)   ggmap(hongdae_map) +     geom_point(data = station_code_final, aes(x = lon, y = lat), colour = \"brown\", size = 3) +     geom_text(data = station_code_final, aes(label = 역명, vjust = -1), family = \"NanumBarunGothic\")      홍대입구역 지도에 지하철 정도 및 아파트 정보 일괄 표시   ggmap(hongdae_map) +     geom_point(data = station_code_final, aes(x = lon, y = lat), colour = \"blue\", size = 6) +     geom_text(data = station_code_final, aes(label = 역명, vjust = -1), family = \"NanumBarunGothic\") +     geom_point(data = apt_final, aes(x = lon, y = lat)) +     geom_text(data = apt_final, aes(label = 단지명, vjust = -1), family = \"NanumBarunGothic\", colour = \"red\", size = 2) +     geom_text(data = apt_final, aes(label = 거래금액, vjust = 1), family = \"NanumBarunGothic\", colour = \"red\", size = 2)     ",
          
        "categories": ["Study","Aidata","R"],
        "tags": ["R","bigdata","LectureNotes","Google API"],
        "url": "https://gitgitwi.github.io"/study/aidata/r/LN-0402-%ED%99%8D%EB%8C%80%EC%9E%85%EA%B5%AC%EC%97%AD-APT-%EC%8B%9C%EC%84%B8-%EC%A1%B0%ED%9A%8C-by-using-Google-maps-API/"",
        "teaser": null
      },
    
      
      {
        "title": "Lecture 0403 Text Mining with R",
        "excerpt":
          
            "텍스트 마이닝 Text Mining   Text-mining 개요   분석절차     형태소분석 Morphology Analsys   명사, 동사, 형용사 등 의미 지닌 품사 단어 추출   빈도표   시각화   ex1. 힙합 가사 분석   import libraries and data files   library(KoNLP)   ## Checking user defined dictionary!   library(memoise) library(dplyr)   ## ## Attaching package: 'dplyr'  ## The following objects are masked from 'package:stats': ## ##     filter, lag  ## The following objects are masked from 'package:base': ## ##     intersect, setdiff, setequal, union   library(stringr)   Sejong 보다 많은 단어 데이터 보유한 NIADic 사용 ; 983012 개 단어, KoNLP 함수   useNIADic()   ## Backup was just finished! ## 983012 words dictionary was built.   txt file 은 마지막 줄에서 엔터 없으면 불완전한 마지막이라는 경고메시지 발생   lyrics &lt;- readLines(\"/Users/WnJ/Desktop/johnwi_KNOU/Programming/1. R/handouts/0401/Data/hiphop.txt\") head(lyrics)   ## [1] \"\\\"보고 싶다\"                  \"이렇게 말하니까 더 보고 싶다\" ## [3] \"너희 사진을 보고 있어도\"      \"보고 싶다\"                    ## [5] \"너무 야속한 시간\"             \"나는 우리가 밉다\"   str_replace_all(data, before, after) : 특수문자 제거      \"\\\\W\" : 모든 특수문자     lyrics &lt;- str_replace_all(lyrics, \"\\\\W\", \" \") head(lyrics)   ## [1] \" 보고 싶다\"                   \"이렇게 말하니까 더 보고 싶다\" ## [3] \"너희 사진을 보고 있어도\"      \"보고 싶다\"                    ## [5] \"너무 야속한 시간\"             \"나는 우리가 밉다\"   class (lyrics)   ## [1] \"character\"   dim (lyrics)   ## NULL   str (lyrics)   ##  chr [1:4261] \" 보고 싶다\" \"이렇게 말하니까 더 보고 싶다\" ...   #View (lyrics)   extractNoun() : 명사만 추출   extractNoun(\"대한민국 영토는 한반도와 그 부속도서로 한다\")   ## [1] \"대한민국\" \"영토\"     \"한반도\"   \"부속도서\" \"한\"   가사에서 명사 추출   nouns &lt;- extractNoun(lyrics)  class (nouns)   ## [1] \"list\"   dim (nouns)   ## NULL   #str (nouns)   추출한 명사 list를 문자열 벡터로 변환해 단어별 빈도표 생성   unlist() : list type 은 table() 함수에서 사용 불가   countw &lt;- table (unlist(nouns)) dim (countw)   ## [1] 3008   head (countw)   ## ##           1 100 168  17 ##  12   2   9   3   1   1   tail (countw)   ## ##  zer zino  zon  zoo zoom   ZZ ##    1    1    6    1    1    1   to data frame   dfwords &lt;- as.data.frame(countw, stringsAsFactors = F) dim (dfwords)   ## [1] 3008    2   summary(dfwords)   ##      Var1                Freq         ##  Length:3008        Min.   :  1.000   ##  Class :character   1st Qu.:  1.000   ##  Mode  :character   Median :  1.000   ##                     Mean   :  4.773   ##                     3rd Qu.:  3.000   ##                     Max.   :374.000   dfwords &lt;- rename(dfwords, word = Var1, freq = Freq) dim (dfwords)   ## [1] 3008    2   summary(dfwords)   ##      word                freq         ##  Length:3008        Min.   :  1.000   ##  Class :character   1st Qu.:  1.000   ##  Mode  :character   Median :  1.000   ##                     Mean   :  4.773   ##                     3rd Qu.:  3.000   ##                     Max.   :374.000   두 단어 이상인 경우만 추출   dfwords &lt;- filter(dfwords, nchar(word) &gt;= 2 ) summary (dfwords)   ##      word                freq        ##  Length:2508        Min.   : 1.000   ##  Class :character   1st Qu.: 1.000   ##  Mode  :character   Median : 1.000   ##                     Mean   : 2.821   ##                     3rd Qu.: 2.000   ##                     Max.   :89.000   상위 20개만 확인   top20 &lt;- dfwords %&gt;% arrange(desc(freq)) %&gt;% head(20) top20   ##    word freq ## 1   you   89 ## 2    my   86 ## 3   YAH   80 ## 4    on   76 ## 5  하나   75 ## 6  오늘   51 ## 7  사랑   49 ## 8   and   49 ## 9  우리   48 ## 10 like   48 ## 11  the   43 ## 12 시간   39 ## 13 love   38 ## 14   to   38 ## 15   we   36 ## 16   it   33 ## 17   em   32 ## 18  not   32 ## 19 역사   31 ## 20 flex   30   Word Cloud   import libraries   library(wordcloud)   ## Loading required package: RColorBrewer   library(RColorBrewer)   brewer.pal(, \"coloreset\") : 단어 색상목록   pal &lt;- brewer.pal(8, \"Dark2\")   create wordcloud   set.seed(1234)  wordcloud(words = dfwords$word, freq = dfwords$freq,           min.freq = 2,                    # 최소 단어 빈도           max.words = 200,                 # 표현 단어 수           random.order = F,                # 고빈도 단어 중앙 배치           rot.per = .1,                    # 회전 단어 비율           scale = c(4, 0.3),               # 단어 크기 범위           colors = pal,                    # 색깔 목록           family = \"NanumBarunGothic\"           # font, Mac에서 한글 깨짐 해결 위한 폰트 설정           )      ex2. 여고생들의 고민   qq &lt;- readLines(\"/Users/WnJ/Desktop/johnwi_KNOU/Programming/1. R/handouts/0403/remake.txt\") class (qq)   ## [1] \"character\"   dim (qq)   ## NULL   head(qq)   ## [1] \"여고생쌍커플수술후부작용어떻하죠?재수술? 의사답변  2012.01.28  안녕하세요 대한의사협회 네이버 지식iN 의료 상담 성형외과 전문의 김진왕 입니다. 문의 주신 내용 잘보았습니다.... 따라서 성형외과전문의 선생님과 직접 온라인과 오프라인 상으로 충분한 상담을 하신후 신중한 선택을 하시어 적절한... 건강 &gt; 의료상담 &gt; 외과  답변수 3  추천수 0  조회수 326  \" ## [2] \"\"                                                                                                                                                                                                                                                                                                                                                        ## [3] \"18살 여고생이에여ㅎ   \"                                                                                                                                                                                                                                                                                                                                  ## [4] \"18살 여고생이에여ㅎ 수능끗나고 바로 성형하러...  의사답변  2013.06.08  하이닥-네이버 지식iN 성형외과 상담의 한형일 입니다. 성형 수술이 무슨 공업용 상품이 아니므로 수는 끝나고... 직접 성형외과 상담을 해야합니다. 질문내용에 좋은 답글이 되었길 바랍니다. 감사합니다건강 &gt; 의료상담 &gt; 성형외과  답변수 2  추천수 0  조회수 2458  \"                      ## [5] \"코성형 나이 의사답변  2013.09.21  의협.네이버 지식인 성형외과 상담의 이세환입니다. 코수술이 궁금하시군요. 대부분의 코수술을 대학이후에... 자세한 내용은 성형외과를 방문하여 확인하시기 바랍니다. 비용은 네이버 정책에 의해 말씀드릴 수는 없습니다. 성형외과... 건강 &gt; 의료상담 &gt; 성형외과  답변수 3  추천수 0  조회수 2170  \"                            ## [6] \"\"   qq &lt;- str_replace_all(qq, \"\\\\W\", \" \") head(qq)   ## [1] \"여고생쌍커플수술후부작용어떻하죠 재수술  의사답변  2012 01 28  안녕하세요 대한의사협회 네이버 지식iN 의료 상담 성형외과 전문의 김진왕 입니다  문의 주신 내용 잘보았습니다     따라서 성형외과전문의 선생님과 직접 온라인과 오프라인 상으로 충분한 상담을 하신후 신중한 선택을 하시어 적절한    건강   의료상담   외과  답변수 3  추천수 0  조회수 326  \" ## [2] \"\"                                                                                                                                                                                                                                                                                                                                                        ## [3] \"18살 여고생이에여ㅎ   \"                                                                                                                                                                                                                                                                                                                                  ## [4] \"18살 여고생이에여ㅎ 수능끗나고 바로 성형하러     의사답변  2013 06 08  하이닥 네이버 지식iN 성형외과 상담의 한형일 입니다  성형 수술이 무슨 공업용 상품이 아니므로 수는 끝나고    직접 성형외과 상담을 해야합니다  질문내용에 좋은 답글이 되었길 바랍니다  감사합니다건강   의료상담   성형외과  답변수 2  추천수 0  조회수 2458  \"                      ## [5] \"코성형 나이 의사답변  2013 09 21  의협 네이버 지식인 성형외과 상담의 이세환입니다  코수술이 궁금하시군요  대부분의 코수술을 대학이후에    자세한 내용은 성형외과를 방문하여 확인하시기 바랍니다  비용은 네이버 정책에 의해 말씀드릴 수는 없습니다  성형외과    건강   의료상담   성형외과  답변수 3  추천수 0  조회수 2170  \"                            ## [6] \"\"   qqn &lt;- extractNoun(qq)  class(qqn)   ## [1] \"list\"   dim(qqn)   ## NULL   qqncount &lt;- table(unlist(qqn)) class(qqncount)   ## [1] \"table\"   dim(qqncount)   ## [1] 616   dfqq &lt;- as.data.frame(qqncount, stringsAsFactors = F) class (dfqq)   ## [1] \"data.frame\"   dim (dfqq)   ## [1] 616   2   summary (dfqq)   ##      Var1                Freq         ##  Length:616         Min.   :  1.000   ##  Class :character   1st Qu.:  1.000   ##  Mode  :character   Median :  1.000   ##                     Mean   :  4.497   ##                     3rd Qu.:  3.000   ##                     Max.   :198.000   dfqq &lt;- filter(dfqq, nchar(Var1) &gt;= 2) summary(dfqq)   ##      Var1                Freq         ##  Length:516         Min.   :  1.000   ##  Class :character   1st Qu.:  1.000   ##  Mode  :character   Median :  1.000   ##                     Mean   :  3.855   ##                     3rd Qu.:  3.000   ##                     Max.   :134.000   wordcloud   pal &lt;- brewer.pal(8, \"Dark2\")  wordcloud(words = dfqq$Var1, freq = dfqq$Freq,           min.freq = 2, max.words = 200, random.order = F, rot.per = 0, scale = c(5, 0.3), colors = pal,           family = \"NanumBarunGothic\")      ex3. 국정원 트윗      국정원 댓글 사건 당시 뉴스타파가 공개한 국정원 트윗자료     twt &lt;- read.csv(\"~/Desktop/johnwi_KNOU/Programming/1. R/handouts/0401/Data/twitter.csv\",                     header = T,                     stringsAsFactors = F,                     fileEncoding = \"UTF-8\")  twt &lt;- rename(twt, no = 번호, id = 계정이름, data = 작성일, tw = 내용)   class (twt)   ## [1] \"data.frame\"   dim (twt)   ## [1] 3743    5   head (twt)   ##   X no              id       data ## 1 1  1         ahkorea  11/2/2011 ## 2 2  2      parkkeewoo 12/30/2011 ## 3 3  3         zndvn33   1/5/2012 ## 4 4  4    hong_jihee77  1/23/2012 ## 5 5  5      ceasar1000   2/5/2012 ## 6 6  6 sunsetyellowsky  2/13/2012 ##                                                                                                                                                                                                                                tw ## 1                                                                                민주당의 ISD관련 주장이 전부 거짓으로 속속 드러나고있다. 미국이 ISD를 장악하고 있다고 주장하지만 중재인 123명 가운데 미국인은 10명뿐이라고 한다. ## 2             말로만 '미제타도', 사실은 '미제환장'! 김정일 운구차가 링컨 컨티넬탈이던데 북한의 독재자나 우리나라 종북들이나 겉으로는 노동자, 서민을 대변한다면서 고급 외제차, 아이팟에 자식들 미국 유학에 환장하는 위선자들인거죠 ## 3                                                한나라당이 보수를 버린다네요\\n뭔가착각하는모냥인에 국민들이보수를싫어하는게 아니라뻘짓거리하는분들을싫어하는겁니다야당이진보어쩌고저쩌고한다고해서그들을조아한다고생각하면대착각 ## 4                                   FTA를 대하는 현명한 자세! 사실 자유주의 경제의 가장 큰 수해자는 한국이죠. 농어업분야 피해를 줄이는 정부대안을 최대한, 보완하고 일자리 창출 등 실익을 최대화해 나가는게 현실적인 대처자세일듯! ## 5                                                                                                    곽노현씨 갈수록 가관입니다. 뇌물질에 아들 병역 의혹까지. 도대체 아이들이 뮐 보고 배우겠습니까? 이래도 자리 연연하시겠습니까? ## 6 과거 집권시 한미FTA를 적극 추진하던 세력이 이제 집권하면 폐기하겠다고 주장합니다. 어이없어 말도 안 나오네요. 표만 얻을 수 있다면 국가 안보나 경제가 어떻게 되든 상관없다는 무책임한 행태들, 우리 정치의 후진성을 드러내는 거죠.   twt$tw &lt;- str_replace_all(twt$tw, \"\\\\W\", \" \")   twt_nouns &lt;- extractNoun(twt$tw)   head(twt_nouns)   ## [[1]] ##  [1] \"민주\"   \"당의\"   \"ISD\"    \"관련\"   \"주장\"   \"거짓\"   \"미국\"   \"ISD\"    ##  [9] \"장악하\" \"주장\"   \"하지\"   \"중재인\" \"123\"    \"명\"     \"가운데\" \"미국인\" ## [17] \"10\"     \"명\"     \"한\"     ## ## [[2]] ##  [1] \"말\"             \"미제\"           \"타도\"           \"사실\"           ##  [5] \"미제\"           \"환장\"           \"김정일\"         \"운구차\"         ##  [9] \"링컨\"           \"컨티넬탈이던데\" \"북한\"           \"독재자\"         ## [13] \"우리나라\"       \"북\"             \"겉\"             \"노동자\"         ## [17] \"서민\"           \"대변\"           \"고급\"           \"외제차\"         ## [21] \"아이팟\"         \"자식\"           \"들\"             \"미국\"           ## [25] \"유학\"           \"환장\"           \"하\"             \"위선자들인거\"   ## ## [[3]] ## [1] \"한나라\"                                                                                             ## [2] \"당\"                                                                                                 ## [3] \"보수\"                                                                                               ## [4] \"뭔가착각하는모냥인에\"                                                                               ## [5] \"국민들이보수를싫어하는게\"                                                                           ## [6] \"아니라뻘짓거리하는분들을싫어하는겁니다야당이진보어쩌고저쩌고한다고해서그들을조아한다고생각하면대착\" ## ## [[4]] ##  [1] \"FTA\"    \"현명\"   \"한\"     \"자세\"   \"사실\"   \"자유\"   \"주의\"   \"경제\"   ##  [9] \"수해\"   \"자\"     \"한국\"   \"농어업\" \"분야\"   \"피해\"   \"줄\"     \"정부\"   ## [17] \"대안\"   \"보완\"   \"일자리\" \"창출\"   \"등\"     \"실익\"   \"최대\"   \"화해\"   ## [25] \"현실\"   \"적\"     \"대처\"   \"자세\"   \"듯\"     ## ## [[5]] ##  [1] \"곽노현\"         \"씨\"             \"가관\"           \"뇌물\"           ##  [5] \"질\"             \"아들\"           \"병역\"           \"의혹\"           ##  [9] \"아이들\"         \"뮐\"             \"자리\"           \"연연하시겠습니\" ## ## [[6]] ##  [1] \"과거\"      \"집권\"      \"시\"        \"한미FTA를\" \"적극\"      \"추진\"      ##  [7] \"세력\"      \"집권\"      \"하면\"      \"폐기\"      \"주장\"      \"말\"        ## [13] \"표\"        \"수\"        \"국가\"      \"안보\"      \"경제\"      \"무책임\"    ## [19] \"한\"        \"행태\"      \"들\"        \"우리\"      \"정치\"      \"후진성\"    ## [25] \"것\"   twtcount &lt;- table(unlist(twt_nouns))   df_twt &lt;- as.data.frame(twtcount, stringsAsFactors = F) df_twt &lt;- rename (df_twt, word = Var1, freq = Freq) summary(df_twt)   ##      word                freq          ##  Length:10229       Min.   :   1.000   ##  Class :character   1st Qu.:   1.000   ##  Mode  :character   Median :   1.000   ##                     Mean   :   8.311   ##                     3rd Qu.:   4.000   ##                     Max.   :2216.000   df_twt &lt;- filter(df_twt, nchar(word) &gt;= 2)   frequncy table   tw20 &lt;- df_twt %&gt;% arrange(desc(freq)) %&gt;% head(20) tw20   ##        word freq ## 1      북한 2216 ## 2  대한민국  804 ## 3      우리  779 ## 4      좌파  641 ## 5      국민  550 ## 6      들이  428 ## 7      세력  409 ## 8      친북  385 ## 9    김정일  342 ## 10     단체  335 ## 11     진보  333 ## 12     대선  329 ## 13   천안함  319 ## 14     사회  307 ## 15     정부  283 ## 16   전교조  278 ## 17     주장  269 ## 18     정권  263 ## 19   연평도  262 ## 20     국가  242   ggplot   library(ggplot2) order &lt;- arrange(tw20, freq)$word  ggplot (data = tw20, aes(x = word, y = freq)) + ylim(0,2500) + geom_col() + coord_flip() + scale_x_discrete(limit = order) + geom_text(aes(label = freq), hjust = -0.3, family = \"NanumBarunGothic\")      wordcloud   pal &lt;- brewer.pal(12, \"Paired\")  wordcloud(words = df_twt$word, freq = df_twt$freq,           min.freq = 2, max.words = 200, random.order = F, rot.per = .1, scale = c(6, 0.3), colors = pal,           family = \"NanumBarunGothic\")      Text Mining &amp; WordCloud2   WordCloud2 Introduction page - https://cran.r-project.org/web/packages/wordcloud2/vignettes/wordcloud.html   library(devtools)   ## Loading required package: usethis   library(htmlwidgets) library(htmltools) library(jsonlite) library(yaml) library(base64enc) library(tm)   ## Loading required package: NLP  ## ## Attaching package: 'NLP'  ## The following object is masked from 'package:ggplot2': ## ##     annotate   library(wordcloud2)   Wordcloud2 그리기 기본   wordcloud2(tw20)             wordcloud2(tw20, size = 0.5, col = \"random-dark\" )             rotateRatio = : 몇 도로 기울일건지   wordcloud2(tw20, size = 1, col = \"random-dark\" , rotateRatio = 90)             wordcloud2(tw20, size = 1.5, col = \"random-light\" , shape = \"pentagon\", backgroundColor = \"dark\")             JS 문법으로 color 범위 지정   In_out_colors = \"function(word, weight){ return (weight &gt; 100) ? '#F3EF12' : '#1EC612' }\"   shpae = : “circle”, “cardioid”, “diamond”, “triangle-forward”, “triangel”, “pentagon”, “star”   wordcloud2(df_twt, shape = 'circle', size = 0.8, color = htmlwidgets::JS(In_out_colors), backgroundColor = \"black\")            ",
          
        "categories": ["Study","R","Aidata"],
        "tags": ["R","bigdata","LectureNotes","text-mining","wordcloud"],
        "url": "https://gitgitwi.github.io"/study/r/aidata/LN-0403-Text-mining-with-R/"",
        "teaser": null
      },
    
      
      {
        "title": "Lecture 0403-2 Visualization Maps & Graphs with R",
        "excerpt":
          
            "Visualization Maps   Choropleth Map      지역별 통계치를 색깔 차이로 표현   인구나 소득 같은 특성   미국 주별 강력 범죄율 단계 구분도   import libraries   library(devtools)   ## Loading required package: usethis   # library(htmlwidgets) # library(htmltools) library(jsonlite) library(yaml) library(base64enc) library(tm)   ## Loading required package: NLP   # library(wordcloud2) # library(ggplot2) library(tibble)  # maps library(ggmap)   ## Loading required package: ggplot2  ## ## Attaching package: 'ggplot2'  ## The following object is masked from 'package:NLP': ## ##     annotate  ## Google's Terms of Service: https://cloud.google.com/maps-platform/terms/.  ## Please cite ggmap if you use it! See citation(\"ggmap\") for details.   library(ggiraph) library(mapproj)   ## Loading required package: maps   macOS Catalina 이상에서는 XQuartz 문제로 ggiraph 에러날 수 있음   이 경우 XQuartz 재설치 후   USArrests 내장 dataset 확인   str(USArrests)   ## 'data.frame':    50 obs. of  4 variables: ##  $ Murder  : num  13.2 10 8.1 8.8 9 7.9 3.3 5.9 15.4 17.4 ... ##  $ Assault : int  236 263 294 190 276 204 110 238 335 211 ... ##  $ UrbanPop: int  58 48 80 50 91 78 77 72 80 60 ... ##  $ Rape    : num  21.2 44.5 31 19.5 40.6 38.7 11.1 15.8 31.9 25.8 ...   head(USArrests)   ##            Murder Assault UrbanPop Rape ## Alabama      13.2     236       58 21.2 ## Alaska       10.0     263       48 44.5 ## Arizona       8.1     294       80 31.0 ## Arkansas      8.8     190       50 19.5 ## California    9.0     276       91 40.6 ## Colorado      7.9     204       78 38.7   # View(USArrests)   rownames_to_column() : set index as state &amp; casting to dataframe   crime &lt;- rownames_to_column(USArrests, var = \"state\") crime$state &lt;- tolower(crime$state)   Library tibble      tibble data : 행이름을 가질 수 있으나 연산자로 subset할 때 제거됨   Null 아닌 행이름을 tibble에 지정하려고 하면 error   일반적으로 행이름은 다른 모들 열과 의미가 다른 문자열, 행이름 사용하지 않는 것이 가장 좋음   tibble사용시 데이터 프레임에 행이름 있는지 감지(has_rownames()) 또는 제거 (remove_rownames()), 명시적 열 사이에서 앞뒤 전환(rownames_to_column(), column_to_rownames()), rowid_to_column()   1부터 시작해 순차적인 행 ID를 오름차순으로 하는 dataframe의 시작부분에 열추가, 기존 행 제거   미국 주 지도 데이터   usmap &lt;- map_data(\"state\") str(usmap)   ## 'data.frame':    15537 obs. of  6 variables: ##  $ long     : num  -87.5 -87.5 -87.5 -87.5 -87.6 ... ##  $ lat      : num  30.4 30.4 30.4 30.3 30.3 ... ##  $ group    : num  1 1 1 1 1 1 1 1 1 1 ... ##  $ order    : int  1 2 3 4 5 6 7 8 9 10 ... ##  $ region   : chr  \"alabama\" \"alabama\" \"alabama\" \"alabama\" ... ##  $ subregion: chr  NA NA NA NA ...   ggChoropleth : 단계 구분도   ggChoropleth(data = crime,              aes(fill = Murder, map_id = state),  # state 에 따라 Murder 값              map = usmap)   # crime$UrbanPop ggChoropleth(data = crime,              aes(fill = UrbanPop, map_id = state),  # state 에 따라 Murder 값              map = usmap)   ggChoropleth(data = crime,              aes(fill = Rape, map_id = state),  # state 에 따라 Murder 값              map = usmap,              interactive = T)   대한민국 시도별 인구, 결핵 환자 수 단계 구분도   import libraries   library(stringi) library(devtools)  # korea map devtools::install_github(\"cardiomoon/kormaps2014\")   ## Skipping install of 'kormaps2014' from a github remote, the SHA1 (873f3c5d) has not changed since last install. ##   Use `force = TRUE` to force installation   library(kormaps2014)  library(dplyr)   ## ## Attaching package: 'dplyr'  ## The following objects are masked from 'package:stats': ## ##     filter, lag  ## The following objects are masked from 'package:base': ## ##     intersect, setdiff, setequal, union   시도별 인구 데이터   str(korpop1)   ## 'data.frame':    17 obs. of  25 variables: ##  $ C행정구역별_읍면동     : Factor w/ 3819 levels \"'00\",\"'03\",\"'04\",..: 5 455 681 832 995 1096 1181 1246 1264 1874 ... ##  $ 행정구역별_읍면동      : Factor w/ 3398 levels \"  가경동\",\"  가곡동\",..: 3388 3387 3383 3392 3382 3384 3390 3389 3379 3378 ... ##  $ 시점                   : int  2015 2015 2015 2015 2015 2015 2015 2015 2015 2015 ... ##  $ 총인구_명              : int  9904312 3448737 2466052 2890451 1502881 1538394 1166615 204088 12479061 1518040 ... ##  $ 남자_명                : int  4859535 1701347 1228511 1455017 748867 772243 606924 103210 6309661 768241 ... ##  $ 여자_명                : int  5044777 1747390 1237541 1435434 754014 766151 559691 100878 6169400 749799 ... ##  $ 내국인_계_명           : int  9567196 3404667 2436770 2822601 1481289 1519314 1136755 199617 12026429 1499734 ... ##  $ 내국인_남자_명         : int  4694317 1675339 1211219 1414793 736656 763310 587603 100455 6039800 758601 ... ##  $ 내국인_여자_명         : int  4872879 1729328 1225551 1407808 744633 756004 549152 99162 5986629 741133 ... ##  $ 외국인_계_명           : Factor w/ 1256 levels \"10\",\"100\",\"1009\",..: 618 764 554 1024 394 330 563 772 781 306 ... ##  $ 외국인_남자_명         : Factor w/ 995 levels \"10\",\"100\",\"1002\",..: 200 388 224 589 82 952 262 413 401 985 ... ##  $ 외국인_여자_명         : Factor w/ 856 levels \"10\",\"100\",\"1000\",..: 174 189 66 350 840 8 25 173 196 812 ... ##  $ 가구_계_가구           : int  3914820 1348315 937573 1066297 573181 588395 434058 76419 4537581 611578 ... ##  $ 일반가구_가구          : int  3784490 1335900 928528 1045417 567157 582504 423412 75219 4384742 606117 ... ##  $ 집단가구_가구          : Factor w/ 176 levels \"10\",\"100\",\"102\",..: 64 143 129 148 109 104 68 139 99 155 ... ##  $ 외국인가구_가구        : Factor w/ 764 levels \"10\",\"100\",\"10002\",..: 75 46 709 214 579 574 15 35 126 523 ... ##  $ 주택_계_호             : int  2793244 1164352 738100 942244 486527 468885 357674 81130 3693557 569899 ... ##  $ 단독주택_호            : Factor w/ 2149 levels \"100\",\"1000\",\"1001\",..: 1443 1090 594 34 2019 1941 1777 606 1614 1122 ... ##  $ 아파트_호              : Factor w/ 2466 levels \"10\",\"100\",\"10008\",..: 517 2103 1622 1787 1281 1161 879 1886 873 1031 ... ##  $ 연립주택_호            : Factor w/ 875 levels \"10\",\"100\",\"1002\",..: 54 424 857 266 773 4 782 874 67 241 ... ##  $ 다세대주택_호          : Factor w/ 1428 levels \"10\",\"100\",\"1000\",..: 1192 269 1064 551 1331 803 580 251 1073 60 ... ##  $ 비거주용_건물내_주택_호: Factor w/ 534 levels \"10\",\"100\",\"1001\",..: 279 94 17 473 391 384 421 431 294 19 ... ##  $ 주택이외의_거처_호     : Factor w/ 911 levels \"10\",\"100\",\"1007\",..: 159 643 167 550 26 27 805 295 200 84 ... ##  $ C행정구역별            : chr  \"11\" \"21\" \"22\" \"23\" ... ##  $ code                   : chr  \"11\" \"21\" \"22\" \"23\" ...   encoding error … ??   # str(changeCode(korpop1))   korpop1 &lt;- rename(korpop1, pop = 총인구_명, name = 행정구역별_읍면동)   ggChoropleth(data = korpop1, aes(fill = pop, map_id = code, tooltip = name), map = kormap1, interactive = T)   대한민국 시도별 결핵 환자 수 단계 구분도   str(tbc)   ## 'data.frame':    255 obs. of  5 variables: ##  $ name1 : Factor w/ 18 levels \"강원\",\"경기\",..: 1 2 3 4 5 6 7 8 9 10 ... ##  $ code  : int  32 31 38 37 24 22 25 21 11 29 ... ##  $ name  : Factor w/ 17 levels \"강원도\",\"경기도\",..: 1 2 3 4 5 6 7 8 9 10 ... ##  $ year  : Factor w/ 15 levels \"2001\",\"2002\",..: 1 1 1 1 1 1 1 1 1 1 ... ##  $ NewPts: int  1396 4843 1749 2075 658 1406 1345 3188 11178 NA ...   str(changeCode(tbc))   ## 'data.frame':    255 obs. of  5 variables: ##  $ name1 : chr  \"\\xb0\\xad\\xbf\\xf8\" \"\\xb0\\xe6\\xb1\\xe2\" \"\\xb0泲\" \"\\xb0\\xe6\\xba\\xcf\" ... ##  $ code  : chr  \"32\" \"31\" \"38\" \"37\" ... ##  $ name  : chr  \"\\xb0\\xad\\xbf\\xf8\\xb5\\xb5\" \"\\xb0\\xe6\\xb1\\u2d75\" \"\\xb0\\xe6\\xbb󳲵\\xb5\" \"\\xb0\\xe6\\xbb\\xf3\\xbaϵ\\xb5\" ... ##  $ year  : chr  \"2001\" \"2001\" \"2001\" \"2001\" ... ##  $ NewPts: chr  \"1396\" \"4843\" \"1749\" \"2075\" ...   newtbc &lt;- changeCode(tbc)   ggChoropleth(data = tbc, aes (fill = NewPts, map_id = code, tooltip = name), map = kormap1, interactive = T)   plotly Package - interactive graph      plotly.com   made by JavaScript     library(plotly)   ## ## Attaching package: 'plotly'  ## The following object is masked from 'package:ggmap': ## ##     wind  ## The following object is masked from 'package:ggplot2': ## ##     last_plot  ## The following object is masked from 'package:stats': ## ##     filter  ## The following object is masked from 'package:graphics': ## ##     layout   point chart   p &lt;- ggplot(data = mpg, aes(x = displ, y = hwy, col = drv)) + geom_point() p      ggplotly(p)   ## PhantomJS not found. You can install it with webshot::install_phantomjs(). If it is installed, please make sure the phantomjs executable can be found via the PATH variable.             bar chart   ggplotly( ggplot(data = diamonds, aes(x = cut, fill = clarity)) + geom_bar(position = \"dodge\") )             ggplotly( ggplot(data = diamonds, aes(x = cut, fill = clarity)) + geom_bar() )             dygraphs Package : interactive time series graph   library (dygraphs)   econo &lt;- ggplot2::economics head(econo)   ## # A tibble: 6 x 6 ##   date         pce    pop psavert uempmed unemploy ##   &lt;date&gt;     &lt;dbl&gt;  &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;    &lt;dbl&gt; ## 1 1967-07-01  507. 198712    12.6     4.5     2944 ## 2 1967-08-01  510. 198911    12.6     4.7     2945 ## 3 1967-09-01  516. 199113    11.9     4.6     2958 ## 4 1967-10-01  512. 199311    12.9     4.9     3143 ## 5 1967-11-01  517. 199498    12.8     4.7     3066 ## 6 1967-12-01  525. 199657    11.8     4.8     3018   library(xts)   ## Loading required package: zoo  ## ## Attaching package: 'zoo'  ## The following objects are masked from 'package:base': ## ##     as.Date, as.Date.numeric  ## ## Attaching package: 'xts'  ## The following objects are masked from 'package:dplyr': ## ##     first, last   eco &lt;- xts(econo$unemploy, order.by = econo$date) head(eco)   ##            [,1] ## 1967-07-01 2944 ## 1967-08-01 2945 ## 1967-09-01 2958 ## 1967-10-01 3143 ## 1967-11-01 3066 ## 1967-12-01 3018   dygraph(eco)             dyRangeSelector()   dygraph(eco) %&gt;% dyRangeSelector()             multiple variables      save rate + unemployment rate     eco_a &lt;- xts(econo$psavert, order.by = econo$date) eco_b &lt;- xts(econo$unemploy/1000 , order.by = econo$date)  eco2 &lt;- cbind(eco_a, eco_b) colnames(eco2) &lt;- c(\"psavert\", \"unemploy\") head(eco2)   ##            psavert unemploy ## 1967-07-01    12.6    2.944 ## 1967-08-01    12.6    2.945 ## 1967-09-01    11.9    2.958 ## 1967-10-01    12.9    3.143 ## 1967-11-01    12.8    3.066 ## 1967-12-01    11.8    3.018   dygraph(eco2) %&gt;% dyRangeSelector()             통계 분석 기법을 이용한 가설 검정   통계적 가설 검정      Descriptive statistics 기술 통계 : 데이터 요약 ; 지금까지 R을 통해서 본 내용   Inferential statistics 추론 통계 : 어떤 값이 발생할 확률 계산            statistically significant : 차이가 우연히 나타날 확률이 적은 경우       not statistically significant : 차이가 우연히 나타날 확률이 큰 경우       기술 통계 분석에서 집단 간 차이가 있는 것으로 나타나더라도 이는 우연에 의한 차이일 수 있음 -&gt; 데이터를 이용해 신뢰할 수 있는 결론을 내려면 유의확률을 계산하는 통계적 가설 검정 절차를 거쳐야 함           Statistical hypothesis test 통계적 가설 검정      유의확률을 이용해 가설 검정   Significance probability, p-value : 유의확률            실제로는 집단 간 차이가 없는데 우연히 차이가 있는 데이터가 추출될 확률       분석 결과 유의확률이 크게 나타날 경우                    집단 간 차이가 통계적으로 유의하지 않다고 해석           우연에 의한 관찰 결과일 가능성                       분석 결과 유의확률이 적게 나타날 경우                    집단 간 차이가 통계적으로 유의하다고 해석           우연으로 보기 힘들다                           t-test ; 두집단 평균 비교      두 집단의 평균에 유의미한 차이가 있는지   compact cars vs. suv cars   import data set   mpg &lt;- as.data.frame(ggplot2::mpg) mpg_diff &lt;- mpg %&gt;% select(class, cty) %&gt;% filter(class %in% c(\"compact\", \"suv\")) head(mpg_diff)   ##     class cty ## 1 compact  18 ## 2 compact  21 ## 3 compact  20 ## 4 compact  21 ## 5 compact  16 ## 6 compact  18   table(mpg_diff$class)   ## ## compact     suv ##      47      62   table(mpg_diff$cty)   ## ##  9 11 12 13 14 15 16 17 18 19 20 21 22 24 26 28 33 ##  2 13  6 13 12  9  5  5 10  6  7 12  3  2  2  1  1   t-test   t.test(data=mpg_diff, cty ~ class, var.equal = T)   ## ##  Two Sample t-test ## ## data:  cty by class ## t = 11.917, df = 107, p-value &lt; 2.2e-16 ## alternative hypothesis: true difference in means is not equal to 0 ## 95 percent confidence interval: ##  5.525180 7.730139 ## sample estimates: ## mean in group compact     mean in group suv ##              20.12766              13.50000      alternative hypothesis 대립 가설 : 결과 값 != 0 이면 신뢰 가능   95% 유효범위에서 p-value == 7.730139 - 5.525180 &lt; 2.2e-16   regular oil vs premium oil   mpg_diff2 &lt;- mpg %&gt;% select(fl, cty) %&gt;% filter(fl %in% c(\"r\", \"p\")) table(mpg_diff2$fl)   ## ##   p   r ##  52 168   t-test   t.test(data=mpg_diff2, cty ~ fl, var.equal = T)   ## ##  Two Sample t-test ## ## data:  cty by fl ## t = 1.0662, df = 218, p-value = 0.2875 ## alternative hypothesis: true difference in means is not equal to 0 ## 95 percent confidence interval: ##  -0.5322946  1.7868733 ## sample estimates: ## mean in group p mean in group r ##        17.36538        16.73810      평균 차이가 거의 나지 않음 -&gt; 고급유라고 해서 시내주행 연비가 좋아지는 것이 아니다   Correlation Analysis 상관 분석      두 변수가 서로 관련 있는지 검정   상관계수 Correlation Coefficient            두 변수가 얼마나 관련 있는지, 관련성의 정도       절대값 0~1 사이 값, 1에 가까울수록 관련성 큼       상관계수가 양수면 정비례, 음수면 반비례             econo &lt;- as.data.frame(ggplot2::economics)   cor.test()   numbers of unemploy - personal consumptions   cor.test(econo$unemploy, econo$pce)   ## ##  Pearson's product-moment correlation ## ## data:  econo$unemploy and econo$pce ## t = 18.63, df = 572, p-value &lt; 2.2e-16 ## alternative hypothesis: true correlation is not equal to 0 ## 95 percent confidence interval: ##  0.5608868 0.6630124 ## sample estimates: ##       cor ## 0.6145176      correlation == 0.6145176 ; 어느정도 상관관계가 있음   Correlation Matrix Heatmap : 상관행렬 히트맵      Correlation Matrix : 다변수간 상관계수를 행렬로     head(mtcars)   ##                    mpg cyl disp  hp drat    wt  qsec vs am gear carb ## Mazda RX4         21.0   6  160 110 3.90 2.620 16.46  0  1    4    4 ## Mazda RX4 Wag     21.0   6  160 110 3.90 2.875 17.02  0  1    4    4 ## Datsun 710        22.8   4  108  93 3.85 2.320 18.61  1  1    4    1 ## Hornet 4 Drive    21.4   6  258 110 3.08 3.215 19.44  1  0    3    1 ## Hornet Sportabout 18.7   8  360 175 3.15 3.440 17.02  0  0    3    2 ## Valiant           18.1   6  225 105 2.76 3.460 20.22  1  0    3    1   cor() : correlation matrix   carcor &lt;- cor(mtcars) # carcor round (carcor, 2)   ##        mpg   cyl  disp    hp  drat    wt  qsec    vs    am  gear  carb ## mpg   1.00 -0.85 -0.85 -0.78  0.68 -0.87  0.42  0.66  0.60  0.48 -0.55 ## cyl  -0.85  1.00  0.90  0.83 -0.70  0.78 -0.59 -0.81 -0.52 -0.49  0.53 ## disp -0.85  0.90  1.00  0.79 -0.71  0.89 -0.43 -0.71 -0.59 -0.56  0.39 ## hp   -0.78  0.83  0.79  1.00 -0.45  0.66 -0.71 -0.72 -0.24 -0.13  0.75 ## drat  0.68 -0.70 -0.71 -0.45  1.00 -0.71  0.09  0.44  0.71  0.70 -0.09 ## wt   -0.87  0.78  0.89  0.66 -0.71  1.00 -0.17 -0.55 -0.69 -0.58  0.43 ## qsec  0.42 -0.59 -0.43 -0.71  0.09 -0.17  1.00  0.74 -0.23 -0.21 -0.66 ## vs    0.66 -0.81 -0.71 -0.72  0.44 -0.55  0.74  1.00  0.17  0.21 -0.57 ## am    0.60 -0.52 -0.59 -0.24  0.71 -0.69 -0.23  0.17  1.00  0.79  0.06 ## gear  0.48 -0.49 -0.56 -0.13  0.70 -0.58 -0.21  0.21  0.79  1.00  0.27 ## carb -0.55  0.53  0.39  0.75 -0.09  0.43 -0.66 -0.57  0.06  0.27  1.00   corrplot Package : heat map   library(corrplot)   ## corrplot 0.84 loaded   corrplot(carcor)      corrplot(carcor, method = \"pie\")      corrplot(carcor, method = \"number\")      colorRampPalette() : color palette 만드는 함수   col &lt;- colorRampPalette(c(\"#BB4444\", \"#EE9988\", \"#FFFFFF\", \"#77AADD\", \"#4477AA\"))  corrplot(carcor, method = \"square\",          # 색상 200개          col = col(200),          # type = \"lower\" 왼쪽 아래만 표시          type = \"lower\",          # 유사한 상관계수끼리 군집화          order = \"hclust\",          # 상관계수 색깔          addCoef.col = \"black\",          # 변수명 색깔          tl.col = \"black\",          # 변수명 45도 기울임          tl.srt = 30,          # 대각 행렬 제외          diag = F          )     ",
          
        "categories": ["Study","R","Aidata"],
        "tags": ["R","bigdata","LectureNotes","visualizion","graph","basic statistics"],
        "url": "https://gitgitwi.github.io"/study/r/aidata/Lecture-0403-2-Visualization-Maps-&-Graphs/"",
        "teaser": null
      },
    
      
      {
        "title": "LN-Docker-동빈나's Docker 활용 1강~",
        "excerpt":
          
            "  - [AWS 서버 인스턴스 생성](#aws-) \t\t- [서버 인스턴스](#-) \t\t- [AMI 선택](#ami-) \t\t- [인스턴스 유형 선택](#-) \t\t- [Key pair](#key-pair) \t\t\t- [Error 같은 Normal Message](#error-normal-message) - [보다 편한 EC2 활용을 위한 `Jupyter Notebook` 설치](#-ec2-jupyter-notebook-) \t\t- [1. check python3 version](#1-check-python3-version) \t\t- [2. python3 개발환경 설치위한 pip install](#2-python3-pip-install) \t\t- [3. pip를 통해 notebook install](#3-pip-notebook-install) \t\t- [4. notebook에서 사용할 p/w 설정](#4-notebook-pw-) \t\t- [5. System terminal이 아닌 WebBrowser jupyter terminal을 사용하기 위한 설정](#5-system-terminal-webbrowser-jupyter-terminal-) \t\t- [6. jupyter가 background에서 실행되도록 설정](#6-jupyter-background-) \t\t- [7. SSL 접속을 위한 SSL KeyPair 생성](#7-ssl-ssl-keypair-) \t\t- [8. SSH 접속 가능하도록 `jupyter_notebook_config.py` 환경설정 수정](#8-ssh-jupyternotebookconfigpy-) \t\t- [9. System 기본 프로그램으로 jupyter가 실행되도록 설정](#9-system-jupyter-) - [실행 상태 확인](#-)        lecture playlist  : Docker 활용 및 배포 자동화 실전 초급   lecturer  : 동빈나   01 실습용 AWS EC2 인스턴스 생성 및 접속   AWS 서버 인스턴스 생성   Docker Machine 설치를 위한 객체 생성   서버 인스턴스     EC2   강의일 현재까지 AWS에서 가장 많이 쓰이고 있는 서버   AMI 선택     Amazon Machine Image   Ubuntu Server 18.04 (LTS) 선택      인스턴스 유형 선택     t2 micro   free-tier 에서 사용 가능한 유일한 type      유형 선택 후 시작하기 버튼 누르면 바로 step7으로 넘어감      처음에 잘못 눌렀는지..AMI를 AmazonLinux로 잘못 선택해서 왜 sudo가 안먹히나 또 헤맸다..   Key pair  보안을 위한 key pair 생성 및 download     별도의 workspace 디렉토리 생성하여 관리   파일 속성을 통해 보안 설정 필수   linux/Mac chmod 400를 통해 보안 설정   terminal 열어서 SSH 방식으로 연결해야 함   ex.  $ ssh -i /{path}/{keypair.pem} ubuntu@{public DNS}    aws instance connect 눌렀을 때 나오는 안내 화면에서 예:에 있는 거 그대로 가져와서 경로만 써주면 됨      Error 같은 Normal Message  ssh 방식으로 연결 시도하고 나니, 아래처럼 메시지가 떴음   can't be established 라는 메시지 때문에 오류인 줄 알고 헤맸는데, 그냥 yes 하면 연결 되는 거 였음..   The authenticity of host '###' cant be established. ECDSA key fingerprint is SHA256:###. Are you sure you want to continue connecting (yes/no/[fingerprint])? yes   Welcome to Ubuntu..!!   EC2의 Ubuntu에 접속되어 linux 명령으로 작업하면 된다   Welcome to Ubuntu 18.04.3 LTS (GNU/Linux 4.15.0-1057-aws x86_64)   * Documentation:  https://help.ubuntu.com  * Management:     https://landscape.canonical.com  * Support:        https://ubuntu.com/advantage    System information as of Sat Apr  4 10:10:05 UTC 2020    System load:  0.25              Processes:           91   Usage of /:   13.6% of 7.69GB   Users logged in:     0   Memory usage: 15%               IP address for eth0: 172.31.45.116   Swap usage:   0%  0 packages can be updated. 0 updates are security updates.  ...  ~$ pwd /home/ubuntu   참고     SSH 방식 접속 방법  : lhh3520.tistory.com   SSH Key 만드는 법 : uroa.tistory.com   02 Jupyter Notebook 설치, HTTPS 적용, 시스템 서비스 설정하기   보다 편한 EC2 활용을 위한 Jupyter Notebook 설치   System terminal이 아닌 Jupyter Notebook의 terminal에서 Server 접속 위함   1. check python3 version  ~$ python3 --version Python 3.6.9   2. python3 개발환경 설치위한 pip install   ~$ sudo apt-get install python3-pip Reading package lists... Done Building dependency tree        Reading state information... Done The following additional packages will be installed:   3. pip를 통해 notebook install   ~$ sudo pip3 install notebook   4. notebook에서 사용할 p/w 설정      이때 return 되는 sha 값을 반드시 잘 저장해둔다; SSH 만들기 위함!! ```python ~$ python3   Python 3.6.9 (default, Nov  7 2019, 10:44:02) [GCC 8.3.0] on linux Type “help”, “copyright”, “credits” or “license” for more information.                 from notebook.auth import passwd passwd() Enter password: Verify password: ```            5. System terminal이 아닌 WebBrowser jupyter terminal을 사용하기 위한 설정   ~$ jupyter notebook --generate-config Writing default config to: /home/ubuntu/.jupyter/jupyter_notebook_config.py  ~$ sudo vi /home/ubuntu/.jupyter/jupyter_notebook_config.py  여기서 jupyter_notebook_config.py 파일이 열림, 최하단에 아래 내용 입력  c = get_config() c.NotebookApp.password = u'sha1:7134d8d88d92:6e362dcebe594cc7e3eb809e2936c089ba22cd42' c.NotebookApp.ip = '172.31.45.116' c.NotebookApp.notebook_dir = '/' c.NotebookApp.certfile = u'/home/ubuntu/ssl/gitgit.pem' c.NotebookApp.keyfile = u'/home/ubuntu/ssl/gitgit.key'   ~$ sudo jupyter-notebook --allow-root   아래와 같이 ip주소가 뜨면 성공  [I 10:21:59.278 NotebookApp] The Jupyter Notebook is running at: [I 10:21:59.278 NotebookApp] http://xxx.xxx.xxx.xxx:8888/  ip주소로 접속 -&gt; jupyter pw 입력 -&gt; New Terminal   6. jupyter가 background에서 실행되도록 설정   ~$ bg [1]+ sudo jupyter-notebook --allow-root &amp; ~$ disown -h     보안을 위해 접속ip 확인 및 ip kill   ~$   tcp        0      0 @@@.@@@.@@@.@@@:8888      0.0.0.0:*               LISTEN      7410/python3         tcp        0      0 @@@.@@@.@@@.@@@:8888      @@@.@@@.@@@.@@@:63856   ESTABLISHED 7410/python3         ...  ~$ sudo kill -9 7410 [1]+  Killed                  sudo jupyter-notebook --allow-root   7. SSL 접속을 위한 SSL KeyPair 생성   ~$ mkdir ssl ~$ cd ssl ~/ssl$ sudo openssl req -x509 -nodes -days 365 -newkey rsa:1024 -keyout \"{OpenKeyName}.key\" -out \"{PrivateKeyName}.pem\" -batch   sudo openssl req -x509 -nodes -days 365 -newkey rsa:1024 -keyout “gitgit.key” -out “gitgit.pem” -batch   8. SSH 접속 가능하도록 jupyter_notebook_config.py 환경설정 수정   ~/ssl$ sudo vi /home/ubuntu/.jupyter/jupyter_notebook_config.py   9. System 기본 프로그램으로 jupyter가 실행되도록 설정   ~/ssl$ which jupyter-notebook /usr/local/bin/jupyter-notebook  ~/ssl$ sudo vi /etc/systemd/system/jupyter.service  ~/ssl$ sudo systemctl enable jupyter Created symlink /etc/systemd/system/multi-user.target.wants/jupyter.service → /etc/systemd/system/jupyter.service.  ~/ssl$ sudo systemctl start jupyter  # 실행 상태 확인 ~/ssl$ sudo systemctl status jupyter ● jupyter.service - Jupyter Notebook Server    Loaded: loaded (/etc/systemd/system/jupyter.service; enabled; vendor preset:    Active: active (running) since Sat 2020-04-04 10:56:44 UTC; 9s ago   접속 시 신뢰할 수 없는 인증서 문제가 발생하나, 무시하고 진행하면 됨     사설인증서 SSL을 사용하기 때문   희한하게 내 Mac-Chrome에서는 무시하고 진행 메뉴가 안보이고 인증서 따로 저장하는 메뉴도 없음.. 그냥 꽉~막힘 ㅠ googling해도 깔끔한 해결방법은 찾기 힘들었는데, FireFox로 여니까 된다..내 금쪽 같은 토요일 2시간 뚝딱!  ",
          
        "categories": ["Study","Cloud","AWS","Docker"],
        "tags": ["Docker","LectureNotes","AWS","동빈나"],
        "url": "https://gitgitwi.github.io"/study/cloud/aws/docker/"",
        "teaser": null
      },
    
      
      {
        "title": "왕초보도 따라하는 도커 기초 강의 by 재즐보프 youtube",
        "excerpt":
          
            "Docker basic by 재즐보프’s Youtube   왕초보도 따라하는 도커 기초 강의 lecture notes   Install Apps in Docker   in Terminal    (base) JnWui-MacBook-Pro:~ WnJ$ sudo -i  JnWui-MacBook-Pro:~ root# docker search tomcat9  # 검색 결과로 나온 tomcat9 관련 이미지 중 원하는 것을 찾아 # docker에서 8080 포트로 바로 실행  JnWui-MacBook-Pro:~ root# docker run -d -p 8080:8080 --name tc ykaj9758/tomcat9        run : 처음 설치시에만 run 명령어 사용, 이후부터는 start  명령어로 tomcat 사용 가능   -d : background 실행      127.0.0.1:8080d 에서 tomcat 9 실행 확인     JnWui-MacBook-Pro:~ root# docker ps  CONTAINER ID        IMAGE               COMMAND                  CREATED             STATUS              PORTS                    NAMES 38ca9cccee3e        ykaj9758/tomcat9    \"/opt/tomcat/apache-…\"   8 minutes ago       Up 8 minutes        0.0.0.0:8080-&gt;8080/tcp   tc    현재 실행 중인 컨테이너 확인    JnWui-MacBook-Pro:~ root# docker stop tc  tc JnWui-MacBook-Pro:~ root# docker ps CONTAINER ID        IMAGE               COMMAND             CREATED             STATUS              PORTS               NAMES    실행중인 프로그램 stop   Docker Registry   docker hub   이미지만 다운받고 싶은 경우    docker pull [ image name ]    설치한 이미지 확인    JnWui-MacBook-Pro:~ root# docker images  REPOSITORY          TAG                 IMAGE ID            CREATED             SIZE ykaj9758/tomcat9    latest              4fe6b09b4e59        23 months ago       1.16GB    Docker Lifecycle    # nginx 이미지 가져오기  bash-3.2# docker pull nginx  Using default tag: latest latest: Pulling from library/nginx c499e6d256d6: Pull complete 74cda408e262: Pull complete ffadbd415ab7: Pull complete Digest: sha256:282530fcb7cd19f3848c7b611043f82ae4be3781cb00105a1d593d7e6286b596 Status: Downloaded newer image for nginx:latest docker.io/library/nginx:latest  # nginx를 nx라는 이름 지정하여 port 80번에 할당, 컨테이너 생성  bash-3.2# docker create -p 80:80 --name nx nginx  # 현재 실행중인 모든 컨테이너 조회  bash-3.2# docker ps -a   bash-3.2# docker start 3b46b4a158d7     위의 내용은 아래 한줄로도 가능    bash-3.2# docker run -d -p 80:80 --name nx2 nginx     bash-3.2# docker stop nx2  bash-3.2# docker ps -a  CONTAINER ID        IMAGE               COMMAND                  CREATED              STATUS                          PORTS               NAMES a1d0718587fc        nginx               \"nginx -g 'daemon of…\"   About a minute ago   Exited (0) 13 seconds ago                           nx2 3b46b4a158d7        nginx               \"nginx -g 'daemon of…\"   6 minutes ago        Exited (0) About a minute ago                       nx 38ca9cccee3e        ykaj9758/tomcat9    \"/opt/tomcat/apache-…\"   57 minutes ago       Exited (143) 47 minutes ago                         tc      bash-3.2# docker rm 3b46b4a158d7  3b46b4a158d7  bash-3.2# docker ps -a  CONTAINER ID        IMAGE               COMMAND                  CREATED             STATUS                        PORTS               NAMES a1d0718587fc        nginx               \"nginx -g 'daemon of…\"   2 minutes ago       Exited (0) 57 seconds ago                         nx2 38ca9cccee3e        ykaj9758/tomcat9    \"/opt/tomcat/apache-…\"   58 minutes ago      Exited (143) 48 minutes ago                       tc      bash-3.2# docker stop nx  nx  bash-3.2# docker start nx  nx  bash-3.2# docker restart nx  nx     bash-3.2# docker stop nx  nx  bash-3.2# docker rmi nx  bash-3.2# docker rmi nginx  Untagged: nginx:latest Untagged: nginx@sha256:282530fcb7cd19f3848c7b611043f82ae4be3781cb00105a1d593d7e6286b596 Deleted: sha256:ed21b7a8aee9cc677df6d7f38a641fa0e3c05f65592c592c9f28c42b3dd89291 Deleted: sha256:8a305f371a6c3c445a1dfc500c1364743868a269ab8cdaf95902692e82168352 Deleted: sha256:d079ef06ec1f10a8050887365f9a940b39547ba6bcc46b16a463e740984f3223 Deleted: sha256:c3a984abe8a88059915bb6c7a1d249fd1ccc16d931334ac8816540b0eb686b45     Layers      containers -&gt; image -&gt; overlay2   overlay2 로 갈수록 용량이 급격히 커짐, 컨테이너 대부분의 정보를 overlay2가 갖고 있음   Useful Commands   execute inner container terminal      -it : input &amp; terminal    bash-3.2# sudo docker exec -it tc /bin/bash  # terminal이 tomcat의 hostname/containerID 로 열림 [tomcat@38ca9cccee3e /]$ ls anaconda-post.log  bin  dev  etc  home  lib  lib64  media  mnt  opt  proc  root  run  sbin  srv  sys  tmp  usr  var  [tomcat@38ca9cccee3e /]$ exit exit  bash-3.2#     logs {container name} print console output log    bash-3.2# docker logs tc    cp {path1} {path2} : copy a file from path1 to path2    bash-3.2# docker cp {filename} {path}  bash-3.2# cat {filename}       -q : 현재 containers id 값만 조회   `  ` : ` ` 안의 명령에 대한 결과값을 return    bash-3.2# docker ps -a -q 38ca9cccee3e  # containers id 값을 모두 가져와서 stop bash-3.2# docker stop `docker ps -a -q` 38ca9cccee3e     Ways to stop &amp; remove all of containers &amp; images    sudo docker stop `sudo docker ps -a -q` sudo docker rm `sudo docker ps -a -q`  sudo docker rmi `sudo docker images -q`    temporary container   run과 함께 --rm 명령, container stop 과 함께 자동으로 삭제됨    bash-3.2# docker run -d --name tctemp -p 8090:8090 --rm ykaj9758/tomcat9 2a45b3053e169292aefb0a050283b0fe8589b6b275e18f326dc3f87de4ffe6f0  bash-3.2# docker ps -a CONTAINER ID        IMAGE               COMMAND                  CREATED              STATUS                       PORTS                              NAMES 2a45b3053e16        ykaj9758/tomcat9    \"/opt/tomcat/apache-…\"   About a minute ago   Up 59 seconds                8080/tcp, 0.0.0.0:8090-&gt;8090/tcp   tctemp 38ca9cccee3e        ykaj9758/tomcat9    \"/opt/tomcat/apache-…\"   2 hours ago          Exited (143) 7 minutes ago                                      tc  bash-3.2# docker stop tctemp tctemp  bash-3.2# docker ps -a CONTAINER ID        IMAGE               COMMAND                  CREATED             STATUS                       PORTS               NAMES 38ca9cccee3e        ykaj9758/tomcat9    \"/opt/tomcat/apache-…\"   2 hours ago         Exited (143) 8 minutes ago                       tc     MySQL 설치 &amp; 실행   Installation      -e  : 환경변수설정            MYSQL_ROOT_PASSWORD= : 반드시 설정           mysql : 최신버전 설치            mysql:5 : mysql5 설치            bash-3.2# docker run --name mymysql -e MYSQL_ROOT_PASSWORD=1234 -d mysql  # bash-3.2# docker run --name mymysql5 -e MYSQL_ROOT_PASSWORD=1234 -d mysql:5.7  Unable to find image 'mysql:latest' locally latest: Pulling from library/mysql  # ps 명령으로 설치 됐는지 확인, name / port 확인 bash-3.2# docker ps  CONTAINER ID        IMAGE               COMMAND                  CREATED             STATUS              PORTS                 NAMES 7001e556ecd4        mysql               \"docker-entrypoint.s…\"   3 minutes ago       Up 3 minutes        3306/tcp, 33060/tcp   mymysql     Exectute    bash-3.2# docker exec -it mymysql mysql -u root -p  # MySQL 접속 화면 Enter password:  Welcome to the MySQL monitor.  Commands end with ; or \\g. Your MySQL connection id is 8 Server version: 8.0.19 MySQL Community Server - GPL  Copyright (c) 2000, 2020, Oracle and/or its affiliates. All rights reserved.  Oracle is a registered trademark of Oracle Corporation and/or its affiliates. Other names may be trademarks of their respective owners.  Type 'help;' or '\\h' for help. Type '\\c' to clear the current input statement.  mysql&gt;    Oracle XE 11g   Installation  bash-3.2# docker run -d -p 49161:1521 oracleinanutshell/oracle-xe-11g  ",
          
        "categories": ["Study","Cloud","Docker"],
        "tags": ["Docker","LectureNotes","Oracle","MySQL"],
        "url": "https://gitgitwi.github.io"/study/cloud/docker/docker-basic-01/"",
        "teaser": null
      },
    
      
      {
        "title": "LN-Docker-동빈나's Docker 활용 1강~2강",
        "excerpt":
          
            "01 실습용 AWS EC2 인스턴스 생성 및 접속   AWS 서버 인스턴스 생성   Docker Machine 설치를 위한 객체 생성   서버 인스턴스     EC2   강의일 현재까지 AWS에서 가장 많이 쓰이고 있는 서버   AMI 선택     Amazon Machine Image   Ubuntu Server 18.04 (LTS) 선택      인스턴스 유형 선택     t2 micro   free-tier 에서 사용 가능한 유일한 type      유형 선택 후 시작하기 버튼 누르면 바로 step7으로 넘어감      처음에 잘못 눌렀는지..AMI를 AmazonLinux로 잘못 선택해서 왜 sudo가 안먹히나 또 헤맸다..   Key pair  보안을 위한 key pair 생성 및 download     별도의 workspace 디렉토리 생성하여 관리   파일 속성을 통해 보안 설정 필수   linux/Mac chmod 400를 통해 보안 설정   terminal 열어서 SSH 방식으로 연결해야 함   ex.  $ ssh -i /{path}/{keypair.pem} ubuntu@{public DNS}   aws instance connect 눌렀을 때 나오는 안내 화면에서 예:에 있는 거 그대로 가져와서 경로만 써주면 됨      Error 같은 Normal Message  ssh 방식으로 연결 시도하고 나니, 아래처럼 메시지가 떴음   can't be established 라는 메시지 때문에 오류인 줄 알고 헤맸는데, 그냥 yes 하면 연결 되는 거 였음..   The authenticity of host '###' cant be established. ECDSA key fingerprint is SHA256:###. Are you sure you want to continue connecting (yes/no/[fingerprint])? yes   Welcome to Ubuntu..!!   EC2의 Ubuntu에 접속되어 linux 명령으로 작업하면 된다   Welcome to Ubuntu 18.04.3 LTS (GNU/Linux 4.15.0-1057-aws x86_64)   * Documentation:  https://help.ubuntu.com  * Management:     https://landscape.canonical.com  * Support:        https://ubuntu.com/advantage    System information as of Sat Apr  4 10:10:05 UTC 2020    System load:  0.25              Processes:           91   Usage of /:   13.6% of 7.69GB   Users logged in:     0   Memory usage: 15%               IP address for eth0: 172.31.45.116   Swap usage:   0%  0 packages can be updated. 0 updates are security updates.  ...  ~$ pwd /home/ubuntu   참고     SSH 방식 접속 방법  : lhh3520.tistory.com   SSH Key 만드는 법 : uroa.tistory.com   02 Jupyter Notebook 설치, HTTPS 적용, 시스템 서비스 설정하기   보다 편한 EC2 활용을 위한 Jupyter Notebook 설치   System terminal이 아닌 Jupyter Notebook의 terminal에서 Server 접속 위함   1. check python3 version  ~$ python3 --version Python 3.6.9   2. python3 개발환경 설치위한 pip install   ~$ sudo apt-get install python3-pip Reading package lists... Done Building dependency tree        Reading state information... Done The following additional packages will be installed:   3. pip를 통해 notebook install   ~$ sudo pip3 install notebook   4. notebook에서 사용할 p/w 설정      이때 return 되는 sha 값을 반드시 잘 저장해둔다; SSH 만들기 위함!!   ~$ python3  Python 3.6.9 (default, Nov  7 2019, 10:44:02) [GCC 8.3.0] on linux Type \"help\", \"copyright\", \"credits\" or \"license\" for more information.  from notebook.auth import passwd passwd() Enter password: Verify password:   5. System terminal이 아닌 WebBrowser jupyter terminal을 사용하기 위한 설정   ~$ jupyter notebook --generate-config Writing default config to: /home/ubuntu/.jupyter/jupyter_notebook_config.py  ~$ sudo vi /home/ubuntu/.jupyter/jupyter_notebook_config.py   여기서 jupyter_notebook_config.py 파일이 열림, 최하단에 아래 내용 입력   c = get_config() c.NotebookApp.password = u'sha1:~~~~' c.NotebookApp.ip = '@@@.@@@.@@@.@@@' c.NotebookApp.notebook_dir = '/' c.NotebookApp.certfile = u'/home/ubuntu/ssl/@@@.pem' c.NotebookApp.keyfile = u'/home/ubuntu/ssl/@@@.key'   ~$ sudo jupyter-notebook --allow-root   아래와 같이 ip주소가 뜨면 성공  [I 10:21:59.278 NotebookApp] The Jupyter Notebook is running at: [I 10:21:59.278 NotebookApp] http://xxx.xxx.xxx.xxx:8888/  ip주소로 접속 -&gt; jupyter pw 입력 -&gt; New Terminal   6. jupyter가 background에서 실행되도록 설정   ~$ bg [1]+ sudo jupyter-notebook --allow-root &amp; ~$ disown -h     보안을 위해 접속ip 확인 및 ip kill   ~$   tcp        0      0 @@@.@@@.@@@.@@@:8888      0.0.0.0:*               LISTEN      7410/python3         tcp        0      0 @@@.@@@.@@@.@@@:8888      @@@.@@@.@@@.@@@:63856   ESTABLISHED 7410/python3         ...  ~$ sudo kill -9 7410 [1]+  Killed                  sudo jupyter-notebook --allow-root   7. SSL 접속을 위한 SSL KeyPair 생성   ~$ mkdir ssl ~$ cd ssl ~/ssl$ sudo openssl req -x509 -nodes -days 365 -newkey rsa:1024 -keyout \"{OpenKeyName}.key\" -out \"{PrivateKeyName}.pem\" -batch   8. SSH 접속 가능하도록 jupyter_notebook_config.py 환경설정 수정   ~/ssl$ sudo vi /home/ubuntu/.jupyter/jupyter_notebook_config.py   9. System 기본 프로그램으로 jupyter가 실행되도록 설정   ~/ssl$ which jupyter-notebook /usr/local/bin/jupyter-notebook  ~/ssl$ sudo vi /etc/systemd/system/jupyter.service  ~/ssl$ sudo systemctl enable jupyter Created symlink /etc/systemd/system/multi-user.target.wants/jupyter.service → /etc/systemd/system/jupyter.service.  ~/ssl$ sudo systemctl start jupyter  # 실행 상태 확인 ~/ssl$ sudo systemctl status jupyter ● jupyter.service - Jupyter Notebook Server    Loaded: loaded (/etc/systemd/system/jupyter.service; enabled; vendor preset:    Active: active (running) since Sat 2020-04-04 10:56:44 UTC; 9s ago   접속 시 신뢰할 수 없는 인증서 문제가 발생하나, 무시하고 진행하면 됨     사설인증서 SSL을 사용하기 때문   희한하게 내 Mac-Chrome에서는 무시하고 진행 메뉴가 안보이고 인증서 따로 저장하는 메뉴도 없음.. 그냥 꽉~막힘 ㅠ googling해도 깔끔한 해결방법은 찾기 힘들었는데, FireFox로 여니까 된다..내 금쪽 같은 토요일 2시간 뚝딱!  ",
          
        "categories": ["Study","Cloud","AWS"],
        "tags": ["Docker","LectureNotes","AWS","동빈나"],
        "url": "https://gitgitwi.github.io"/study/cloud/aws/ln-aws-0102/"",
        "teaser": null
      },
    
      
      {
        "title": "LN-Docker-동빈나's Docker 활용 3강~4강",
        "excerpt":
          
            "03 AWS EC2에 도커(Docker) 설치 및 Dockerfile로 웹 서버 구동시키기   Docker 설치를 위한 준비   AWS에서 생성한 jupyter-notebook 접속   현재 메모리 상황 확인  /# df -h  Filesystem      Size  Used Avail Use% Mounted on udev            481M     0  481M   0% /dev tmpfs            99M  752K   98M   1% /run /dev/xvda1      7.7G  1.7G  6.1G  22% / tmpfs           492M     0  492M   0% /dev/shm tmpfs           5.0M     0  5.0M   0% /run/lock tmpfs           492M     0  492M   0% /sys/fs/cgroup /dev/loop0       90M   90M     0 100% /snap/core/8268 /dev/loop1       18M   18M     0 100% /snap/amazon-ssm-agent/1480 tmpfs            99M     0   99M   0% /run/user/1000  필요한 프로그램 설치   /# sudo apt install apt-transport-https  /# sudo apt install ca-certificates  /# sudo apt install curl  /# sudo apt install software-properties-common   curl 을 통해 stable version docker for linux 설치   :/# curl -fssL https://download.docker.com/linux/ubuntu/gpg | sudo apt-key add - OK  # Docker를 download할 경로 설정 :/# sudo add-apt-repository \"deb [arch=amd64] https://download.docker.com/linux/ubuntu bionic stable\"  # Docker-ce version check apt-cache policy docker-ce  # Docker-ce download sudo apt install docker-ce  # system status 확인으로 정상설치 및 실행 여부 확인 root@ip-@@@@:/# sudo systemctl status docker ● docker.service - Docker Application Container Engine    Loaded: loaded (/lib/systemd/system/docker.service; enabled; vendor preset: enabled)    Active: active (running) since Sat 2020-04-04 13:25:00 UTC; 24s ago      Docs: https://docs.docker.com  Main PID: 9562 (dockerd)     Tasks: 8    CGroup: /system.slice/docker.service            └─9562 /usr/bin/dockerd -H fd:// --containerd=/run/containerd/containerd.sock   Docker Image 다루기      test용 image hello-world   root@ip-@@@@:/# docker pull hello-world Using default tag: latest latest: Pulling from library/hello-world 1b930d010525: Pull complete Digest: sha256:f9dfddf63636d84ef479d645ab5885156ae030f611a56f3a7ac7f2fdd86d7e4e Status: Downloaded newer image for hello-world:latest docker.io/library/hello-world:latest  root@ip-@@@@:/# docker run hello-world  root@ip-@@@@:/# docker ps -a CONTAINER ID        IMAGE               COMMAND             CREATED             STATUS    PORTS               NAMES e7cf415feb6d        hello-world         \"/hello\"            42 seconds ago      Exited (0) 41 seconds ago                       serene_brahmagupta  root@ip-@@@@:/# docker rm e7cf415feb6d e7cf415feb6d  root@ip-@@@@:/# docker images REPOSITORY          TAG                 IMAGE ID            CREATED             SIZE hello-world         latest              fce289e99eb9        15 months ago       1.84kB   rm 명령으로 Container 삭제하더라도 image 는 그대로 남아있음   새로운 image Dockerfile 생성하여 실행   root@ip-@@@@:~# pwd /home/ubuntu  root@ip-@@@@:~# mkdir example  root@ip-@@@@:~# cd example  root@ip-@@@@:~/example# sudo vi Dockerfile   Dockerfile 생성   FROM ubuntu:18.04 MAINTAINER gitgitwi &lt;johnwi@knou.ac.kr&gt;  RUN apt-get update RUN apt-get install -y apache2  EXPOSE 80  CMD [\"apachectl\", \"-D\", \"FOREGROUND\"]     FROM : set OS   MAINTAINER : information about author   RUN : image를 run할 때 수행할 명령            여기서는 update &gt; apache2 server 설치       -y : 설치시 yes로 답변하도록           EXPOSE : 사용할 port 설정            80 port 는 apache2의 기본 HTTP port           CMD : 사용할 명령 설정            여기서 apache2가 항상 수행될 수 있도록 설정 (daemon 상태로 설정)           ls로 Dockerfile 생성 확인  root@ip-@@@@:~/example# ls Dockerfile   Dockerfile 실행     -t : tag, 이름 지정            여기서 example 로 지정           . : directory   root@ip-@@@@:~/example# docker build -t example . Sending build context to Docker daemon  2.048kB Step 1/6 : FROM ubuntu:18.04 ... Successfully built 36e373ec3b52 Successfully tagged example:latest   설치된 images 확인, tag name 으로 실행     ubuntu 18.04에서 실행되도록 지정하면서, ubuntu도 설치됨   -p {container port} : {EC2 port}             container에서의 80 port를 AWS EC2의 80 port와 맞춤       EC2 인스턴스 보안그룹 설정에서 http port를 만들어줘야 함           root@ip-@@@@:~/example# docker images REPOSITORY          TAG                 IMAGE ID            CREATED             SIZE example             latest              36e373ec3b52        6 seconds ago       189MB ubuntu              18.04               4e5021d210f6        2 weeks ago         64.2MB hello-world         latest              fce289e99eb9        15 months ago       1.84kB  root@ip-@@@@:~/example# docker run -p 80:80 example AH00558: apache2: Could not reliably determine the server's fully qualified domain name, using 172.17.0.2. Set the 'ServerName' directive globally to suppress this message  Apache2 WebServer 접속     http://{EC2 ip}:80   https 가 아닌 http 로 접속에 주의!      04 도커(Docker) 이미지로 Apache 및 PHP 개발환경 구축하기   현재 열려있는 모든 port 강제종료   root@ip-@@@@:/# docker ps -a CONTAINER ID        IMAGE               COMMAND                  CREATED             STATUS  PORTS                NAMES 90f277814d0d        example             \"apachectl -D FOREGR…\"   31 minutes ago      Up 31 minutes  0.0.0.0:80-&gt;80/tcp   reverent_benz  root@ip-@@@@:/# docker rm -f `docker ps -a -q` 90f277814d0d   Dockerfile 수정하여 PHP 설치      실습을 위해 일부러 PHP 5.6 설치함   프로그램 설치 중 option 을 선택하게 하는 경우가 종종 있음   그런데 dockerfile 활용한 설치 중에는 입력 불가   따라서 Dockerfile에서 미리 interaction 방지를 위한 환경변수 설정을 해줘야 함   ENV DEBIAN_FRONTEND=noninteractive  RUN apt-get install -y software-properties-common RUN add-apt-repository ppa:ondrej/php RUN apt-get update RUN apt-get install -y php5.6   불필요한 image 제거   root@ip-@@@@:~/example# docker images REPOSITORY          TAG                 IMAGE ID            CREATED             SIZE example             latest              4c1f2c09a2a6        9 seconds ago       256MB &lt;none&gt;              &lt;none&gt;              36e373ec3b52        46 minutes ago      189MB ubuntu              18.04               4e5021d210f6        2 weeks ago         64.2MB hello-world         latest              fce289e99eb9        15 months ago       1.84kB  root@ip-@@@@:~/example# docker rmi 36e373ec3b52   PHP 기본 port 접속  /var/www/html : PHP 기본 port   root@ip-@@@@:~/example# docker run -p 80:80 -v /home/ubuntu/example/html:/var/www/html example AH00558: apache2: Could not reliably determine the server's fully qualified domain name, using 172.17.0.2. Set the 'ServerName' directive globally to suppress this message   jupyter에서 새로 terminal 열어서 PHP 폴더에서 작업    PHP가 연결된 모습   root@ip-@@@@:/# cd /home/ubuntu/example/html root@ip-@@@@:~/example/html# ls root@ip-@@@@:~/example/html# sudo vi index.php   test를 위해 index.php에 phpinfo 함수 입력  &lt;?php phpinfo(); ?&gt;     다시 접속하면 위와 같이 phpinfo가 나오는 화면으로 바뀜  ",
          
        "categories": ["Study","Cloud","AWS","Docker"],
        "tags": ["Docker","LectureNotes","AWS","동빈나","Apache Server"],
        "url": "https://gitgitwi.github.io"/study/cloud/aws/docker/ln-aws-0304/"",
        "teaser": null
      },
    
      
      {
        "title": "LN-Docker-동빈나's Docker 활용 5강~6강",
        "excerpt":
          
            "05 Docker로 MySQL 컨테이너 만들어 보기   작업 전 모든 container 제거   root@ip-172-31-45-116:/# docker rm -f `docker ps -a -q` 0037b1e5d4eb  root@ip-172-31-45-116:/# docker ps -a CONTAINER ID        IMAGE               COMMAND             CREATED             STATUS              PORTS               NAMES   MySQL5.6 설치     host 9876 port와 MySQL 3306 port 연결     root@ip-172-31-45-116:/# docker run -d -p 9876:3306 -e MYSQL_ROOT_PASSWORD=1234 mysql:5.6           MySQL 접속   1. docker exec -it c5f4d59d5bea /bin/bash  MySQL container의 terminal로 접속   2. mysql -u root -p  MySQL 접속   root@ip-172-31-45-116:/# docker exec -it c5f4d59d5bea /bin/bash  root@c5f4d59d5bea:/# mysql -u root -p Enter password: Welcome to the MySQL monitor.  Commands end with ; or \\g. Your MySQL connection id is 1 Server version: 5.6.47 MySQL Community Server (GPL)  Copyright (c) 2000, 2020, Oracle and/or its affiliates. All rights reserved.  Oracle is a registered trademark of Oracle Corporation and/or its affiliates. Other names may be trademarks of their respective owners.  Type 'help;' or '\\h' for help. Type '\\c' to clear the current input statement.  mysql&gt;   root에서 MySQL로 바로 접속   root에서 MySQL 접속 IP 확인  root@ip-172-31-45-116:/# docker inspect c5f4d59d5bea ...       \"IPAddress\": \"172.17.0.2\", ...   mysql-client-core 설치  root에서 접속하기 위한 툴   root@ip-172-31-45-116:/# sudo apt install mysql-client-core-5.7   root에서 MySQL로 바로 접속     MySQL port로 접속     root@ip-172-31-45-116:/# mysql -u root -p --host 172.17.0.2 --port 3306 Enter password: Welcome to the MySQL monitor.           docker host port로 접속     root@ip-172-31-45-116:/# mysql -u root -p --host 127.0.0.1  --port 9876 Enter password: Welcome to the MySQL monitor.  Commands end with ; or \\g.           관리자 역할을 할 user생성   mysql&gt; create user 'test'@'%' identified by '1234'; Query OK, 0 rows affected (0.03 sec)  mysql&gt; grant all privileges on *.* to 'test'@'%'; Query OK, 0 rows affected (0.01 sec)  mysql&gt; flush privileges; Query OK, 0 rows affected (0.00 sec)  외부 접속 권한까지 부여   restart MySQL container  root@ip-172-31-45-116:/# docker restart c5f4d59d5bea c5f4d59d5bea  EC2에서 9876 포트 오픈, SQL관리툴인 HeidiSQL 등 이용해 접속 가능     mac에서는 HeidiSQL 설치 바로 안됨..   EC2 IP와 포트, MySQL User/PW 사용해 접속     06 PHP 컨테이너와 MySQL 컨테이너 연동해보기   php-MySQL 연동을 위한 Setting  Dockerfile 수정하여 php5.6-mysql package 설치   package install 내용 추가   RUN apt-get install -y php5.6-mysql  dockerfile 실행 후 이미지 실행     Apache server, PHP, MySQL 실행   root@ip-172-31-45-116:~/example# docker build -t example .  root@ip-172-31-45-116:~/example# docker run -p 80:80 -v /home/ubuntu/example/html:/var/www/html example  php를 통해 MySQL 접속  jupyter를 통한 index.php 수정      지금까지는 vi를 통해 수정했으나,   jupyter를 통해서 수정 가능!     &lt;?php   $conn = mysqli_connect(     '54.180.30.186', # EC2 Port     'test',     '1234',     'test', # DB Name     '9876' # DB Port     );     if(mysqli_connect_errno()) {       echo \"Connection Failed : \".mysqli_connect_error();     }     # SQL 의 버전 값 출력     $sql = \"SELECT VERSION()\";     $result = mysqli_query($conn, $sql);     $row = mysqli_fetch_array($result);     print_r($row[\"VERSION()\"]); ?&gt;  일반적으로 RMDB를 container에 실어서 운영하기보다는 AWS RDS 이용  ",
          
        "categories": ["Study","Cloud","AWS","Docker"],
        "tags": ["Docker","LectureNotes","AWS","동빈나","Apache Server","MySQL"],
        "url": "https://gitgitwi.github.io"/study/cloud/aws/docker/ln-aws-0506/"",
        "teaser": null
      },
    
      
      {
        "title": "LN-Docker-동빈나's Docker 활용 7강~9강",
        "excerpt":
          
            "07 AWS RDS를 이용한 데이터베이스 구축   Amazon RDS를 통한 DB 생성   한글 parameter 설정      parameter 생성   parameter 수정            ‘char’, ‘collation’ 검색       가능한 모든 encoding을 UTF8, UTF8_general_ci로 설정              DB 생성      MySQL 5.6   template &gt; Free-Tier ; 반드시 확인!   Master User Name / PW ; 외부접속 위한 ID/PW   보안 그룹            일반적으로 가장 중요한 곳이 DB 이므로 특정 server에서만 접근 가능하도록 설정       여기서는 실습을 위해 모든 server에서 접속 가능하도록 열어놓음           DB port : 3306   DB parameter group : 위에서 설정한 parameter   생성 완료까지는 몇분 소요될 수 있음   생성 이후 dashboard에서 end-point 확인 : DB 접속주소   EC2 root terminal에서 MySQL 접속   Syntax : mysql -h {end-point-value} -P {port} -u {master-user-name} -p   ex.  :~# mysql -h mysql.@@@@.rds.amazonaws.com -P 3306 -u gitgitwi -p Enter password: Welcome to the MySQL monitor.  Commands end with ; or \\g.  php-MySQL 연동 테스트  php 파일 수정  DB 생성시 입력한 그대로     접속 주소   접속 ID / PW      08 GitHub에 Docker 프로젝트 올리기   create new repository   port 보안을 위해 private repository로 만들어야 함   AWS-GitHub 연동   EC2 Ubuntu18에는 기본적으로 Git이 설치되어 있음   local repository에서 Dockerfile, index.php 생성   이전에 만든  그대로 복사   root@ip-@@@@@@:~# git clone https://github.com/ezerwi/AWS-Docker-SQL-test.git Cloning into 'AWS-Docker-SQL-test'... Username for 'https://github.com': ezerwi Password for 'https://ezerwi@github.com':  root@ip-@@@@@@:~# cd AWS-Docker-SQL-test root@ip-@@@@@@:~/AWS-Docker-SQL-test# sudo vi Dockerfile   작업 내용 확인하고 git add &amp; commit  root@ip-@@@@@@:~/AWS-Docker-SQL-test# ls Dockerfile  index.php  root@ip-@@@@@@:~/AWS-Docker-SQL-test# cat index.php  root@ip-@@@@@@:~/AWS-Docker-SQL-test# git add .  root@ip-@@@@@@:~/AWS-Docker-SQL-test# git commit -m \"inital project\"  root@ip-@@@@@@:~/AWS-Docker-SQL-test# git push Username for 'https://github.com': ezerwi Password for 'https://ezerwi@github.com':   09 DockerHub와 GitHub 연동하기   DockerHub-GitHub 연동 과정      Dockerfile Source Code 수정   GitHub commit-push   DockerHub에서 수정된 내용대로 알아서 re-build   New DockerHub Repository      Build Setting : Github   Create &amp; Build   auto-build 약 5~10분 정도 걸림   DockerHub 통해   docker push gitgitwi/git-test:tagname    Readme.md 작성      Readme.md   image에 대한 안내   대소문자 틀리면 DockerHub에서 build ERROR   # AWS-Docker-SQL-test # test for Docker build  ### Installation &lt;pre&gt; cd /home git clone https://github.com/ezerwi/AWS-Docker-SQL-test cd AWS-Docker-SQL-test &lt;/pre&gt;  ### RUN &lt;pre&gt; # login for private docker repository docker login docker pull gitgitwi/git-test  # set directory 'Project' to save php file docker run -p 80:80 -v /home/AWS-Docker-SQL-test/Project:/var/www/html gitgitwi/git-test &lt;/pre&gt;    ",
          
        "categories": ["Study","Cloud","AWS","Docker"],
        "tags": ["Docker","동빈나","LectureNotes","AWS","AWS RDS","MySQL","GitHub","DockerHub"],
        "url": "https://gitgitwi.github.io"/study/cloud/aws/docker/ln-aws-0709/"",
        "teaser": null
      },
    
      
      {
        "title": "LN-Docker-동빈나's Docker 활용 10강~11강",
        "excerpt":
          
            "10 Jenkins를 이용해 Docker 프로젝트 빌드해보기   Jenkins를 활용한 Build 자동화      Docker in Docker 방식    Jenkins 설치 및 실행           Jenkins도 기본포트 == 8080            Jenkins 안에서 php가 구동되도록       root@ip-172-31-45-116:~/# docker pull jenkins/jenkins:lts  LTS tag 붙이지 않고 설치할 경우 plugins 설치 시 ERROR         jenkins의 repository가 변경되어서 그렇다고 함..   docker run -d -p 8080:8080 -v /home/jenkins/:/var/jenkins_home -v /var/run/docker.sock:/var/run/docker.sock -u root jenkins/jenkins      실행 확인 후 EC2 보안설정으로 open 8080 port   EC2 IP:8080으로 접속하여 Jenkins 실행 확인    Jenkins 초기 비번 확인     docker logs {ContainerID}           plugins 설치, 계정 설정 등 setting 이후 Jenkins 첫 화면      Jenkins로 Docker Auto-Build 구현   Freestyle Project 선택      Build &gt; Execute Shell     여기에서 이전에 github readme.md로 만든 내용 입력      아직은 Jenkins에 Docker를 설치하지 않아 ERROR      Jenkins의 bash 에서 Docker 설치   root@ip-172-31-45-116:~/AWS-Docker-SQL-test# docker exec -it c6595515894f /bin/bash root@c6595515894f:/# curl -fsSLO https://get.docker.com/builds/Linux/x86_64/docker-17.04.0-ce.tgz root@c6595515894f:/# tar xzvf docker-17.04.0-ce.tgz   용량 절약을 위해 Jenkins 내부 Docker 설치 파일 삭제   root@c6595515894f:/# pwd /  root@c6595515894f:/# mv docker/docker /usr/local/bin  root@c6595515894f:/# rm -r docker docker-17.04.0-ce.tgz   Jenkins 내부 Docker Login   root@c6595515894f:/# docker login Login with your Docker ID to push and pull images from Docker Hub. If you don't have a Docker ID, head over to https://hub.docker.com to create one. Username: gitgitwi Password: Login Succeeded   git clone으로 Dockerfile 설치 및 확인  root@c6595515894f:/# cd /home  root@c6595515894f:/home# git clone https://github.com/ezerwi/AWS-Docker-SQL-test  root@15b7c3a5a0a6:/home# ls AWS-Docker-SQL-test root@15b7c3a5a0a6:/home# cd AWS-Docker-SQL-test root@15b7c3a5a0a6:/home/AWS-Docker-SQL-test# ls Project  Readme.md root@15b7c3a5a0a6:/home/AWS-Docker-SQL-test# cd Project root@15b7c3a5a0a6:/home/AWS-Docker-SQL-test/Project# ls Dockerfile  index.php      11 Jenkins를 활용해 원격에서 서버 프로그램 빌드하기   현재 실행중인 Jenkins 내부 container 종료, Jenkins가 설치된 container만 남겨둔다   Jenkins project build 수정  ",
          
        "categories": ["Study","Cloud","AWS","Docker"],
        "tags": ["Docker","동빈나","LectureNotes","AWS","Jenkins"],
        "url": "https://gitgitwi.github.io"/study/cloud/aws/docker/ln-aws-10~11/"",
        "teaser": null
      },
    
      
      {
        "title": "2020 상반기 LINE online coding test 후기..",
        "excerpt":
          
            "2020 상반기 LINE online coding test 후기..        정말 말그대로, 참가하는데 의의를 뒀다   개발 배운지 아직 반년도 안됐고, 말로만 듣던 코딩 테스트는 이번이 첫 경험이기 때문에 뭔가 될 거란 생각하는게 이상하지..ㅋㅋ   AWS-Docker에 빠져서 밤새 유튜브 보고 따라해보느라, 6시반에 잠깐 잤다가 일어나서 샤워하고 시간 맞춰서 프로그래머스 들어간거라 정신도 없었다   6문제 중 홀수번 문제들만 간신히 풀어서 Test Case는 모두 통과했는데, 실제 case들은 어떻게 될지 모르겠다      한 문제 정도는 쉽게 몸풀고 가라고 준거 같은데, 그거도 눈으로만 봤던거라 꽤 오래 걸렸다 ㅋㅋㅋ  얼마전까지 1일-1알고리즘 퀴즈하던 것도 안하다 보니 환경 세팅용으로 준 예제도 버벅거렸다..ㅋㅋㅋㅋㅋㅋ      LINE 출제팀 인터뷰에서 (LINE Engineering &gt; LINE 신입 SW 개발자 코딩 테스트, 이렇게 만들어졌습니다) 알고리즘 문제뿐만 아니라 구현 문제도 출제했다고 했다   그래서 알고리즘 모르면 노가다스럽게 풀어서 풀릴 수도 있는데, 시간이 문제인 문제들도 있었고 그 노가다로 풀 방법 생각하는 것도 시간이 오래걸렸다..   그나마 DFS/BFS, 이진트리, 그래프 정도 수준의 문제는 없지 않았나.. 정렬, 스택 정도까지만 해도 풀려면 풀 수 있는 문제 아니었나 싶다.. 내가 파악을 못했는지 모르겠지만 ㅋㅋ   암튼 코딩 테스트 첫 경험을 하면서 나름의 가능성을 볼 수 있었다 열씸히 해보는 수밖에~!!  ",
          
        "categories": ["Career","Python"],
        "tags": ["LINE","취준기","Python"],
        "url": "https://gitgitwi.github.io"/career/python/2020_%EC%83%81%EB%B0%98%EA%B8%B0_LINE-_online_coding_test_%ED%9B%84%EA%B8%B0/"",
        "teaser": null
      },
    
      
      {
        "title": "Frequent Git Error Messages",
        "excerpt":
          
            "non-fast-forward   특별한 문제를 일으키지 않았는데도, non-fast-forward 메시지와 함께 push가 rejected되는 경우가 있다   이 에러가 발생하는 원인은 여러가지인 듯   $ git push -u origin master  ! [rejected]        master -&gt; master (non-fast-forward) error: failed to push some refs to 'https://github.com/gitgitWi/ezerwi'   해결방법      원인 01   GitHub에 저장한 내용 - Local에서 commit한 내용 중 겹치는 것이 하나도 없는 경우        GitHub는 Remote repo와 Local repo 사이에 공통분모 없는 상태에서 merge 시도할 경우 원칙적으로 차단                       참고 : devlog.jwgo.kr                        아래와 같이 history와 무관하게 강제적으로 pull 허용시킴                     $ git pull origin master --allow-unrelated-histories                  GitHub Desktop 을 사용하는 경우 문제가 있는 파일을 수정하도록 파일을 열어줌, 파일을 수정하여 저장한 후 commit          ",
          
        "categories": ["fundamentals","Git","Errors"],
        "tags": ["Git","Github","Error Messages"],
        "url": "https://gitgitwi.github.io"/fundamentals/git/errors/Git-Error/"",
        "teaser": null
      },
    
      
      {
        "title": "CPTeam X 영등포구청 외국계 취업 멘토링(MS,AWS 등)",
        "excerpt":
          
            "date: Apr 24, 2020 6 ~ 9 PM   멘토분들 개인정보는 모두 가렸습니다. 문제시 삭제하겠습니다.          Section1. 前 MS 인사총괄 특강         Resume         수치화 중요   지원하고자 하는 position과 align된 skill 위주         약 200번의 interview 경험   interview 전 항상 모의 연습, 면접관 관점에서   면접 직후 반드시 면접 내용 정리   다국적 기업 면접시, 궁금한 점에 대한 질문 없으면 감점되는 경우 다수 ; 기업에 대한 관심으로 이해   평범한 짝퉁이 아닌 고귀한 명품이 되어라~~   Q&amp;A      외국계 기업 면접에서 특별히 중요한 것?            해당 기업의 해당 직무에 대한 이해; 인터넷에 잘 안나옴, networking 필요한 이유, 재직자를 반드시 만나야 함           불필요한 스펙?            직무와 무관한 자격증 등       직무에 대해 정확한 이해 필요, 직무에 맞춰서 준비하라       대부분 외국계 기업은 자소서 비중 크지 않음, 이력서와 직무이해도 중심       자소서는 전세계에서 한국만 쓴다~           LinkedIn            회사 입장에서 매력적으로 보이게 update하는 것이 1차           스펙이든 뭐든 본인이 잘할 수 있고 흥미있는것, 남들과 차별화된 것이 필요   외국계 기업은 공채 보다 수시 채용, 신입에게는 정규직보다 계약직이 대다수, 그래도 일단 들어가서 뭔가 보여줘야 정규직 전환 가능, 그런 경우 많음            단 정규직 전환에 대한 guarantee는 없음, 기회가 있을 거라고 정도만 알려줌                Section2.  AWS Data Center Technician Manager 멘토 특강   Amazon      브랜드 가치 1위   일하고 싶은 기업 1위(미국) : 10권 내 대부분 IT, 미디어   Amazon Web Service      Amazon의 매출구조            retail product : 60~70%       AWS : 15%, 그러나 영업이익은 70% 이상 기여                    IT업계 종사자 수요가 높고, 연봉이 높은 이유                       Leadership Principles 중 가장 중요한 2가지                    Customer Obsession : 고객이 왕이다           Deliver Results : 반드시 Output이 있어야                   Amazon’s global career site                   AWS’ Culture      Job Level : 직급체계   Work-Life Balance : 야근을 강요하지 않지만, 대부분 자발적으로 야근하는 분위기   Benefits : Amazon Korea의 경우 타 국내 기업과 비슷한 수준, 복지는 start-up이 좋다..   6 Pager / 3 Pager : PPT 쓰지 않음, 그림에 현혹되지 않기 위해, 무조건 word   Loop Interview : 채용과정에서, Leadership Principles 에 맞는지 길게는 12시간까지 면접,   Think Big      Focus on what you want to do   Set goals for yourself            Little by little : 작은 것부터 시작해 큰 것으로, 취업은 장기적인 과정           Fundamental and Basic            Practical skills come later       기본기가 탄탄해야 신기술도 잘 할 수 있다       IT의 트렌드를 맹신하지 마라, Junior에게 필요한 건 기본기, 신기술은 Senior에게 필요한 것           Know yourself            Think like employer                    직무적합성 : 이사할 때는 트럭을 쓰지 람보르기니를 쓰지 않는다, JD를 잘 봐야하는 이유           가성비 : 메이커 컴퓨터 한 대 사느니, 조립식 컴퓨터 두대로 더 많은 성능 발휘하듯, 이사람을 뽑았더니 이것도 알고 저것도 안다                                 시간관리 : 신입사원 당시 시간관리 잘해서 국제공인 자격증 14개 땀          Section3. Panel Group Talk      AmorePacific / 기획(채널관리)            채널관리 == 영업관리, 다양한 유통/영업채널 관리       영업 역량 중요, 커뮤니케이션 스킬은 모든 직무에 중요, 영업에서 특히 중요한 것은 협상과 데이터 분석 능력       남녀비율 : 채널에 따라 다른데 남자 비율이 80% 정도,  다만 온라인 채널은 여성 비중이 60% 이상, 공채 total 5:5 정도       코로나에 따른 사내 트렌드 : 전체 업무의 50% 이상을 디지털화, 빠르면 올 하반기부터 채용도 온라인으로,           Nike Korea / Business Planner            업무 : 최근 판매 data 분석, 미래 주문 예측, 요즘은 ‘21 봄시즌 제품군 예상 주문/매출 등 분석       인재상은 직무에 따라 다름, active한 모습 좋아함 - 운동 좋아하는 것과는 다름       신입 사원은 안뽑음       데이터 분석 역량 - 카드사 같은 빅데이터 개념은 아님, 통계 자격증 필요한 거 아님, Excel/Tableau 활용           Disney Korea / 영업관리            입사과정 : 계약직/경력직 등 대부분 헤드헌터 통해서 진행, 면접 많이 진행하므로 회사에 대해 잘 알아야, 본사의 모든 guide-line이 영어로 진행되므로 english skill 중요, 모두가 영어 다 잘함(현재 멘토 상사가 중국인임)       경력직 위주 채용, 직무 경험 많이 봄, 이전 회사 인지도는 잘 안봄       인재상 : 차분하고 침착한 인재       디즈니는 코리아에서 본사로 가는 프로그램은 없습니다       영업관리 영업지원 컨셉 하는 일 같습니다       creative한 직무는 모두 본사에서 진행, 지사는 operating, 배급, 개념                  Section 4.  Small-Group Mentoring   AWS 멘토      Amazon 면접 :            멘토의 경우 7번 면접, 15시간 정도 진행, 한번 떨어지고 다시 지원해서 붙음       모두 영어, 전화 인터뷰-과제-기술면접-인성면접-reference check 등,       어차피 영어로 계속 면접을 진행하기 때문에, 영어성적은 없어도 됨       신입이라면 연봉협상에서 튕기면 안됨       경력이라면 무조건 한번은 튕겨서 연봉을 올려야, 전 회사의 +20%가 관례       붙어도 3개월간 performance check; 동료 performance 평균의 50% 이상 내야                ML은 석사, AI는 박사 위주, 그외 시스템 엔지니어/back-end 등은 학력 컷 낮음            알고리즘 필수, 국내 기업들을 실무를 중시하지만, 대부분 외국계는 기본적인 내용들(알고리즘, 자료구조, 시스템) 제일 중요, 어차피 실무는 입사해서 배움       DevOps : 개발자가 서버/시스템도 관리, 사실상 풀스택( 풀스택이라는 얘기는 함부로 하면 안됨.. ), 경력 필요, Cloud 등 가상화에 따라..            서버, DB에 대한 공부 필수, 특히 AWS에서 migration 작업을 주로 하기 떄문에                언어 : python을 주로 쓰지만, 현재 개발자가 아닌 서버 관리자이기 때문에 Shell Script 위주로            비전공자 국비교육을 받는다면 전공자 보다 뭔가 뛰어난게 있어야 함            대기업은 대부분 협력업체를 끼고 PL,PM을 하기 때문에 프로그래머로서 성장하긴 힘들다, 프로그래머로 성장하고 싶다면 외국계나 스타트업을 가라            IT에서 첫 회사는 중요하지 않다, 다만 배울게 없는 회사라면 스스로 공부해야 함            외국계 자소서는 대부분 자유형식, 자신이 강조할 수 있는 부분(학력/프로젝트 내용) 순서대로, 이력서 통과는 어렵지 않지만 면접이 문제            지금은 IT기업들의 전성시대, 들어가기 가장 쉬운 시기일 것            AWS data-center는 재택근무가 불가능한 직무, 24시간 관리가 필요 - 2교대근무, 보안 때문에 절대 계약직 쓰지 않음            전세계 AWS 중에서 한국 개발자들이 젤 한다, 항상 top3 안에 듦            AWS/MS/Google 모두 워라벨이 좋지는 않다, 급여가 치유해준다, 성과금 보다는 연봉협상(base salary + signing bonus + extra money + RSU/자사주)       AWS 평균근속연수 1~2년 정도, ~보통 타사에서 좋은 조건줘서~  ",
          
        "categories": ["Career"],
        "tags": ["Mentoring","MS","AWS"],
        "url": "https://gitgitwi.github.io"/career/Fri_CPTeamX%EC%98%81%EB%93%B1%ED%8F%AC%EA%B5%AC%EC%B2%AD/"",
        "teaser": null
      },
    
      
      {
        "title": "[Python] ML Quick Review",
        "excerpt":
          
            "연휴기간 (04/30~05/05) 과제      본인이 지원하고자하는 회사 3군데 조사   1.의 회사 관련 포트폴리오 주제 선정            06/01 ~ 06/14 : 최종 포트폴리오 준비 기간       06/15 : 프로젝트 발표       동시에 Java Spring 추가 학습 예정                1. Machine Learning   Basic Types      지도학습 (supervised learning)   비지도학습 (unsupervised learning)   두 학습 모두 컴퓨터가 인식 가능한 입력 데이터 필요 (0, 1)   고려사항      어떤 질문에 대한 답을 원하는가? 현재 데이터가 원하는 답을 줄 수 있는가?   내가 원하는 질문의 답에 대한 ML 기술/algorithm은 무엇?   충분한 학습용 데이터가 있는지?   현재 데이터의 특성, 좋은 예측을 만들수 있는지?   ML App.의 성과를 어떻게 측정할 수 있는지?   ML Solution이 다른 연구/제품과 어떻게 협력할 수 있는가?        2. Python Libraries related to ML      Scikit-learn   Numpy   Scipy : 희소행렬(sparse matrix)   Matplotlib : plots   Pandas : DataFrame, Series        3. Scikit-learn   KNN (k-nearest neighbors) Model   Iris dataset로 단순하게 구현해보기; KNN 관련 가장 간단한 dataset   dataset      학습 : 기출문제   훈련 : 모의고사   예측 : 실제 시험   지도 학습 및 훈련을 위한 dataset은 사람이 직접 만들어줘야 함  일반적으로 학습 : 훈련 = 7 : 3      Check Characteristics of data      data에 대한 사전 탐색 필수   web project의 경우 data-flow 중요   iris = load_iris() type(iris)                  # sklearn.utils.Bunch iris.keys() iris.target_names           # 품종명 iris.feature_names          # ['sepal length (cm)', 'sepal width (cm)', 'petal length (cm)', 'petal width (cm)']                             # [꽃받침 길이, 꽃받침 폭, 꽃잎 길이, 꽃잎 폭] iris_dataset.data.shape     # (150, 4) : sample 150, attribution 4 iris.data[:10]              # ML에서 각 item은 \"sample\"이라하고, 속성은 \"특성\"이라 함 iris.target                 # results of labeling   이 dataset에 없는 새로운 data가 들어왔을때, 그 품종을 예측하는 ML Model을 만드는 것이 목적     Evaluate the ML Model      Model에 대한 성능 평가   Problems of Overfitting; not-normalized   -&gt; ML의 성능을 높이고 일반화하기 위해, 주어진 데이터를 train data - test data로 나눠야 함     sklearn.model_selection.train_test_split : Split data      train data, test data   관례) scikit-learn에서 data는 대문자 X, label은 소문자 y로 표기   수학 표기 방식을 따르되, data는 2차원 matrix이므로 대문자 X, target은 1차원 vector이므로 소문자 y 사용   데이터가 순서대로 나누어지지 않도록, random 하게 섞음   test set은 모든 class의 data를 포함하도록 잘 섞어야 함   from sklearn.model_selection import train_test_split X_train, X_test, y_train, y_test = train_test_split(iris_dataset.data, iris_dataset.target, test_size = 0.25, random_state = 2020)  print (X_train.shape, X_test.shape, y_train.shape, y_test.shape) print (X_train[:10], X_test[:10], y_train[:10], y_test[:10],)       Look into data   ML 없이도 풀수 있는 문제가 아닌지, 필요한 정보가 누락되어 있는지 data 조사   DataFrame, Scatter plot   iris_df = pd.DataFrame(X_train, columns=iris_dataset.feature_names) iris_df.head() iris_df.isnull().sum() pd.plotting.scatter_matrix(iris_df, c = y_train, figsize=(15,15), marker='o', hist_kwds={'bins' : 20}, s=60, alpha=.8)       Fitting (Machine Learning) by KNN Model   from sklearn.neighbors import KNeighborsClassifier knn = KNeighborsClassifier(n_neighbors = 3) knn.fit(X_train, Y_train)       KNN Model   K-nearset neighbors      train data 를 통해 model 만들고, 새로운 data 들어오면 가까운 훈련 data point를 찾아 분류   scikit-learn의 모든 ML model은 estimator라는 python class로 구현   KNN algorithm은 neighbors module 아래 KNeighborsClassifier class에 구현   parameters of KNN   KNeighborsClassifier(algorithm='auto',                      leaf_size=30,                      metric='minkowski',                      metric_params=None,                      n_jobs=None,                      n_neighbors=3,                      p=2,                      weights='uniform')       Predict about new data   n by 4 array   X_new = np.array([[3, 4.2, 0.8, 0.4]]) prediction = knn.predict(X_new) print (f\"Predict about X_new : {prediction}\") print (f\"Name of the predicted one : {iris_dataset.target_names[prediction]}\")  y_predict = knn.predict(X_test) y_predict == y_test       Evaluate Accuracy   print (f\"Accuracy of test set by 'mean' : {np.mean(y_predict == y_test) * 100}\") print (f\"Accuracy of test set by 'knn.score' : {knn.score(X_test, y_test) * 100}\")  from sklearn import metrics print (f\"Accuracy of test set by 'metrics.accuracy_score' : {metrics.accuracy_score(y_test, y_predict) * 100}\")   multiple ‘k’s   accuracy_set = [] k_set = [i for i in range(1,12,2)] print (k_set)  for k in k_set:     knn = KNeighborsClassifier(n_neighbors=k)     knn.fit(X_train, y_train)     y_predicts = knn.predict(X_test)     accuracy = metrics.accuracy_score(y_test, y_predicts)     accuracy_set.append(accuracy)  from pprint import pprint pprint(accuracy_set) print (max(accuracy_set))        kfold for Cross Validation         sklearn.model_selection.cross_val_score   train_test_split() 보다 성능이 좋은 평가방법   데이터를 k번 쪼개서 k번 검증   cross-val-score                 dataset : sklearn.datasets.load_breast_cancer         type(cancer)   cancer.data[:10]   cancer.feature_names   cancer.target_names   cancer.target[:10]                test models             sklearn.linear_model.LinearRegression         LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None, normalize=False)                       sklearn.neighbors.KNeighborsClassifier               KNeighborsClassifier(algorithm='auto',                          leaf_size=30, metric='minkowski',                         metric_params=None,                         n_jobs=None,                          n_neighbors=4,                          p=2,                         weights='uniform')  `     sklearn.svm.LinearSVC     LinearSVC(C=1.0,              class_weight=None,              dual=True,              fit_intercept=True,              intercept_scaling=1,              loss='squared_hinge',              max_iter=1000,              multi_class='ovr',              penalty='l2',              random_state=0,              tol=0.0001,              verbose=0)           sklearn.tree.DecisionTreeClassifier     DecisionTreeClassifier(class_weight=None,                          criterion='gini',                          max_depth=3,                          max_features=None,                          max_leaf_nodes=None,                          min_impurity_decrease=0.0,                          min_impurity_split=None,                          min_samples_leaf=1,                          min_samples_split=2,                          min_weight_fraction_leaf=0.0,                          presort=False,                          random_state=0,                          splitter='best')           sklearn.ensemble.RandomForestClassifier     RandomForestClassifier(bootstrap=True,                          class_weight=None,                          criterion='gini',                         max_depth=None,                          max_features='auto',                          max_leaf_nodes=None,                         min_impurity_decrease=0.0,                          min_impurity_split=None,                          min_samples_leaf=1,                          min_samples_split=2,                          min_weight_fraction_leaf=0.0,                          n_estimators=6,                          n_jobs=None,                          oob_score=False,                          random_state=None,                          verbose=0,                          warm_start=False)           exec. Cross Value Score   score1 = cross_val_score( lr, cancer.data, cancer.target) score2 = cross_val_score( knn, cancer.data, cancer.target) score3 = cross_val_score( svm, cancer.data, cancer.target) score4 = cross_val_score( tree, cancer.data, cancer.target) score5 = cross_val_score( forest, cancer.data, cancer.target)  print (f'Linear Regression Cross Value Score : {score1.mean()}') print (f'KNN Cross Value Score : {score2.mean()}') print (f'SVM Cross Value Score : {score3.mean()}') print (f'Decision Tree Cross Value Score : {score4.mean()}') print (f'Random Forest Cross Value Score : {score5.mean()}')   data split해서 fitting   data의 편향을 줄이기 위함   lr = LinearRegression().fit(X_train, Y_train) knn = KNeighborsClassifier(n_neighbors=4).fit(X_train, Y_train) svm = LinearSVC(random_state=0).fit(X_train, Y_train) tree = DecisionTreeClassifier(max_depth=3, random_state=0).fit(X_train, Y_train) forest = RandomForestClassifier(n_estimators=6).fit(X_train, Y_train)   Accuracy   앞의 cross_val_score와 비교   print (f'Linear Regression Accuracy : {lr.score(X_test, Y_test)}') print (f'KNN Accuracy : {knn.score(X_test, Y_test)}') print (f'SVM Accuracy : {svm.score(X_test, Y_test)}') print (f'Decision Tree Accuracy : {tree.score(X_test, Y_test)}') print (f'Random Forest Accuracy : {forest.score(X_test, Y_test)}')        ===   Data Scaling      Data Scaling   one of preprocessings   데이터 값이 너무 크거나 작은 경우 algorithm 학습이 0으로 수렴하거나 무한으로 발산해버릴 가능성 있기 때문   Scalers         1. Standard Scaler      mean = 0, Var = 1   2. Robust Scaler      median, quartile   3. MinMax Scaler      values of all features  : 0 ~ 1   4. Normalizer      위의 3 Scaler 와 달리 row 마다 정규화   Uclid 거리가 1이 되도록 data 조정   Spherical contour(구형 윤곽) : 좀더 빠르게 학습가능, 좋다는 의미가 아님   Fitting      fit : learn data   transform : scaling   Use dataset: Breast-Cancer   from sklearn.datasets import load_breast_cancer from sklearn.model_selection import train_test_split  cancer = load_breast_cancer()  X_train, X_test, y_train, y_test = train_test_split(cancer.data, cancer.target, stratify = cancer.target, random_state = 2020)   Standard Scaler   from sklearn.preprocessing import StandardScaler scaler = StandardScaler() X_train_scale = scaler.fit_transform(X_train)  print (f\"스케일 조정 전 features MIN Values : \\n{X_train.min(axis = 0)}\") print (f\"스케일 조정 전 features MAX Values : \\n{X_train.max(axis = 0)}\") print (f\"스케일 조정 후 features MIN Values : \\n{X_train_scale.min(axis = 0)}\") print (f\"스케일 조정 후 features MAX Values : \\n{X_train_scale.max(axis = 0)}\")   Robert Scaler   from sklearn.preprocessing import RobustScaler rs = RobustScaler() X_train_rs = rs.fit_transform(X_train)  print (f\"스케일 조정 전 features MIN Values : \\n{X_train.min(axis = 0)}\") print (f\"스케일 조정 전 features MAX Values : \\n{X_train.max(axis = 0)}\") print (f\"스케일 조정 후 features MIN Values : \\n{X_train_rs.min(axis = 0)}\") print (f\"스케일 조정 후 features MAX Values : \\n{X_train_rs.max(axis = 0)}\")   MinMax Scaler   from sklearn.preprocessing import MinMaxScaler mms = MinMaxScaler() X_train_mms = mms.fit_transform(X_train)  print (f\"스케일 조정 전 features MIN Values : \\n{X_train.min(axis = 0)}\") print (f\"스케일 조정 전 features MAX Values : \\n{X_train.max(axis = 0)}\") print (f\"스케일 조정 후 features MIN Values : \\n{X_train_mms.min(axis = 0)}\") print (f\"스케일 조정 후 features MAX Values : \\n{X_train_mms.max(axis = 0)}\")   Normalizer   from sklearn.preprocessing import Normalizer nor = Normalizer() X_train_nor = nor.fit_transform(X_train)  print (f\"스케일 조정 전 features MIN Values : \\n{X_train.min(axis = 0)}\") print (f\"스케일 조정 전 features MAX Values : \\n{X_train.max(axis = 0)}\") print (f\"스케일 조정 후 features MIN Values : \\n{X_train_nor.min(axis = 0)}\") print (f\"스케일 조정 후 features MAX Values : \\n{X_train_nor.max(axis = 0)}\")   analysis between before and after data Scaling using SVC      before data scaling   from sklearn.svm import SVC X_train, X_test, y_train, y_test = train_test_split(cancer.data, cancer.target, random_state = 2020)  svc = SVC() svc.fit(X_train, y_train)  svc.score(X_test, y_test)       # 0.5734265734265734      after data scaling   mms = MinMaxScaler()  X_train_mms = mms.fit_transform(X_train) X_test_mms = mms.transform(X_test)  svc.fit(X_train_mms, y_train)  svc.score(X_test_mms, y_test)   # 0.958041958041958   std = StandardScaler()  X_train_std = std.fit_transform(X_train) X_test_std = std.transform(X_test)  svc.fit(X_train_std, y_train) svc.score(X_test_std, y_test)   # 0.965034965034965   robu = RobustScaler()  X_train_robu = robu.fit_transform(X_train) X_test_robu = robu.transform(X_test)  svc.fit(X_train_robu, y_train) svc.score(X_test_robu, y_test)  # 0.986013986013986   norm = Normalizer()  X_train_norm = norm.fit_transform(X_train) X_test_norm = norm.transform(X_test)  svc.fit(X_train_norm, y_train) svc.score(X_test_norm, y_test)  # 0.5734265734265734         Deep Learning with Tensorflow (as tf) &amp; Keras      tensorflow 내부에 image classification model 등 각종 models of machine learning 공개   Inception3 : 일반적인 이미지 예측 model, 여기에 내가 개인적으로 갖고 있는 이미지들로 학습   처음부터 새로 model 만드는 것보다 inception3 등 기존 예측 models를 re-training 시켜서 사용하는 것만 잘해도 tf를 잘 활용할 수 있다   Data Flow Graph      tf 는 data flow graph 형태로 작동 : data flow에 관련된 graph를 잘 알아야 tf를 잘 쓸 수 있다   구성요소         Node : mathematical operations with tensors   Edge : flow way of tensor( multidimensional data array )   tensor(data)가 nodes를 지나면서 연산이 이루어짐, tensor가 graph상에서 이동(flow)해서 TensorFlow   Tensor      multidimensional data array : any value available            Rank : number of dimensions                    0 : scalar           1 : vector           2 : matrix           3 : 3-tensor           n : n-tensor                       Shape : number of elements in each dimensions                    ex) [[1,2,3,],[4,5,6,],[7,8,9,]].shape = [3,3]                       Type : data-type, 대부분 float32           Keras      원래 Tensorflow와는 별개의 library, TF 2.0로 버전업하면서 tf에 포함시킴   주요 특징      Modularity :            keras의 module들은 독립적, 설정가능, 가능한 최소한의 제약사항으로 서로 연결, models은 sequences or graphs로 구성한 것       특히 신경망층, 비용함수, 최적화기, 초기화기법, 활성화함수, 정규화기법 등 모두 독립적 modules, 새로운 model 만들기 위해 이러한 modules 조합 가능           Minimalism : 각 module은 짧고 간결, 모든 code는 한번 훑어보는 것으로도 이해 가능해야, 단 반복속도 및 혁신성은 다소 떨어질 수 있음   쉬운 확장성 : easy to add new classes or functions to modules, 고급연구에 필요한 다양한 표현 가능   Python based : 별도의 model 설정 필요없이 python codes로 정의 가능   기본 개념      Model : basic data structure            sequence model : 원하는 layers를 쉽게 순차적으로 쌓을 수 있음       다중 출력 등 좀더 복잡한 model 구성은 keras의 함수 API 사용           Deep Learning Model by Keras                                dataset 생성                            원본 data 불러오거나 simulation 통해 data 생성               훈련 set / 검증 set / 시험 set 생성               data transformatting : ex. images to array                                                                   model 구성                            sequence model 생성한 뒤(객체), 필요한 layer 추가하여 구성               좀 더 복잡한 model 필요 시 Keras 함수 API 사용                                                                   Model’s learning process 설정                            compile()               학습 전 학습에 대한 설정               손실 함수 및 최적화 방법 정의                                                                   learning process                            fit()               훈련 set 이용해 model로 학습                                                                   학습과정 살펴보기                            훈련 set - 검증 set의 손실 및 정확도 측정               반복 횟수에 따른 손실 및 정확도 추이를 보며 학습 상황 판단                                                                   Evalutate Model                            evaluate()               준비된 시험 set로 학습한 model 평가                                                                   use this model                            predict()               임의의 입력, get model’s output                                                   ML과의 차이점      ML은 모델 훈련만 - DL은 모델과 학습과정 설계 가능   ML은 학습 결과만 return - DL은 학습 과정 중간에 대한 check 가능   Sequential Model 맛보기   tensorflow.keras.layers      layers를 쌓아 만드는 model   multi-layer perceptron   from tensorflow.keras import layers  # 3개의 layers model = tf.keras.Sequential()  # 64개의 output units, 완전 연결 층 model.add(layers.Dense(64, activation = 'relu')) model.add(layers.Dense(64, activation = 'relu'))  # 10개의 output units, Softmax 층 model.add(layers.Dense(10, activation = 'softmax'))  ",
          
        "categories": ["Aidata","Python"],
        "tags": ["LectureNotes","Python","MachineLearning"],
        "url": "https://gitgitwi.github.io"/aidata/python/lec-ML_quick_review/"",
        "teaser": null
      },
    
      
      {
        "title": "CPTeam X 서초구청 외국계 취업 멘토링(IBM, AWS 등)",
        "excerpt":
          
            "date: Apr 29, 2020 6 ~ 9 PM   멘토분들 개인정보는 모두 가렸습니다. 문제시 삭제하겠습니다.          CPTeam X 서초구청 외국계 취업 특강&amp;멘토링      특강 : 한국 네슬레, LG전자   그룹멘토링 : 4개 직무 멘토 총 9명            1) 마케팅&amp;영업: J&amp;J , LG 생활건강       2) IT : AMAZON , IBM       3) HR&amp;총무 : NESPRESSO, CONTINENTAL AUTOMOTIVE, DELL       4) 경영지원&amp;홍보: DISNEY, OB 맥주                Section01. LG전자 멘토 특강   LG전자 소개      전세계 142개 Operations   총 근로자 74000명  (한국 54% 해외 46%)   LG Way      Customer-Value Creation : 고객이 원하는 것이 무엇인가   People-oriented Management : 인화, 인간 존중경영, 직원 - 협력사 존중   Jeong-Do Management : 정도 경영, ethical management 이상의 개념, 정정당당한, 떳떳한, 투명한   My Way?      Purpose   Competence   Passion   WAY; World Awaits You   시야를 한국에만 두지말고 전세계에 두자          Section02. 한국네스프레소 멘토   Nestle      85개국 32만명   2천개 이상의 브랜드   Nespresso      ‘집에서도 이태리 카페의 커피맛을 즐기게 하자’는 목표로 개발 시작   The Positive Cup; sustainability            100% 지속가능하게 관리되는 알루미늄 : 커피캡슐 재활용       100% 효율적인 이산화탄소 관리 : 한잔의 커피를 만들때 수많은 이산화탄소 발생, 탄소배출량 감소를 위해 커피원산지국에 500만 그루의 나무 심기 프로젝트, 현재까지 450만 그루, 한국 난지도에도           Brand Purpose : We Inspire Tasteful and Meaningful Living   84개국 14250 직원   810 boutiques(매장) in 523 cities   in Korea, 320 employees 18 boutiques since 2007   Key Behavior (주요 행동 역량)      inspiring people : leading &amp; develop people, practice what you say   opening up : energy for achievement, knowing yourself, insight, courage, curiousity about yourself and others, service-oriented mind   dealing with others : openness to diversity, positiveness,   → adding value : result-focused, innovation or renovation,   Future Leader      Learning Agility; 학습민첩성            the ability and willingness to learn from experience and subsequently apply that learning to perform successfully under new or first time conditions       항상 변화를 추구하는 것을 얘기하는 건 아니다           https://www.nespresso.com/kr          Section03. Panel Talk(Amazon/Disney/J&amp;J)   Disney      다들 영어 잘하고, 해외대 출신도 많긴한데, OPIC IH 이상이면 서류통과에 무리 없음   외국계에서 계약직이 정규직 전환되는 경우는 거의 없음, 그래도 Disney에서 계약직은 정규직과 차별없이 근무하기 때문에 기회가 있다면 꼭 해볼것을 추천   AWS      하루 2-3시간 이상 개인공부, 처음 두번 중소기업 근무하는 4년동안 휴가 10일씀   대부분 이공계 출신이지만, 문과+방통대컴공으로 온 케이스도 있음   AWS 엔지니어 기술 면접시 알고리즘 제일 중요   개발자 포지션은 한국에 없음, 개발자는 미국이나 호주 등으로 지원해야, 한국은 서버 엔지니어만 있음          Section04.  Small-Group Mentoring   멘토소개      전 IBM IT영업   Q&amp;A           본인이 걸어온 길을 분석, 역량 분석            Business Mind-Set            자신감; 이 회사가 지금 날 안뽑아주면 딴 데서 일하면 된다            수동적으로 뽑아주길 기다리지말고, 스스로 기회를 만들어야            불필요한 스펙은 불필요한 질문을 만들어냄, 본인이 잘 할 수 있는것에 집중해야 함       현재 IBM의 주력사업?            IBM annual report 검색, 다른 회사들도 마찬가지, 한국 공시제도와 다르게 미국은 회사마다 양식 다름       Portfolio 순서가 중요순                    Cloud           Data &amp; AI           Security           Blockchain                           IBM = International Business Machines corporation; HW company            HW사업에서 SW사업으로 transformation       양자 컴퓨터!!       RedHat 재인수           채용 방식 변화            채용형 인턴에서 신입 공채로       보통 8~9월 경 공고           인재상            기업이 왜 채용을 하는지에서 시작해야       직무연관성 : 대부분 뻔한 얘기기 때문에 너무 얽매이지 말고, 직무에 대해 생각해보자           한국IBM            개발을 위한 조직이 아닌 영업을 위한 조직       다만 한국에 맞는 상품을 제작하기 위해 엔지니어/개발자가 필요한 것, 따라서 많이 뽑을 수가 없다       아시아 AP 본사는 싱가폴에 있음       개발은 대기업보다는 중소기업이..           IT는 Hype Cycle을 항상 염두해야            그때그떄 유행을 따르지말고       Annual Report들을 보면서 각 회사가 주력으로 하려는 것에 주목해야       과거에는 근육을 쓰는 일, 현재는 뇌를 쓰는 일, 미래는 심장(마음)을 쓰는 일           https://www.gartner.com/smarterwithgartner/top-trends-on-the-gartner-hype-cycle-for-artificial-intelligence-2019/              https://www.gartner.com/smarterwithgartner/5-trends-appear-on-the-gartner-hype-cycle-for-emerging-technologies-2019/             ",
          
        "categories": ["Career"],
        "tags": ["Mentoring","MS","AWS"],
        "url": "https://gitgitwi.github.io"/career/CPTeamX%EC%84%9C%EC%B4%88%EA%B5%AC%EC%B2%AD_%EC%99%B8%EA%B5%AD%EA%B3%84_%EC%B7%A8%EC%97%85%EB%A9%98%ED%86%A0%EB%A7%81/"",
        "teaser": null
      },
    
      
      {
        "title": "Wikidocs & GithubPages Collections about DeepLearning, MachineLearning",
        "excerpt":
          
            "mkdate : 2020/04/29/Wed     with Python   딥 러닝을 이용한 자연어 처리 입문      원준   2020년 04월 28일   딥 러닝을 이용한 자연어 처리 심화      원준   2019년 11월 29일   PyTorch로 시작하는 딥 러닝 입문      원준   2020년 03월 17일   Machine Learning 강의노트      Andrew Ng 교수님 Coursera 강의 내용 정리 노트   지은이 : 박수진   최종 편집일시 : 2020년 4월 1일 7:29 오전   Deep Learning 강의노트      Andrew Ng 교수님 Coursera 강의 내용 정리 노트   지은이 : 박수진   최종 편집일시 : 2020년 3월 23일 11:37 오전   (블록과 함께하는) 파이썬 딥러닝 “케라스” 기초   Stanford’s CS 221 Artificial Intelligence   Stanford’s CS 229 Machine Learning    Stanford’s CS 230 ― Deep Learning   Yudonggeun/Deep-Learning-Examples      CNN   LSTM(RNN)   GAN   케라스와 함께하는 쉬운 딥러닝         with Hadoop, Spark   빅데이터 - 하둡, 하이브로 시작하기    Python 데이터 분석 실무      지은이 : Hunhwa   최종 편집일시 : 2020년 2월 16일 7:03 오후  ",
          
        "categories": ["Aidata","Python"],
        "tags": ["Python","MachineLearning","DeepLearning","Wikidocs","NLP","Keras","Hadoop","Spark","Tensorflow","Pytorch"],
        "url": "https://gitgitwi.github.io"/aidata/python/wikidocs_collections/"",
        "teaser": null
      },
    
      
      {
        "title": "[SKTacademy/딥러닝 입문에서 활용까지] 2강 다중클래스 ~ 3강 다층퍼셉트론(MLP)",
        "excerpt":
          
            "  2강. 다중클래스 ~ 3강. 다층 퍼셉트론(MLP)   강의 :  딥러닝 입문에서 활용까지 케라스(Keras)   제공처 : SKplanet Tacademy   Youtube      2강  Link   3강  Link   GithubPages      2강 Link   3강 Link   3강 실습 Link   실습 dataset      Kaggle &gt; 피마족 인디언 당뇨병 발병 dataset         import libraries &amp; dataset (mnist)   import keras from keras import datasets from keras.utils import np_utils from keras.models import Sequential from keras.layers import Dense, Activation import numpy as np   (X_train, y_train), (X_test, y_test) = datasets.mnist.load_data()   X_train.shape, y_train.shape, X_test.shape, y_test.shape   ((60000, 28, 28), (60000,), (10000, 28, 28), (10000,))       dataset 정규화 &amp; One-Hot-Encoding (categorize)   dataset      train data : 수능 모의고사   test data  :  작년 수능시험  문제   real data  :  올해 수능시험  문제   검증 dataset이 있어야 학습 중단 시점 결정 가능     overfitting 발생하는 구간 부근에서 학습 중단   스크린골프로 연습을 지나치게 하면,  오히려 필드에서 못치게 된다   ### channel of image      흑백 :  channel 1개   color : channel 3개   (R/G/B)   PNG : channel 4개 (R/G/B/a=투명)   X_train = X_train.reshape(-1, 28*28).astype('float32') / 255.0 X_test = X_test.reshape(-1, 28*28).astype('float32') / 255.0  y_train = np_utils.to_categorical(y_train) y_test = np_utils.to_categorical(y_test)   X_train.shape, y_train.shape, X_test.shape, y_test.shape   ((60000, 784), (60000, 10), (10000, 784), (10000, 10))   X_train[0]   array([0.        , 0.        , 0.        , 0.        , 0.        ,        0.        , 0.        , 0.        , 0.        , 0.        ,        0.        , 0.        , 0.        , 0.        , 0.        ,        0.        , 0.        , 0.        , 0.        , 0.        ,        0.        , 0.        , 0.        , 0.        , 0.        ,        0.        , 0.        , 0.        , 0.        , 0.        ,        0.        , 0.        , 0.        , 0.        , 0.        ,        0.        , 0.        , 0.        , 0.        , 0.        ,        0.        , 0.        , 0.        , 0.        , 0.        ,        0.        , 0.        , 0.        , 0.        , 0.        ,        0.        , 0.        , 0.        , 0.        , 0.        ,        0.        , 0.        , 0.        , 0.        , 0.        ,        0.        , 0.        , 0.        , 0.        , 0.        ,        0.        , 0.        , 0.        , 0.        , 0.        ,        0.        , 0.        , 0.        , 0.        , 0.        ,        0.        , 0.        , 0.        , 0.        , 0.        ,        0.        , 0.        , 0.        , 0.        , 0.        ,        0.        , 0.        , 0.        , 0.        , 0.        ,        0.        , 0.        , 0.        , 0.        , 0.        ,        0.        , 0.        , 0.        , 0.        , 0.        ,        0.        , 0.        , 0.        , 0.        , 0.        ,        0.        , 0.        , 0.        , 0.        , 0.        ,        0.        , 0.        , 0.        , 0.        , 0.        ,        0.        , 0.        , 0.        , 0.        , 0.        ,        0.        , 0.        , 0.        , 0.        , 0.        ,        0.        , 0.        , 0.        , 0.        , 0.        ,        0.        , 0.        , 0.        , 0.        , 0.        ,        0.        , 0.        , 0.        , 0.        , 0.        ,        0.        , 0.        , 0.        , 0.        , 0.        ,        0.        , 0.        , 0.        , 0.        , 0.        ,        0.        , 0.        , 0.01176471, 0.07058824, 0.07058824,        0.07058824, 0.49411765, 0.53333336, 0.6862745 , 0.10196079,        0.6509804 , 1.        , 0.96862745, 0.49803922, 0.        ,        0.        , 0.        , 0.        , 0.        , 0.        ,        0.        , 0.        , 0.        , 0.        , 0.        ,        0.        , 0.11764706, 0.14117648, 0.36862746, 0.6039216 ,        0.6666667 , 0.99215686, 0.99215686, 0.99215686, 0.99215686,        0.99215686, 0.88235295, 0.6745098 , 0.99215686, 0.9490196 ,        0.7647059 , 0.2509804 , 0.        , 0.        , 0.        ,        0.        , 0.        , 0.        , 0.        , 0.        ,        0.        , 0.        , 0.        , 0.19215687, 0.93333334,        0.99215686, 0.99215686, 0.99215686, 0.99215686, 0.99215686,        0.99215686, 0.99215686, 0.99215686, 0.9843137 , 0.3647059 ,        0.32156864, 0.32156864, 0.21960784, 0.15294118, 0.        ,        0.        , 0.        , 0.        , 0.        , 0.        ,        0.        , 0.        , 0.        , 0.        , 0.        ,        0.        , 0.07058824, 0.85882354, 0.99215686, 0.99215686,        0.99215686, 0.99215686, 0.99215686, 0.7764706 , 0.7137255 ,        0.96862745, 0.94509804, 0.        , 0.        , 0.        ,        0.        , 0.        , 0.        , 0.        , 0.        ,        0.        , 0.        , 0.        , 0.        , 0.        ,        0.        , 0.        , 0.        , 0.        , 0.        ,        0.3137255 , 0.6117647 , 0.41960785, 0.99215686, 0.99215686,        0.8039216 , 0.04313726, 0.        , 0.16862746, 0.6039216 ,        0.        , 0.        , 0.        , 0.        , 0.        ,        0.        , 0.        , 0.        , 0.        , 0.        ,        0.        , 0.        , 0.        , 0.        , 0.        ,        0.        , 0.        , 0.        , 0.        , 0.05490196,        0.00392157, 0.6039216 , 0.99215686, 0.3529412 , 0.        ,        0.        , 0.        , 0.        , 0.        , 0.        ,        0.        , 0.        , 0.        , 0.        , 0.        ,        0.        , 0.        , 0.        , 0.        , 0.        ,        0.        , 0.        , 0.        , 0.        , 0.        ,        0.        , 0.        , 0.        , 0.        , 0.54509807,        0.99215686, 0.74509805, 0.00784314, 0.        , 0.        ,        0.        , 0.        , 0.        , 0.        , 0.        ,        0.        , 0.        , 0.        , 0.        , 0.        ,        0.        , 0.        , 0.        , 0.        , 0.        ,        0.        , 0.        , 0.        , 0.        , 0.        ,        0.        , 0.        , 0.04313726, 0.74509805, 0.99215686,        0.27450982, 0.        , 0.        , 0.        , 0.        ,        0.        , 0.        , 0.        , 0.        , 0.        ,        0.        , 0.        , 0.        , 0.        , 0.        ,        0.        , 0.        , 0.        , 0.        , 0.        ,        0.        , 0.        , 0.        , 0.        , 0.        ,        0.        , 0.13725491, 0.94509804, 0.88235295, 0.627451  ,        0.42352942, 0.00392157, 0.        , 0.        , 0.        ,        0.        , 0.        , 0.        , 0.        , 0.        ,        0.        , 0.        , 0.        , 0.        , 0.        ,        0.        , 0.        , 0.        , 0.        , 0.        ,        0.        , 0.        , 0.        , 0.        , 0.        ,        0.31764707, 0.9411765 , 0.99215686, 0.99215686, 0.46666667,        0.09803922, 0.        , 0.        , 0.        , 0.        ,        0.        , 0.        , 0.        , 0.        , 0.        ,        0.        , 0.        , 0.        , 0.        , 0.        ,        0.        , 0.        , 0.        , 0.        , 0.        ,        0.        , 0.        , 0.        , 0.        , 0.1764706 ,        0.7294118 , 0.99215686, 0.99215686, 0.5882353 , 0.10588235,        0.        , 0.        , 0.        , 0.        , 0.        ,        0.        , 0.        , 0.        , 0.        , 0.        ,        0.        , 0.        , 0.        , 0.        , 0.        ,        0.        , 0.        , 0.        , 0.        , 0.        ,        0.        , 0.        , 0.        , 0.0627451 , 0.3647059 ,        0.9882353 , 0.99215686, 0.73333335, 0.        , 0.        ,        0.        , 0.        , 0.        , 0.        , 0.        ,        0.        , 0.        , 0.        , 0.        , 0.        ,        0.        , 0.        , 0.        , 0.        , 0.        ,        0.        , 0.        , 0.        , 0.        , 0.        ,        0.        , 0.        , 0.        , 0.9764706 , 0.99215686,        0.9764706 , 0.2509804 , 0.        , 0.        , 0.        ,        0.        , 0.        , 0.        , 0.        , 0.        ,        0.        , 0.        , 0.        , 0.        , 0.        ,        0.        , 0.        , 0.        , 0.        , 0.        ,        0.        , 0.        , 0.        , 0.18039216, 0.50980395,        0.7176471 , 0.99215686, 0.99215686, 0.8117647 , 0.00784314,        0.        , 0.        , 0.        , 0.        , 0.        ,        0.        , 0.        , 0.        , 0.        , 0.        ,        0.        , 0.        , 0.        , 0.        , 0.        ,        0.        , 0.        , 0.        , 0.        , 0.15294118,        0.5803922 , 0.8980392 , 0.99215686, 0.99215686, 0.99215686,        0.98039216, 0.7137255 , 0.        , 0.        , 0.        ,        0.        , 0.        , 0.        , 0.        , 0.        ,        0.        , 0.        , 0.        , 0.        , 0.        ,        0.        , 0.        , 0.        , 0.        , 0.        ,        0.09411765, 0.44705883, 0.8666667 , 0.99215686, 0.99215686,        0.99215686, 0.99215686, 0.7882353 , 0.30588236, 0.        ,        0.        , 0.        , 0.        , 0.        , 0.        ,        0.        , 0.        , 0.        , 0.        , 0.        ,        0.        , 0.        , 0.        , 0.        , 0.        ,        0.        , 0.09019608, 0.25882354, 0.8352941 , 0.99215686,        0.99215686, 0.99215686, 0.99215686, 0.7764706 , 0.31764707,        0.00784314, 0.        , 0.        , 0.        , 0.        ,        0.        , 0.        , 0.        , 0.        , 0.        ,        0.        , 0.        , 0.        , 0.        , 0.        ,        0.        , 0.        , 0.07058824, 0.67058825, 0.85882354,        0.99215686, 0.99215686, 0.99215686, 0.99215686, 0.7647059 ,        0.3137255 , 0.03529412, 0.        , 0.        , 0.        ,        0.        , 0.        , 0.        , 0.        , 0.        ,        0.        , 0.        , 0.        , 0.        , 0.        ,        0.        , 0.        , 0.        , 0.21568628, 0.6745098 ,        0.8862745 , 0.99215686, 0.99215686, 0.99215686, 0.99215686,        0.95686275, 0.52156866, 0.04313726, 0.        , 0.        ,        0.        , 0.        , 0.        , 0.        , 0.        ,        0.        , 0.        , 0.        , 0.        , 0.        ,        0.        , 0.        , 0.        , 0.        , 0.        ,        0.        , 0.53333336, 0.99215686, 0.99215686, 0.99215686,        0.83137256, 0.5294118 , 0.5176471 , 0.0627451 , 0.        ,        0.        , 0.        , 0.        , 0.        , 0.        ,        0.        , 0.        , 0.        , 0.        , 0.        ,        0.        , 0.        , 0.        , 0.        , 0.        ,        0.        , 0.        , 0.        , 0.        , 0.        ,        0.        , 0.        , 0.        , 0.        , 0.        ,        0.        , 0.        , 0.        , 0.        , 0.        ,        0.        , 0.        , 0.        , 0.        , 0.        ,        0.        , 0.        , 0.        , 0.        , 0.        ,        0.        , 0.        , 0.        , 0.        , 0.        ,        0.        , 0.        , 0.        , 0.        , 0.        ,        0.        , 0.        , 0.        , 0.        , 0.        ,        0.        , 0.        , 0.        , 0.        , 0.        ,        0.        , 0.        , 0.        , 0.        , 0.        ,        0.        , 0.        , 0.        , 0.        , 0.        ,        0.        , 0.        , 0.        , 0.        , 0.        ,        0.        , 0.        , 0.        , 0.        , 0.        ,        0.        , 0.        , 0.        , 0.        , 0.        ,        0.        , 0.        , 0.        , 0.        , 0.        ,        0.        , 0.        , 0.        , 0.        , 0.        ,        0.        , 0.        , 0.        , 0.        ], dtype=float32)   y_test[0]   array([0., 0., 0., 0., 0., 0., 0., 1., 0., 0.], dtype=float32)   검증 dataset  만들기   X_val = X_train[50000:] y_val = y_train[50000:]  X_train = X_train[:50000] y_train = y_train[:50000]   X_val.shape, y_val.shape, X_train.shape, y_train.shape   ((10000, 784), (10000, 10), (50000, 784), (50000, 10))       Make a Model   Layers   MLP  : Multi-Layer Perceptron   img example)         inputs : 3   weights : 3 * 2 = 6   ouputs : 2       code example)  Dense(8, input_dim=4, init='uniform', activation='relu'))      (units =) 8 : number of output neurons   input_dim = 4 : number of input neurons   여기서 학습해야할 data  수는 units * input_dim = 8 * 4 = 32      init= : 가중치 초기화 방법            'uniform' : 균일 분포,  default       'normal' : gaussian 분포           activation=: 활성화 함수, output을 어떻게 만들지            linear                    default           input neurons  X 가중치  계산한 결과값 그대로 출력           수치 예측하는  경우                       'relu'                    rectifier function           은닉층에서 주로 쓰임                       'Sigmoid'                    0~1  사이  실수 출력           binary classification                       'Softmax'                    각각의 확률을 더하면 100%           multi-classes classfication                           output_dim=            output 은닉층의 dimension       마지막 은닉층의 output_dim은 y의 dim과 같아야 함       y가 categorical type인 경우 category 수에 맞춰야           HyperParameter Tuning      바꿀 수 없는 option            첫번째 layer의 input_dim  :  입력되는 data의 dimension에 맞춰야       sigmoid activation layer의 units : 0  또는 1이 출력되어야 하므로 반드시 1           model = Sequential() model.add(Dense(units=64, input_dim = 28*28, activation='relu')) model.add(Dense(units=10, activation='softmax'))       Compile      model의 학습과정 설정   caategorical_crossentropy      entropy : Youtube 이찬우 딥러닝 참고   model.compile(loss='categorical_crossentropy', optimizer='sgd', metrics=['accuracy'])      Fit   batch-size           학습과정에서,  몇 문제를 풀고 network를 update할 것인지 결정            memory와 학습 size  모두에 영향            ex. 학습 데이터 =  100,  batch-size = 1  인 경우 : update  100회 발생       epoch           같은 dataset을 몇 번 학습할 것인지??            같은 문제집이라도 반복하면 학습이 일어난다  - overfitting 가능성       validation_data=(X_val, y_val)           한번의 epoch마다 학습한 내용을 가지고 검증            overfitting 일어나는 구간을 찾는 용도; val_accuracy가 감소하는 구간까지 epoch를 늘려서  찾아야 함       hist = model.fit(X_train, y_train, epochs=20, batch_size=32, validation_data=(X_val, y_val))   Train on 50000 samples, validate on 10000 samples Epoch 1/20 50000/50000 [==============================] - 3s 51us/step - loss: 0.1547 - accuracy: 0.9559 - val_loss: 0.1526 - val_accuracy: 0.9597 Epoch 2/20 50000/50000 [==============================] - 2s 48us/step - loss: 0.1487 - accuracy: 0.9576 - val_loss: 0.1485 - val_accuracy: 0.9600 Epoch 3/20 50000/50000 [==============================] - 3s 50us/step - loss: 0.1431 - accuracy: 0.9594 - val_loss: 0.1449 - val_accuracy: 0.9605 Epoch 4/20 50000/50000 [==============================] - 3s 61us/step - loss: 0.1382 - accuracy: 0.9603 - val_loss: 0.1401 - val_accuracy: 0.9628 Epoch 5/20 50000/50000 [==============================] - 3s 61us/step - loss: 0.1334 - accuracy: 0.9621 - val_loss: 0.1371 - val_accuracy: 0.9631 Epoch 6/20 50000/50000 [==============================] - 3s 61us/step - loss: 0.1289 - accuracy: 0.9635 - val_loss: 0.1349 - val_accuracy: 0.9637 Epoch 7/20 50000/50000 [==============================] - 2s 50us/step - loss: 0.1248 - accuracy: 0.9651 - val_loss: 0.1319 - val_accuracy: 0.9634 Epoch 8/20 50000/50000 [==============================] - 2s 48us/step - loss: 0.1209 - accuracy: 0.9657 - val_loss: 0.1295 - val_accuracy: 0.9642 Epoch 9/20 50000/50000 [==============================] - 2s 46us/step - loss: 0.1173 - accuracy: 0.9665 - val_loss: 0.1256 - val_accuracy: 0.9650 Epoch 10/20 50000/50000 [==============================] - 2s 47us/step - loss: 0.1139 - accuracy: 0.9680 - val_loss: 0.1234 - val_accuracy: 0.9659 Epoch 11/20 50000/50000 [==============================] - 2s 47us/step - loss: 0.1107 - accuracy: 0.9688 - val_loss: 0.1233 - val_accuracy: 0.9646 Epoch 12/20 50000/50000 [==============================] - 2s 45us/step - loss: 0.1077 - accuracy: 0.9697 - val_loss: 0.1202 - val_accuracy: 0.9664 Epoch 13/20 50000/50000 [==============================] - 2s 49us/step - loss: 0.1048 - accuracy: 0.9706 - val_loss: 0.1191 - val_accuracy: 0.9669 Epoch 14/20 50000/50000 [==============================] - 2s 47us/step - loss: 0.1021 - accuracy: 0.9711 - val_loss: 0.1155 - val_accuracy: 0.9677 Epoch 15/20 50000/50000 [==============================] - 2s 49us/step - loss: 0.0995 - accuracy: 0.9725 - val_loss: 0.1155 - val_accuracy: 0.9677 Epoch 16/20 50000/50000 [==============================] - 2s 49us/step - loss: 0.0968 - accuracy: 0.9728 - val_loss: 0.1138 - val_accuracy: 0.9676 Epoch 17/20 50000/50000 [==============================] - 2s 48us/step - loss: 0.0946 - accuracy: 0.9742 - val_loss: 0.1112 - val_accuracy: 0.9680 Epoch 18/20 50000/50000 [==============================] - 2s 48us/step - loss: 0.0922 - accuracy: 0.9747 - val_loss: 0.1097 - val_accuracy: 0.9683 Epoch 19/20 50000/50000 [==============================] - 2s 46us/step - loss: 0.0901 - accuracy: 0.9751 - val_loss: 0.1105 - val_accuracy: 0.9685 Epoch 20/20 50000/50000 [==============================] - 2s 47us/step - loss: 0.0881 - accuracy: 0.9758 - val_loss: 0.1084 - val_accuracy: 0.9699       실습 : Pima Indian Diabetes   data = np.loadtxt('/content/pima-indians-diabetes.csv', delimiter=',') data.shape   (768, 9)   data[:10]   array([[6.000e+00, 1.480e+02, 7.200e+01, 3.500e+01, 0.000e+00, 3.360e+01,         6.270e-01, 5.000e+01, 1.000e+00],        [1.000e+00, 8.500e+01, 6.600e+01, 2.900e+01, 0.000e+00, 2.660e+01,         3.510e-01, 3.100e+01, 0.000e+00],        [8.000e+00, 1.830e+02, 6.400e+01, 0.000e+00, 0.000e+00, 2.330e+01,         6.720e-01, 3.200e+01, 1.000e+00],        [1.000e+00, 8.900e+01, 6.600e+01, 2.300e+01, 9.400e+01, 2.810e+01,         1.670e-01, 2.100e+01, 0.000e+00],        [0.000e+00, 1.370e+02, 4.000e+01, 3.500e+01, 1.680e+02, 4.310e+01,         2.288e+00, 3.300e+01, 1.000e+00],        [5.000e+00, 1.160e+02, 7.400e+01, 0.000e+00, 0.000e+00, 2.560e+01,         2.010e-01, 3.000e+01, 0.000e+00],        [3.000e+00, 7.800e+01, 5.000e+01, 3.200e+01, 8.800e+01, 3.100e+01,         2.480e-01, 2.600e+01, 1.000e+00],        [1.000e+01, 1.150e+02, 0.000e+00, 0.000e+00, 0.000e+00, 3.530e+01,         1.340e-01, 2.900e+01, 0.000e+00],        [2.000e+00, 1.970e+02, 7.000e+01, 4.500e+01, 5.430e+02, 3.050e+01,         1.580e-01, 5.300e+01, 1.000e+00],        [8.000e+00, 1.250e+02, 9.600e+01, 0.000e+00, 0.000e+00, 0.000e+00,         2.320e-01, 5.400e+01, 1.000e+00]])   type (data)   numpy.ndarray   ",
          
        "categories": ["Aidata","Python"],
        "tags": ["Python","DeepLearning","Keras"],
        "url": "https://gitgitwi.github.io"/aidata/python/Keras02_03_SKTacademy/"",
        "teaser": null
      },
    
      
      {
        "title": "[SKTacademy/딥러닝 입문에서 활용까지] 4강. CNN; Convolutional Neural Networks",
        "excerpt":
          
            "  4강. CNN; Convolutional Neural Networks   강의 :  딥러닝 입문에서 활용까지 케라스(Keras)   제공처 : SKplanet Tacademy   Youtube      4강  Link   GithubPages      4강 Link   4강  실습 Link   실습 dataset      손글씨 이미지         CNN; Convolutional Neural Networks   keras.layers.convolutionalConv2D  example)  Conv2D(             filters,              kernel_size,              strides=(1, 1),              padding='valid',              data_format=None,              dilation_rate=(1, 1),              activation=None,              use_bias=True,              kernel_initializer='glorot_uniform',              bias_initializer='zeros',              kernel_regularizer=None,              bias_regularizer=None,              activity_regularizer=None,              kernel_constraint=None,              bias_constraint=None,              **kwargs)  Conv2D(32, (5,5), padding = 'valid', input_shape=(28,28,1), activation='relu')   Argments     filers            number of convolution filters       출력 data  개수와 동일           kernel_size : (rows, cols) of convolutional kernels   *학습 데이터 수 =  filers * kernel rows * kernel cols           padding= : 경계 처리 방법               valid : 유효한 영역만 출력,  따라서 출력 이미지 사이즈는 입력  이미지 사이즈보다 작다       same : 출력 이미지 사이즈가 입력 이미지 사이즈와 동일                input_shape=: sample 수 제외한 입력 형태 정의. 첫 layer에서만 정의하면 됨             (rows, cols, channels) : 흑백영상인 경우 channel == 1, RGB인 경우 channel=3           filter         하나의 filter로 전체 input에 대해 학습   지역적인 요소;  어떤 지역에 대해 학습한 내용이 다른 지역에 영향을 미치지 않음   Dense layer를 통해서도 구현할 수 있으나,  CNN을 사용하면  훨씬 적은 가중치를 통해서 더 좋은 성능을 만들 수 있음   keras.layers.convolutional.MaxPooling2D   MaxPooling2D(         pool_size=(2, 2),          strides=None,          padding='valid',          data_format=None,          **kwargs)        각 pixel에서 가장 큰 것만 추출해 이미지 size 축소,  사소한 변화는 무시 (추상화)   학습하는 내용은 없음   Arguments      pool_size= : (rows, cols)   keras.layers.Flatten   Flatten(     data_format=None,      **kwargs)     다차원 tensor를 1차원으로 flattening   학습하는 내용은 없음   ImageDataGenerator : 데이터 부풀리기   ImageDataGenerator(         featurewise_center=False,          samplewise_center=False,          featurewise_std_normalization=False,          samplewise_std_normalization=False,          zca_whitening=False,          zca_epsilon=1e-06,          rotation_range=0,          width_shift_range=0.0,          height_shift_range=0.0,          brightness_range=None,          shear_range=0.0,          zoom_range=0.0,          channel_shift_range=0.0,          fill_mode='nearest',          cval=0.0,          horizontal_flip=False,          vertical_flip=False,          rescale=None,          preprocessing_function=None,          data_format='channels_last',          validation_split=0.0,          interpolation_order=1,          dtype='float32')  ",
          
        "categories": ["Aidata","Python"],
        "tags": ["Python","DeepLearning","Keras"],
        "url": "https://gitgitwi.github.io"/aidata/python/Keras04_CNN/"",
        "teaser": null
      },
    
      
      {
        "title": "[SKTacademy/딥러닝 입문에서 활용까지] 5강. RNN;  Recurrent Neural Networks",
        "excerpt":
          
            "  5강. RNN;  Recurrent Neural Networks   강의 :  딥러닝 입문에서 활용까지 케라스(Keras)   제공처 : SKplanet Tacademy   Youtube      5강  Link   GithubPages      5강 Link   5강  실습 Link         keras.layers.LSTM   LSTM(         units,          activation='tanh',          recurrent_activation='sigmoid',          use_bias=True,          kernel_initializer='glorot_uniform',          recurrent_initializer='orthogonal',          bias_initializer='zeros',          unit_forget_bias=True,          kernel_regularizer=None,          recurrent_regularizer=None,          bias_regularizer=None,          activity_regularizer=None,          kernel_constraint=None,          recurrent_constraint=None,          bias_constraint=None,          dropout=0.0,          recurrent_dropout=0.0,          implementation=2,          return_sequences=False,          return_state=False,          go_backwards=False,          stateful=False,          unroll=False,          **kwargs)   Arguments      units : number of output data   input_dim=   input_length=   return_sequences=   stateful= : 상태 유지 여부   ",
          
        "categories": ["Aidata","Python"],
        "tags": ["Python","DeepLearning","Keras"],
        "url": "https://gitgitwi.github.io"/aidata/python/Keras05_RNN/"",
        "teaser": null
      },
    
      
      {
        "title": "[SKTacademy/딥러닝 입문에서 활용까지] 6강. GM  ~  7강. Keras vs. PyTorch",
        "excerpt":
          
            "  6강. GM  ~  7강. Keras vs. PyTorch   강의 :  딥러닝 입문에서 활용까지 케라스(Keras)   제공처 : SKplanet Tacademy   Youtube      6강  Link   7강  Link   GithubPages      Link   Link2         GM; Generator Model, 생성 모델      최신 model들은 대부분 generator를 갖고 있다   단순히 분류  뿐만 아니라 만들어  냄            ex. 고양이 이미지 학습 후 고양이 이미지 생성           잠재공간;  학습 data에 없는 내용도 잠재 vector로 만들어서 아예 새로운 data 생성   GAN  Progressive GAN   연예인 사진 학습하여 deeplearning이 실제에 가까운 가상 인물 이미지 생성   Keras vs. PyTorch   deepsense.ai &gt; Keras or PyTorch as your first deep learning framework   최신 논문  &amp;  Code   https://paperswithcode.com/sota  ",
          
        "categories": ["Aidata","Python"],
        "tags": ["Python","DeepLearning","Keras"],
        "url": "https://gitgitwi.github.io"/aidata/python/Keras06_GM/"",
        "teaser": null
      },
    
      
      {
        "title": "[SKTacademy/코드로 알아보는 딥러닝 입문] DNN/CNN/GAN/RNN/RL with Tensorflow",
        "excerpt":
          
            "  코드로 알아보는 딥러닝 입문      강사 :  임도형 (엑셈)   일자 :  2019.1.17(목)   제공 :  SKplanet Tacademy   playlist : https://www.youtube.com/playlist?list=PL9mhQYIlKEhcutlrKpdnO83LNq_yke3FS     Deep Learning 동작   Deep Learning 이해   용어      model   training set   test set, evaluation set   iteration, step, epoch   learning, training   feature, feature/input vector   weight   Cost Function   학습은 오차/error를 최소로  하는 지점을 찾는 것   Gradient Descent; 경사  하강법           비용함수가 최소인 지점을 찾는 방법            미분 활용            다양한 파생 방식들이 있음            모델에 따라 방정식 모양 다름           Neural Network   Perceptron      임계점을 넘은 값만 넘겨줌   선형분리가 가능한 문제만 가능            AND / OR  문제  가능       XOR 문제 불가능       단순한 perceptron model로는 실생활 문제를 해결할 수 없음           선형 분리 불가 문제의 해결법들      입력 차원  늘림   입력을 비선형 변환하여 선형 분리 가능하도록   MLP   MLP; Multi-Layer Perceptron      입력과 출력 사이 여러 층   1개의 Perceptron은 1개의 선형 분리 가능            perceptron의 결과를 다른 perceptron의 입력으로 만들어  여러개의 선형 분리           일반적인 Deep Learning 방식으로 자리 잡음; DNN, Deep Neural Network   DNN      임의의 함수를 근사화함   함수의 내부를 알수 없고,,   input data / output data만 가지고 함수를 machine이 직접 만듦   Deep Learning      DNN은 함수 근사화 능력이 있음   입출력 쌍을 계속 제공하여 DNN  내부 weight를 지속적으로 update   이를 위해  내부에서  BP(Nack Propagation),  GD(Gradient Descent)  Algorithm  사용   충분한 Input/Output data와 computing power  필요   이 과정을 반복해 함수를 근사화하는 것을 DNN의 학습, Deep Learning이라 함       AI / ML / DL      사람 손이 아닌 기계가 알아서 하면 인공지능   전문가 지식을 직접 hard-coding 하던가   data를 통해 기계가 직접 logic을 찾던가   ML      data에서 가치를 찾아내는 방법   수많은 방법            SVM       Decision Tree       Random Forest       Bayesian       K-Means Clustering       KNN       Neural Network           ML 전문가라면 이러한 방법 20가지  정도는 손에 익어서,,  언제 어떤 방법  사용해야 하는지 알아야   DL      신경망을 사용한 ML의 한 방법   Neural Network의 은닉층이 많아서 (Deep) Deep Learning이라 부름   신경망 - 심층신경망      20년 전 AI/ML에 대한 기대가  있었으나, 엄청난 계산량 때문에 결과 못보임, 기대만큼의 실망   DNN은 기존 NN과 다른게 없으나, 최근 대용량 저장공간, computing power  덕분에 압도적 성능 보임   실망했던  용어 대신 붐을 다시 일으키기 위한 용어   요즘 신경망의 압도적인 성능으로 ML의 대부분은 신경망 사용,,  그러면서 그냥 AI = ML = DL로 부름   DL을 쓸 때와  ML을 쓸 떄      DL은 비용이 비싸다            data 비용       computing power 비용; GPU or Cloud           다만 ML로 풀리지 않는 문제들은 어쩔 수 없이 DL로       ML frameworks   Tensorflow      가장 많이 사용되는 ML framework   실제 실행되는 core(CPU/GPU/Android/iOS..) &amp; 연산 정의하고 요청하는 front-end(Python/C)   학습할 때는 GPU  등 고성능이  필요하지만,,  사용자체는 모바일에서도 가능함   Keras      보다 간단하고 사용하기 편리   *논문을 코드로 구현하는 건 보통 6개월,,  아무리 잘하는 사람도 최소 2주  정도는 걸린다..  구현체가 함께 있는 논문 위주로 보면 됨 *DL을 잘하려면 일단 돈이 있어야함..  학교보다는 회사가 더 잘할 수 밖예 없다..   Tensorflow 개요   Graph      연산될 내용 정의   Session      Core와의 session  생성,,  graph와 data  전달하여 연산 실행   실제 연산은 sess.run()  할 때 실행됨   3 types of data      Constant : 변하지 않는 상수   Variable : update할 대상        Placeholder : data         X = tf.placeholder (tf.float32, [None, 3])   W = tf.Variable (tf.random_normal([3, 2))   b = tf.Variable (tf.random_normal([2, 1]))           Structure of DL code   3개의 정의 +  실행     Model : NN Model   Cost Function   Optimizer   pred = multilayer_perceptron(x, weights, biases) cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits = pred, labels = y)) optimizer = tf.train.AdamOptimizer(learning_rate = learning_rate).minimize(cost) sess.run(optimizer, feed_dict={x : batch_x, y : batch_y})       Deep Learning 기술용어      MSE; Mean Squared Error   CE; Cross Entropy   KL-Divergence   MLE; Maximum Likelihood Estimation   Optimizer 종류   오차에 대해 w를 update  시키는 algorithms      GD; Gradient Descent   Batch GD   Mini-Batch GD   SGD; Stochastic GD   Momentum   AdaGrad   AdaDelta   Adam   RMSprop   Overfitting 방지법  종류      DropOut   BN; Batch Normalization        Regularization       *Data Augmentation : data를 임의로 증폭,,  영상처리에선 필수,,  domain에 따라 적용 여부는 다르다   Activation Function 종류      sigmoid ( = logistics)   Tanh   ReLU   Leaky ReLU   SoftMax : 최종 출력층에서 사용   Learning Rate      w가 변경되는 정도   Back Propagation;  역전파      출력값과 원하는 값과의 차이,,  오차를 가지고 그 전 w값들을 update하는 algorithm   뒤(back)에서부터 그 오차 값이 전파(propagation)   실제 변경되는 값의 크기는 GD로 결정         모델별 기본 코드구조           자료 :  https://notebooks.azure.com/dhrim/projects            코드 한줄 한줄  다  이해하고 넘어가려고 하지말고,,  중요한 것부터 이해하면서 진행해야…       DNN   IRIS 분류           notebook : https://notebooks.azure.com/dhrim/projects/t-academy-deep-learning/html/Iris/iris.ipynb            original codes : https://www.tensorflow.org/get_started/tflearn            MLP Model             input nodes(features) : 4       hidden layers : 3       nodes of hidden layers : 10, 20, 10       ouput nodes : 3           MNIST 손글씨 숫자 분류      notebook: https://notebooks.azure.com/dhrim/projects/t-academy-deep-learning/html/mnist/mnist.ipynb   Parameters     learning_rate = 0.001 : GD를 할 떄  움직이는 폭,,  0.001이 일반적으로 가장 많이 사용하는 learning_rate   training_epochs = 15 : 실무에서 보통 5천번 정도            data 수  : 실무에서 최소 1만개 이상,  10만개 이상이어야 적당하다고 봄,,  1천개 정도는 overfitting 많이 일어나서 불안           Create model   def multilayer_perceptron(x, weights, biases):     # Hidden layer with RELU activation     layer_1 = tf.add(tf.matmul(x, weights['h1']), biases['b1'])     layer_1 = tf.nn.relu(layer_1)     # Hidden layer with RELU activation     layer_2 = tf.add(tf.matmul(layer_1, weights['h2']), biases['b2'])     layer_2 = tf.nn.relu(layer_2)     # Output layer with linear activation     out_layer = tf.matmul(layer_2, weights['out']) + biases['out']     return out_layer     tf.add(tf.matmul(x, weights['h1']), biases['b1'])            layer_1 (y) = w*x + b  를 만드는 과정       tf.matmul(a, b) : matrix의 곱, a  *  b       tf.add(a, b) : a+b           *DL algorithm을 직접 짜고 싶다면 (NHN Clova, Kakao Brain 등 지원한다든지..) 이론적으로 깊게 들어가야 하지만,,  DL을 활용한 서비스를 개발하고 싶다면 사용 방법만 잘 알면 된다        CNN; Convolutional NN   구조      출처 :  https://www.kakaobrain.com/blog/9      convolution filter와 pooling  반복   이후 일반 DNN에 적용   Convolution Filter      출처 :  https://mc.ai/understanding-the-structure-of-a-cnn/      사람 눈에 특정 모양에 반응하는 신경세포들을 구현   computer vision에 나왔던 기법   source pixel과 filter pixel의 각각  대응하는 값을 곱한 뒤 더해서 filter pixels 수로 나눔   filter  모양의 자극이 있으면 그 결과가 최대가 됨,, 이미지에서 filter 모양이  몇 개나 있는지 찾아내는 것   Stride : filter 적용 시 이동하는 칸 수,,  보통은 1   Padding : filter 적용 시 이미지가 작아지는데,  원본 사이즈를 유지할지 작아지도록 만들지   MaxPooling      각 지역에서 가장 큰 값만 추출   보통 Stride==2   이미지가 그만큼 작아짐   Average Pooling도 있으나 보통은 Max Pooling 사용   성능      이미지 처리에 뛰어남   이미지 처리 외에도 좋은 성능 보임   DNN  보다  좋기 때문에  DL 할 경우 default로 사용함   CNN으로 MNIST 손글씨 숫자 분류   notebook : https://notebooks.azure.com/dhrim/projects/t-academy-deep-learning/html/CNN/cnn.ipynb      입출력 등 대부분 DNN과 동일   Model 만 CNN       X = tf.placeholder(tf.float32, [None, 28, 28, 1])   Y = tf.placeholder(tf.float32, [None, 10])   is_training = tf.placeholder(tf.bool)    L1 = tf.layers.conv2d(X, 32, [3, 3])   L1 = tf.layers.max_pooling2d(L1, [2, 2], [2, 2])   L1 = tf.layers.dropout(L1, 0.7, is_training)    L2 = tf.layers.conv2d(L1, 64, [3, 3])   L2 = tf.layers.max_pooling2d(L2, [2, 2], [2, 2])   L2 = tf.layers.dropout(L2, 0.7, is_training)    L3 = tf.contrib.layers.flatten(L2)   L3 = tf.layers.dense(L3, 256, activation=tf.nn.relu)   L3 = tf.layers.dropout(L3, 0.5, is_training)    model = tf.layers.dense(L3, 10, activation=None)           tf.layers.dropout() : overfitting 방지 위한 함수   Hyperparameter      Hidden layer를 몇개를 두고,,  dropout을 언제 하고 등등   정해진 방법이 없다   알아서 대충…   또 하나의 연구분야임; AutoML        Google의  VGG-16 model; 왜 이  구조에서  효율이 좋은지 아무도 모른다…                      GAN; Generative Adversarial Networks   notebook : https://notebooks.azure.com/dhrim/projects/t-academy-deep-learning/html/GAN/gan.ipynb      labeling data : DL의 기본, 다만 현실/실무에서 찾기가 정말 힘듦   이러한  labeling data  없이 학습시키기 위한 비지도학습 중 가장 성공한 것이 GAN            진짜 이미지는 구하기 쉽다       학습을 위한 가짜 이미지는 별도로 준비 X           ex. Image Translation : https://phillipi.github.io/pix2pix/      월 500편 이상 논문 발표될 정도로 핫한 분야       Structure      출처 :  https://awesomeopensource.com/project/hwalsuklee/tensorflow-generative-model-collections?categoryPage=11      Discriminator : 판별기            이미지가 진짜인지 가짜인지 판별       진짜 이미지  X에 대한 결과 D_real은 1       생성한 가짜 이미지 G에 대한 결과 D_gene은 0       loss function : loss_D = log(D_real) + log(1-D_gene)           Generator : 생성기            noise에서 가짜 이미지 생성       생성기의 출력을 판별기의 입력으로 사용       생성한 가짜 이미지 G에 대한 결과 D_gene은 1       loss function : loss_G = log(D_gene)           D와 G 모두 CNN   개별 학습 :  loss_G와 loss_D를 교대로  학습   학습 완료되면 생성기는 판별기가 구별 못하는 가짜 이미지 생성   Noise      이미지는 28  *  28  =  784  차원   임의의 이미지 대부분은 의미 없는 이미지   자연스런 숫자처럼 보이는 이미지는 784차원 공간에서 극히 일부분   입력으로 사용된 128차원은 그 극히 일부분에 mapping  됨            128차원의 대부분은 자연스러운 숫자       이러한 입력 공간을 잠재 공간 (Latent Space)라 함       Interpolation                 RNN;  Recurrent NN         상태를 가지고 있음   다음 연산에서 그 상태를 입력으로 사용   ex) [‘h’,’e’,’l’,’l’,’o’]  학습  :  첫번째 l일 때와 두번째 l일 때의 출력이 다름   사용  예: auto-complete,  기계 번역   LSTM; Long Short Term Memory   RNN의 단점을 보완한 Model   Word2Vec   단어를 vector로 표현…   Google Data Center의 실례   전력을 얼마나 아끼느냐가 수익의 핵심 중 하나   논문  발표 이후 전력 사용 분야 bible이 됨   (Google 1개월 인턴이 논문 작성)   DNN 적용   학습 data     input : 측정 센서 데이터, 19개 vector   output : PUE (Power Usage Effectiveness), 작을 수록 좋음   예측 결과 : mean absolute error = 0.4%   simulation이 가능하면     운영 parameter를 변경하여 simulation, PUE  변동 예측 가능   최적 PUE를 위한 운영 parameter와 값을 찾고 적용 가능   가상의 환경에서 요인별 분석 가능;  외부 온도가 가장 영향이 크다고 분석됨         RL;  Reinforcement Learning   상호 작용을 통해 목표를 달성하는 방법을 배우는 문제   DQN; Deep Q Network   강화학습에  DNN 적용   쿠키런     액션과 점수를 매칭시켜 강화학습   지도학습 data 없이, 점수에 따라 학습   Robotics  분야에서  많이 사용     perfect data 를 찾을 수 없기 때문에   Boston Dynamimcs 영상            기존의 제어계측 방식에서 DL 방식으로 전환           Google Deepmind의 Atari Game         AlphaGo      2개의 DNN network + MCTS   Policy Network            input layer + convolutional layer + output layer       프로기사 100 명의 기보 활용,  이것만 가지고는 프로기사 100  명 중 50 등 정도의 성적,       바둑 프로그램 Pachi를 상대로 85%  승률       경우의 수를 크게 줄이는 역할,  상위 20개만 출력, 출력된 수만 고려           Value Network            현재 판을 가지고 유리/불리 학습       최종 결과(1,  0)를 학습       Policy Network를 통해 스스로 학습한 데이터를 입력       게임의 끝까지 가보지 않아도       검색  깊이를 줄임           MCTS; Monte-Carlose Tree Search   중국식 기보를 학습했기 때문에,,  이세돌과의 대국 당시에도 중국식으로  ",
          
        "categories": ["Aidata","Python"],
        "tags": ["Python","MachineLearning","DeepLearning","Tensorflow"],
        "url": "https://gitgitwi.github.io"/aidata/python/DLwithCodes/"",
        "teaser": null
      }
    
  
]
