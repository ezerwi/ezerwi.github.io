<!doctype html>
<!--
  Minimal Mistakes Jekyll Theme 4.19.1 by Michael Rose
  Copyright 2013-2019 Michael Rose - mademistakes.com | @mmistakes
  Free for personal and commercial use under the MIT license
  https://github.com/mmistakes/minimal-mistakes/blob/master/LICENSE
-->
<html lang="en" class="no-js">
  <head>
    <meta charset="utf-8">

<!-- begin _includes/seo.html -->








<title>[Python] ML Quick Review - gitgitWi’s gitgit pages</title>
<meta name="description" content="연휴기간 (04/30~05/05) 과제     본인이 지원하고자하는 회사 3군데 조사   1.의 회사 관련 포트폴리오 주제 선정            06/01 ~ 06/14 : 최종 포트폴리오 준비 기간       06/15 : 프로젝트 발표       동시에 Java Spring 추가 학습 예정             1. Machine Learning  Basic Types     지도학습 (supervised learning)   비지도학습 (unsupervised learning)   두 학습 모두 컴퓨터가 인식 가능한 입력 데이터 필요 (0, 1)  고려사항     어떤 질문에 대한 답을 원하는가? 현재 데이터가 원하는 답을 줄 수 있는가?   내가 원하는 질문의 답에 대한 ML 기술/algorithm은 무엇?   충분한 학습용 데이터가 있는지?   현재 데이터의 특성, 좋은 예측을 만들수 있는지?   ML App.의 성과를 어떻게 측정할 수 있는지?   ML Solution이 다른 연구/제품과 어떻게 협력할 수 있는가?     2. Python Libraries related to ML     Scikit-learn   Numpy   Scipy : 희소행렬(sparse matrix)   Matplotlib : plots   Pandas : DataFrame, Series     3. Scikit-learn  KNN (k-nearest neighbors) Model  Iris dataset로 단순하게 구현해보기; KNN 관련 가장 간단한 dataset  dataset     학습 : 기출문제   훈련 : 모의고사   예측 : 실제 시험   지도 학습 및 훈련을 위한 dataset은 사람이 직접 만들어줘야 함 일반적으로 학습 : 훈련 = 7 : 3   Check Characteristics of data     data에 대한 사전 탐색 필수   web project의 경우 data-flow 중요   iris = load_iris() type(iris)                  # sklearn.utils.Bunch iris.keys() iris.target_names           # 품종명 iris.feature_names          # [&#39;sepal length (cm)&#39;, &#39;sepal width (cm)&#39;, &#39;petal length (cm)&#39;, &#39;petal width (cm)&#39;]                             # [꽃받침 길이, 꽃받침 폭, 꽃잎 길이, 꽃잎 폭] iris_dataset.data.shape     # (150, 4) : sample 150, attribution 4 iris.data[:10]              # ML에서 각 item은 &quot;sample&quot;이라하고, 속성은 &quot;특성&quot;이라 함 iris.target                 # results of labeling   이 dataset에 없는 새로운 data가 들어왔을때, 그 품종을 예측하는 ML Model을 만드는 것이 목적   Evaluate the ML Model     Model에 대한 성능 평가   Problems of Overfitting; not-normalized   -&gt; ML의 성능을 높이고 일반화하기 위해, 주어진 데이터를 train data - test data로 나눠야 함   sklearn.model_selection.train_test_split : Split data     train data, test data   관례) scikit-learn에서 data는 대문자 X, label은 소문자 y로 표기   수학 표기 방식을 따르되, data는 2차원 matrix이므로 대문자 X, target은 1차원 vector이므로 소문자 y 사용   데이터가 순서대로 나누어지지 않도록, random 하게 섞음   test set은 모든 class의 data를 포함하도록 잘 섞어야 함   from sklearn.model_selection import train_test_split X_train, X_test, y_train, y_test = train_test_split(iris_dataset.data, iris_dataset.target, test_size = 0.25, random_state = 2020)  print (X_train.shape, X_test.shape, y_train.shape, y_test.shape) print (X_train[:10], X_test[:10], y_train[:10], y_test[:10],)     Look into data  ML 없이도 풀수 있는 문제가 아닌지, 필요한 정보가 누락되어 있는지 data 조사  DataFrame, Scatter plot  iris_df = pd.DataFrame(X_train, columns=iris_dataset.feature_names) iris_df.head() iris_df.isnull().sum() pd.plotting.scatter_matrix(iris_df, c = y_train, figsize=(15,15), marker=&#39;o&#39;, hist_kwds={&#39;bins&#39; : 20}, s=60, alpha=.8)     Fitting (Machine Learning) by KNN Model  from sklearn.neighbors import KNeighborsClassifier knn = KNeighborsClassifier(n_neighbors = 3) knn.fit(X_train, Y_train)     KNN Model  K-nearset neighbors     train data 를 통해 model 만들고, 새로운 data 들어오면 가까운 훈련 data point를 찾아 분류   scikit-learn의 모든 ML model은 estimator라는 python class로 구현   KNN algorithm은 neighbors module 아래 KNeighborsClassifier class에 구현   parameters of KNN  KNeighborsClassifier(algorithm=&#39;auto&#39;,                      leaf_size=30,                      metric=&#39;minkowski&#39;,                      metric_params=None,                      n_jobs=None,                      n_neighbors=3,                      p=2,                      weights=&#39;uniform&#39;)     Predict about new data  n by 4 array  X_new = np.array([[3, 4.2, 0.8, 0.4]]) prediction = knn.predict(X_new) print (f&quot;Predict about X_new : {prediction}&quot;) print (f&quot;Name of the predicted one : {iris_dataset.target_names[prediction]}&quot;)  y_predict = knn.predict(X_test) y_predict == y_test     Evaluate Accuracy  print (f&quot;Accuracy of test set by &#39;mean&#39; : {np.mean(y_predict == y_test) * 100}&quot;) print (f&quot;Accuracy of test set by &#39;knn.score&#39; : {knn.score(X_test, y_test) * 100}&quot;)  from sklearn import metrics print (f&quot;Accuracy of test set by &#39;metrics.accuracy_score&#39; : {metrics.accuracy_score(y_test, y_predict) * 100}&quot;)   multiple ‘k’s  accuracy_set = [] k_set = [i for i in range(1,12,2)] print (k_set)  for k in k_set:     knn = KNeighborsClassifier(n_neighbors=k)     knn.fit(X_train, y_train)     y_predicts = knn.predict(X_test)     accuracy = metrics.accuracy_score(y_test, y_predicts)     accuracy_set.append(accuracy)  from pprint import pprint pprint(accuracy_set) print (max(accuracy_set))     kfold for Cross Validation       sklearn.model_selection.cross_val_score   train_test_split() 보다 성능이 좋은 평가방법   데이터를 k번 쪼개서 k번 검증   cross-val-score              dataset : sklearn.datasets.load_breast_cancer        type(cancer)   cancer.data[:10]   cancer.feature_names   cancer.target_names   cancer.target[:10]                test models            sklearn.linear_model.LinearRegression         LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None, normalize=False)                       sklearn.neighbors.KNeighborsClassifier               KNeighborsClassifier(algorithm=&#39;auto&#39;,                          leaf_size=30, metric=&#39;minkowski&#39;,                         metric_params=None,                         n_jobs=None,                          n_neighbors=4,                          p=2,                         weights=&#39;uniform&#39;)  `    sklearn.svm.LinearSVC     LinearSVC(C=1.0,              class_weight=None,              dual=True,              fit_intercept=True,              intercept_scaling=1,              loss=&#39;squared_hinge&#39;,              max_iter=1000,              multi_class=&#39;ovr&#39;,              penalty=&#39;l2&#39;,              random_state=0,              tol=0.0001,              verbose=0)           sklearn.tree.DecisionTreeClassifier     DecisionTreeClassifier(class_weight=None,                          criterion=&#39;gini&#39;,                          max_depth=3,                          max_features=None,                          max_leaf_nodes=None,                          min_impurity_decrease=0.0,                          min_impurity_split=None,                          min_samples_leaf=1,                          min_samples_split=2,                          min_weight_fraction_leaf=0.0,                          presort=False,                          random_state=0,                          splitter=&#39;best&#39;)           sklearn.ensemble.RandomForestClassifier     RandomForestClassifier(bootstrap=True,                          class_weight=None,                          criterion=&#39;gini&#39;,                         max_depth=None,                          max_features=&#39;auto&#39;,                          max_leaf_nodes=None,                         min_impurity_decrease=0.0,                          min_impurity_split=None,                          min_samples_leaf=1,                          min_samples_split=2,                          min_weight_fraction_leaf=0.0,                          n_estimators=6,                          n_jobs=None,                          oob_score=False,                          random_state=None,                          verbose=0,                          warm_start=False)           exec. Cross Value Score  score1 = cross_val_score( lr, cancer.data, cancer.target) score2 = cross_val_score( knn, cancer.data, cancer.target) score3 = cross_val_score( svm, cancer.data, cancer.target) score4 = cross_val_score( tree, cancer.data, cancer.target) score5 = cross_val_score( forest, cancer.data, cancer.target)  print (f&#39;Linear Regression Cross Value Score : {score1.mean()}&#39;) print (f&#39;KNN Cross Value Score : {score2.mean()}&#39;) print (f&#39;SVM Cross Value Score : {score3.mean()}&#39;) print (f&#39;Decision Tree Cross Value Score : {score4.mean()}&#39;) print (f&#39;Random Forest Cross Value Score : {score5.mean()}&#39;)   data split해서 fitting  data의 편향을 줄이기 위함  lr = LinearRegression().fit(X_train, Y_train) knn = KNeighborsClassifier(n_neighbors=4).fit(X_train, Y_train) svm = LinearSVC(random_state=0).fit(X_train, Y_train) tree = DecisionTreeClassifier(max_depth=3, random_state=0).fit(X_train, Y_train) forest = RandomForestClassifier(n_estimators=6).fit(X_train, Y_train)   Accuracy  앞의 cross_val_score와 비교  print (f&#39;Linear Regression Accuracy : {lr.score(X_test, Y_test)}&#39;) print (f&#39;KNN Accuracy : {knn.score(X_test, Y_test)}&#39;) print (f&#39;SVM Accuracy : {svm.score(X_test, Y_test)}&#39;) print (f&#39;Decision Tree Accuracy : {tree.score(X_test, Y_test)}&#39;) print (f&#39;Random Forest Accuracy : {forest.score(X_test, Y_test)}&#39;)     ===  Data Scaling     Data Scaling   one of preprocessings   데이터 값이 너무 크거나 작은 경우 algorithm 학습이 0으로 수렴하거나 무한으로 발산해버릴 가능성 있기 때문   Scalers      1. Standard Scaler     mean = 0, Var = 1   2. Robust Scaler     median, quartile   3. MinMax Scaler     values of all features  : 0 ~ 1   4. Normalizer     위의 3 Scaler 와 달리 row 마다 정규화   Uclid 거리가 1이 되도록 data 조정   Spherical contour(구형 윤곽) : 좀더 빠르게 학습가능, 좋다는 의미가 아님   Fitting     fit : learn data   transform : scaling   Use dataset: Breast-Cancer  from sklearn.datasets import load_breast_cancer from sklearn.model_selection import train_test_split  cancer = load_breast_cancer()  X_train, X_test, y_train, y_test = train_test_split(cancer.data, cancer.target, stratify = cancer.target, random_state = 2020)   Standard Scaler  from sklearn.preprocessing import StandardScaler scaler = StandardScaler() X_train_scale = scaler.fit_transform(X_train)  print (f&quot;스케일 조정 전 features MIN Values : \n{X_train.min(axis = 0)}&quot;) print (f&quot;스케일 조정 전 features MAX Values : \n{X_train.max(axis = 0)}&quot;) print (f&quot;스케일 조정 후 features MIN Values : \n{X_train_scale.min(axis = 0)}&quot;) print (f&quot;스케일 조정 후 features MAX Values : \n{X_train_scale.max(axis = 0)}&quot;)   Robert Scaler  from sklearn.preprocessing import RobustScaler rs = RobustScaler() X_train_rs = rs.fit_transform(X_train)  print (f&quot;스케일 조정 전 features MIN Values : \n{X_train.min(axis = 0)}&quot;) print (f&quot;스케일 조정 전 features MAX Values : \n{X_train.max(axis = 0)}&quot;) print (f&quot;스케일 조정 후 features MIN Values : \n{X_train_rs.min(axis = 0)}&quot;) print (f&quot;스케일 조정 후 features MAX Values : \n{X_train_rs.max(axis = 0)}&quot;)   MinMax Scaler  from sklearn.preprocessing import MinMaxScaler mms = MinMaxScaler() X_train_mms = mms.fit_transform(X_train)  print (f&quot;스케일 조정 전 features MIN Values : \n{X_train.min(axis = 0)}&quot;) print (f&quot;스케일 조정 전 features MAX Values : \n{X_train.max(axis = 0)}&quot;) print (f&quot;스케일 조정 후 features MIN Values : \n{X_train_mms.min(axis = 0)}&quot;) print (f&quot;스케일 조정 후 features MAX Values : \n{X_train_mms.max(axis = 0)}&quot;)   Normalizer  from sklearn.preprocessing import Normalizer nor = Normalizer() X_train_nor = nor.fit_transform(X_train)  print (f&quot;스케일 조정 전 features MIN Values : \n{X_train.min(axis = 0)}&quot;) print (f&quot;스케일 조정 전 features MAX Values : \n{X_train.max(axis = 0)}&quot;) print (f&quot;스케일 조정 후 features MIN Values : \n{X_train_nor.min(axis = 0)}&quot;) print (f&quot;스케일 조정 후 features MAX Values : \n{X_train_nor.max(axis = 0)}&quot;)   analysis between before and after data Scaling using SVC     before data scaling   from sklearn.svm import SVC X_train, X_test, y_train, y_test = train_test_split(cancer.data, cancer.target, random_state = 2020)  svc = SVC() svc.fit(X_train, y_train)  svc.score(X_test, y_test)       # 0.5734265734265734      after data scaling   mms = MinMaxScaler()  X_train_mms = mms.fit_transform(X_train) X_test_mms = mms.transform(X_test)  svc.fit(X_train_mms, y_train)  svc.score(X_test_mms, y_test)   # 0.958041958041958   std = StandardScaler()  X_train_std = std.fit_transform(X_train) X_test_std = std.transform(X_test)  svc.fit(X_train_std, y_train) svc.score(X_test_std, y_test)   # 0.965034965034965   robu = RobustScaler()  X_train_robu = robu.fit_transform(X_train) X_test_robu = robu.transform(X_test)  svc.fit(X_train_robu, y_train) svc.score(X_test_robu, y_test)  # 0.986013986013986   norm = Normalizer()  X_train_norm = norm.fit_transform(X_train) X_test_norm = norm.transform(X_test)  svc.fit(X_train_norm, y_train) svc.score(X_test_norm, y_test)  # 0.5734265734265734      Deep Learning with Tensorflow (as tf) &amp; Keras     tensorflow 내부에 image classification model 등 각종 models of machine learning 공개   Inception3 : 일반적인 이미지 예측 model, 여기에 내가 개인적으로 갖고 있는 이미지들로 학습   처음부터 새로 model 만드는 것보다 inception3 등 기존 예측 models를 re-training 시켜서 사용하는 것만 잘해도 tf를 잘 활용할 수 있다   Data Flow Graph     tf 는 data flow graph 형태로 작동 : data flow에 관련된 graph를 잘 알아야 tf를 잘 쓸 수 있다   구성요소       Node : mathematical operations with tensors   Edge : flow way of tensor( multidimensional data array )   tensor(data)가 nodes를 지나면서 연산이 이루어짐, tensor가 graph상에서 이동(flow)해서 TensorFlow   Tensor     multidimensional data array : any value available            Rank : number of dimensions                    0 : scalar           1 : vector           2 : matrix           3 : 3-tensor           n : n-tensor                       Shape : number of elements in each dimensions                    ex) [[1,2,3,],[4,5,6,],[7,8,9,]].shape = [3,3]                       Type : data-type, 대부분 float32           Keras     원래 Tensorflow와는 별개의 library, TF 2.0로 버전업하면서 tf에 포함시킴   주요 특징     Modularity :            keras의 module들은 독립적, 설정가능, 가능한 최소한의 제약사항으로 서로 연결, models은 sequences or graphs로 구성한 것       특히 신경망층, 비용함수, 최적화기, 초기화기법, 활성화함수, 정규화기법 등 모두 독립적 modules, 새로운 model 만들기 위해 이러한 modules 조합 가능           Minimalism : 각 module은 짧고 간결, 모든 code는 한번 훑어보는 것으로도 이해 가능해야, 단 반복속도 및 혁신성은 다소 떨어질 수 있음   쉬운 확장성 : easy to add new classes or functions to modules, 고급연구에 필요한 다양한 표현 가능   Python based : 별도의 model 설정 필요없이 python codes로 정의 가능   기본 개념     Model : basic data structure            sequence model : 원하는 layers를 쉽게 순차적으로 쌓을 수 있음       다중 출력 등 좀더 복잡한 model 구성은 keras의 함수 API 사용           Deep Learning Model by Keras                                dataset 생성                            원본 data 불러오거나 simulation 통해 data 생성               훈련 set / 검증 set / 시험 set 생성               data transformatting : ex. images to array                                                                   model 구성                            sequence model 생성한 뒤(객체), 필요한 layer 추가하여 구성               좀 더 복잡한 model 필요 시 Keras 함수 API 사용                                                                   Model’s learning process 설정                            compile()               학습 전 학습에 대한 설정               손실 함수 및 최적화 방법 정의                                                                   learning process                            fit()               훈련 set 이용해 model로 학습                                                                   학습과정 살펴보기                            훈련 set - 검증 set의 손실 및 정확도 측정               반복 횟수에 따른 손실 및 정확도 추이를 보며 학습 상황 판단                                                                   Evalutate Model                            evaluate()               준비된 시험 set로 학습한 model 평가                                                                   use this model                            predict()               임의의 입력, get model’s output                                                   ML과의 차이점     ML은 모델 훈련만 - DL은 모델과 학습과정 설계 가능   ML은 학습 결과만 return - DL은 학습 과정 중간에 대한 check 가능   Sequential Model 맛보기  tensorflow.keras.layers     layers를 쌓아 만드는 model   multi-layer perceptron   from tensorflow.keras import layers  # 3개의 layers model = tf.keras.Sequential()  # 64개의 output units, 완전 연결 층 model.add(layers.Dense(64, activation = &#39;relu&#39;)) model.add(layers.Dense(64, activation = &#39;relu&#39;))  # 10개의 output units, Softmax 층 model.add(layers.Dense(10, activation = &#39;softmax&#39;))  ">


  <meta name="author" content="gitgitWi">


<meta property="og:type" content="article">
<meta property="og:locale" content="en_KR">
<meta property="og:site_name" content="gitgitWi's gitgit pages">
<meta property="og:title" content="[Python] ML Quick Review">
<meta property="og:url" content="https://gitgitwi.github.io/aidata/python/lec-ML_quick_review/">
<meta property="og:image" content="https://gitgitwi.github.io/assets/images/me/me.png">


  <meta property="og:description" content="연휴기간 (04/30~05/05) 과제     본인이 지원하고자하는 회사 3군데 조사   1.의 회사 관련 포트폴리오 주제 선정            06/01 ~ 06/14 : 최종 포트폴리오 준비 기간       06/15 : 프로젝트 발표       동시에 Java Spring 추가 학습 예정             1. Machine Learning  Basic Types     지도학습 (supervised learning)   비지도학습 (unsupervised learning)   두 학습 모두 컴퓨터가 인식 가능한 입력 데이터 필요 (0, 1)  고려사항     어떤 질문에 대한 답을 원하는가? 현재 데이터가 원하는 답을 줄 수 있는가?   내가 원하는 질문의 답에 대한 ML 기술/algorithm은 무엇?   충분한 학습용 데이터가 있는지?   현재 데이터의 특성, 좋은 예측을 만들수 있는지?   ML App.의 성과를 어떻게 측정할 수 있는지?   ML Solution이 다른 연구/제품과 어떻게 협력할 수 있는가?     2. Python Libraries related to ML     Scikit-learn   Numpy   Scipy : 희소행렬(sparse matrix)   Matplotlib : plots   Pandas : DataFrame, Series     3. Scikit-learn  KNN (k-nearest neighbors) Model  Iris dataset로 단순하게 구현해보기; KNN 관련 가장 간단한 dataset  dataset     학습 : 기출문제   훈련 : 모의고사   예측 : 실제 시험   지도 학습 및 훈련을 위한 dataset은 사람이 직접 만들어줘야 함 일반적으로 학습 : 훈련 = 7 : 3   Check Characteristics of data     data에 대한 사전 탐색 필수   web project의 경우 data-flow 중요   iris = load_iris() type(iris)                  # sklearn.utils.Bunch iris.keys() iris.target_names           # 품종명 iris.feature_names          # [&#39;sepal length (cm)&#39;, &#39;sepal width (cm)&#39;, &#39;petal length (cm)&#39;, &#39;petal width (cm)&#39;]                             # [꽃받침 길이, 꽃받침 폭, 꽃잎 길이, 꽃잎 폭] iris_dataset.data.shape     # (150, 4) : sample 150, attribution 4 iris.data[:10]              # ML에서 각 item은 &quot;sample&quot;이라하고, 속성은 &quot;특성&quot;이라 함 iris.target                 # results of labeling   이 dataset에 없는 새로운 data가 들어왔을때, 그 품종을 예측하는 ML Model을 만드는 것이 목적   Evaluate the ML Model     Model에 대한 성능 평가   Problems of Overfitting; not-normalized   -&gt; ML의 성능을 높이고 일반화하기 위해, 주어진 데이터를 train data - test data로 나눠야 함   sklearn.model_selection.train_test_split : Split data     train data, test data   관례) scikit-learn에서 data는 대문자 X, label은 소문자 y로 표기   수학 표기 방식을 따르되, data는 2차원 matrix이므로 대문자 X, target은 1차원 vector이므로 소문자 y 사용   데이터가 순서대로 나누어지지 않도록, random 하게 섞음   test set은 모든 class의 data를 포함하도록 잘 섞어야 함   from sklearn.model_selection import train_test_split X_train, X_test, y_train, y_test = train_test_split(iris_dataset.data, iris_dataset.target, test_size = 0.25, random_state = 2020)  print (X_train.shape, X_test.shape, y_train.shape, y_test.shape) print (X_train[:10], X_test[:10], y_train[:10], y_test[:10],)     Look into data  ML 없이도 풀수 있는 문제가 아닌지, 필요한 정보가 누락되어 있는지 data 조사  DataFrame, Scatter plot  iris_df = pd.DataFrame(X_train, columns=iris_dataset.feature_names) iris_df.head() iris_df.isnull().sum() pd.plotting.scatter_matrix(iris_df, c = y_train, figsize=(15,15), marker=&#39;o&#39;, hist_kwds={&#39;bins&#39; : 20}, s=60, alpha=.8)     Fitting (Machine Learning) by KNN Model  from sklearn.neighbors import KNeighborsClassifier knn = KNeighborsClassifier(n_neighbors = 3) knn.fit(X_train, Y_train)     KNN Model  K-nearset neighbors     train data 를 통해 model 만들고, 새로운 data 들어오면 가까운 훈련 data point를 찾아 분류   scikit-learn의 모든 ML model은 estimator라는 python class로 구현   KNN algorithm은 neighbors module 아래 KNeighborsClassifier class에 구현   parameters of KNN  KNeighborsClassifier(algorithm=&#39;auto&#39;,                      leaf_size=30,                      metric=&#39;minkowski&#39;,                      metric_params=None,                      n_jobs=None,                      n_neighbors=3,                      p=2,                      weights=&#39;uniform&#39;)     Predict about new data  n by 4 array  X_new = np.array([[3, 4.2, 0.8, 0.4]]) prediction = knn.predict(X_new) print (f&quot;Predict about X_new : {prediction}&quot;) print (f&quot;Name of the predicted one : {iris_dataset.target_names[prediction]}&quot;)  y_predict = knn.predict(X_test) y_predict == y_test     Evaluate Accuracy  print (f&quot;Accuracy of test set by &#39;mean&#39; : {np.mean(y_predict == y_test) * 100}&quot;) print (f&quot;Accuracy of test set by &#39;knn.score&#39; : {knn.score(X_test, y_test) * 100}&quot;)  from sklearn import metrics print (f&quot;Accuracy of test set by &#39;metrics.accuracy_score&#39; : {metrics.accuracy_score(y_test, y_predict) * 100}&quot;)   multiple ‘k’s  accuracy_set = [] k_set = [i for i in range(1,12,2)] print (k_set)  for k in k_set:     knn = KNeighborsClassifier(n_neighbors=k)     knn.fit(X_train, y_train)     y_predicts = knn.predict(X_test)     accuracy = metrics.accuracy_score(y_test, y_predicts)     accuracy_set.append(accuracy)  from pprint import pprint pprint(accuracy_set) print (max(accuracy_set))     kfold for Cross Validation       sklearn.model_selection.cross_val_score   train_test_split() 보다 성능이 좋은 평가방법   데이터를 k번 쪼개서 k번 검증   cross-val-score              dataset : sklearn.datasets.load_breast_cancer        type(cancer)   cancer.data[:10]   cancer.feature_names   cancer.target_names   cancer.target[:10]                test models            sklearn.linear_model.LinearRegression         LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None, normalize=False)                       sklearn.neighbors.KNeighborsClassifier               KNeighborsClassifier(algorithm=&#39;auto&#39;,                          leaf_size=30, metric=&#39;minkowski&#39;,                         metric_params=None,                         n_jobs=None,                          n_neighbors=4,                          p=2,                         weights=&#39;uniform&#39;)  `    sklearn.svm.LinearSVC     LinearSVC(C=1.0,              class_weight=None,              dual=True,              fit_intercept=True,              intercept_scaling=1,              loss=&#39;squared_hinge&#39;,              max_iter=1000,              multi_class=&#39;ovr&#39;,              penalty=&#39;l2&#39;,              random_state=0,              tol=0.0001,              verbose=0)           sklearn.tree.DecisionTreeClassifier     DecisionTreeClassifier(class_weight=None,                          criterion=&#39;gini&#39;,                          max_depth=3,                          max_features=None,                          max_leaf_nodes=None,                          min_impurity_decrease=0.0,                          min_impurity_split=None,                          min_samples_leaf=1,                          min_samples_split=2,                          min_weight_fraction_leaf=0.0,                          presort=False,                          random_state=0,                          splitter=&#39;best&#39;)           sklearn.ensemble.RandomForestClassifier     RandomForestClassifier(bootstrap=True,                          class_weight=None,                          criterion=&#39;gini&#39;,                         max_depth=None,                          max_features=&#39;auto&#39;,                          max_leaf_nodes=None,                         min_impurity_decrease=0.0,                          min_impurity_split=None,                          min_samples_leaf=1,                          min_samples_split=2,                          min_weight_fraction_leaf=0.0,                          n_estimators=6,                          n_jobs=None,                          oob_score=False,                          random_state=None,                          verbose=0,                          warm_start=False)           exec. Cross Value Score  score1 = cross_val_score( lr, cancer.data, cancer.target) score2 = cross_val_score( knn, cancer.data, cancer.target) score3 = cross_val_score( svm, cancer.data, cancer.target) score4 = cross_val_score( tree, cancer.data, cancer.target) score5 = cross_val_score( forest, cancer.data, cancer.target)  print (f&#39;Linear Regression Cross Value Score : {score1.mean()}&#39;) print (f&#39;KNN Cross Value Score : {score2.mean()}&#39;) print (f&#39;SVM Cross Value Score : {score3.mean()}&#39;) print (f&#39;Decision Tree Cross Value Score : {score4.mean()}&#39;) print (f&#39;Random Forest Cross Value Score : {score5.mean()}&#39;)   data split해서 fitting  data의 편향을 줄이기 위함  lr = LinearRegression().fit(X_train, Y_train) knn = KNeighborsClassifier(n_neighbors=4).fit(X_train, Y_train) svm = LinearSVC(random_state=0).fit(X_train, Y_train) tree = DecisionTreeClassifier(max_depth=3, random_state=0).fit(X_train, Y_train) forest = RandomForestClassifier(n_estimators=6).fit(X_train, Y_train)   Accuracy  앞의 cross_val_score와 비교  print (f&#39;Linear Regression Accuracy : {lr.score(X_test, Y_test)}&#39;) print (f&#39;KNN Accuracy : {knn.score(X_test, Y_test)}&#39;) print (f&#39;SVM Accuracy : {svm.score(X_test, Y_test)}&#39;) print (f&#39;Decision Tree Accuracy : {tree.score(X_test, Y_test)}&#39;) print (f&#39;Random Forest Accuracy : {forest.score(X_test, Y_test)}&#39;)     ===  Data Scaling     Data Scaling   one of preprocessings   데이터 값이 너무 크거나 작은 경우 algorithm 학습이 0으로 수렴하거나 무한으로 발산해버릴 가능성 있기 때문   Scalers      1. Standard Scaler     mean = 0, Var = 1   2. Robust Scaler     median, quartile   3. MinMax Scaler     values of all features  : 0 ~ 1   4. Normalizer     위의 3 Scaler 와 달리 row 마다 정규화   Uclid 거리가 1이 되도록 data 조정   Spherical contour(구형 윤곽) : 좀더 빠르게 학습가능, 좋다는 의미가 아님   Fitting     fit : learn data   transform : scaling   Use dataset: Breast-Cancer  from sklearn.datasets import load_breast_cancer from sklearn.model_selection import train_test_split  cancer = load_breast_cancer()  X_train, X_test, y_train, y_test = train_test_split(cancer.data, cancer.target, stratify = cancer.target, random_state = 2020)   Standard Scaler  from sklearn.preprocessing import StandardScaler scaler = StandardScaler() X_train_scale = scaler.fit_transform(X_train)  print (f&quot;스케일 조정 전 features MIN Values : \n{X_train.min(axis = 0)}&quot;) print (f&quot;스케일 조정 전 features MAX Values : \n{X_train.max(axis = 0)}&quot;) print (f&quot;스케일 조정 후 features MIN Values : \n{X_train_scale.min(axis = 0)}&quot;) print (f&quot;스케일 조정 후 features MAX Values : \n{X_train_scale.max(axis = 0)}&quot;)   Robert Scaler  from sklearn.preprocessing import RobustScaler rs = RobustScaler() X_train_rs = rs.fit_transform(X_train)  print (f&quot;스케일 조정 전 features MIN Values : \n{X_train.min(axis = 0)}&quot;) print (f&quot;스케일 조정 전 features MAX Values : \n{X_train.max(axis = 0)}&quot;) print (f&quot;스케일 조정 후 features MIN Values : \n{X_train_rs.min(axis = 0)}&quot;) print (f&quot;스케일 조정 후 features MAX Values : \n{X_train_rs.max(axis = 0)}&quot;)   MinMax Scaler  from sklearn.preprocessing import MinMaxScaler mms = MinMaxScaler() X_train_mms = mms.fit_transform(X_train)  print (f&quot;스케일 조정 전 features MIN Values : \n{X_train.min(axis = 0)}&quot;) print (f&quot;스케일 조정 전 features MAX Values : \n{X_train.max(axis = 0)}&quot;) print (f&quot;스케일 조정 후 features MIN Values : \n{X_train_mms.min(axis = 0)}&quot;) print (f&quot;스케일 조정 후 features MAX Values : \n{X_train_mms.max(axis = 0)}&quot;)   Normalizer  from sklearn.preprocessing import Normalizer nor = Normalizer() X_train_nor = nor.fit_transform(X_train)  print (f&quot;스케일 조정 전 features MIN Values : \n{X_train.min(axis = 0)}&quot;) print (f&quot;스케일 조정 전 features MAX Values : \n{X_train.max(axis = 0)}&quot;) print (f&quot;스케일 조정 후 features MIN Values : \n{X_train_nor.min(axis = 0)}&quot;) print (f&quot;스케일 조정 후 features MAX Values : \n{X_train_nor.max(axis = 0)}&quot;)   analysis between before and after data Scaling using SVC     before data scaling   from sklearn.svm import SVC X_train, X_test, y_train, y_test = train_test_split(cancer.data, cancer.target, random_state = 2020)  svc = SVC() svc.fit(X_train, y_train)  svc.score(X_test, y_test)       # 0.5734265734265734      after data scaling   mms = MinMaxScaler()  X_train_mms = mms.fit_transform(X_train) X_test_mms = mms.transform(X_test)  svc.fit(X_train_mms, y_train)  svc.score(X_test_mms, y_test)   # 0.958041958041958   std = StandardScaler()  X_train_std = std.fit_transform(X_train) X_test_std = std.transform(X_test)  svc.fit(X_train_std, y_train) svc.score(X_test_std, y_test)   # 0.965034965034965   robu = RobustScaler()  X_train_robu = robu.fit_transform(X_train) X_test_robu = robu.transform(X_test)  svc.fit(X_train_robu, y_train) svc.score(X_test_robu, y_test)  # 0.986013986013986   norm = Normalizer()  X_train_norm = norm.fit_transform(X_train) X_test_norm = norm.transform(X_test)  svc.fit(X_train_norm, y_train) svc.score(X_test_norm, y_test)  # 0.5734265734265734      Deep Learning with Tensorflow (as tf) &amp; Keras     tensorflow 내부에 image classification model 등 각종 models of machine learning 공개   Inception3 : 일반적인 이미지 예측 model, 여기에 내가 개인적으로 갖고 있는 이미지들로 학습   처음부터 새로 model 만드는 것보다 inception3 등 기존 예측 models를 re-training 시켜서 사용하는 것만 잘해도 tf를 잘 활용할 수 있다   Data Flow Graph     tf 는 data flow graph 형태로 작동 : data flow에 관련된 graph를 잘 알아야 tf를 잘 쓸 수 있다   구성요소       Node : mathematical operations with tensors   Edge : flow way of tensor( multidimensional data array )   tensor(data)가 nodes를 지나면서 연산이 이루어짐, tensor가 graph상에서 이동(flow)해서 TensorFlow   Tensor     multidimensional data array : any value available            Rank : number of dimensions                    0 : scalar           1 : vector           2 : matrix           3 : 3-tensor           n : n-tensor                       Shape : number of elements in each dimensions                    ex) [[1,2,3,],[4,5,6,],[7,8,9,]].shape = [3,3]                       Type : data-type, 대부분 float32           Keras     원래 Tensorflow와는 별개의 library, TF 2.0로 버전업하면서 tf에 포함시킴   주요 특징     Modularity :            keras의 module들은 독립적, 설정가능, 가능한 최소한의 제약사항으로 서로 연결, models은 sequences or graphs로 구성한 것       특히 신경망층, 비용함수, 최적화기, 초기화기법, 활성화함수, 정규화기법 등 모두 독립적 modules, 새로운 model 만들기 위해 이러한 modules 조합 가능           Minimalism : 각 module은 짧고 간결, 모든 code는 한번 훑어보는 것으로도 이해 가능해야, 단 반복속도 및 혁신성은 다소 떨어질 수 있음   쉬운 확장성 : easy to add new classes or functions to modules, 고급연구에 필요한 다양한 표현 가능   Python based : 별도의 model 설정 필요없이 python codes로 정의 가능   기본 개념     Model : basic data structure            sequence model : 원하는 layers를 쉽게 순차적으로 쌓을 수 있음       다중 출력 등 좀더 복잡한 model 구성은 keras의 함수 API 사용           Deep Learning Model by Keras                                dataset 생성                            원본 data 불러오거나 simulation 통해 data 생성               훈련 set / 검증 set / 시험 set 생성               data transformatting : ex. images to array                                                                   model 구성                            sequence model 생성한 뒤(객체), 필요한 layer 추가하여 구성               좀 더 복잡한 model 필요 시 Keras 함수 API 사용                                                                   Model’s learning process 설정                            compile()               학습 전 학습에 대한 설정               손실 함수 및 최적화 방법 정의                                                                   learning process                            fit()               훈련 set 이용해 model로 학습                                                                   학습과정 살펴보기                            훈련 set - 검증 set의 손실 및 정확도 측정               반복 횟수에 따른 손실 및 정확도 추이를 보며 학습 상황 판단                                                                   Evalutate Model                            evaluate()               준비된 시험 set로 학습한 model 평가                                                                   use this model                            predict()               임의의 입력, get model’s output                                                   ML과의 차이점     ML은 모델 훈련만 - DL은 모델과 학습과정 설계 가능   ML은 학습 결과만 return - DL은 학습 과정 중간에 대한 check 가능   Sequential Model 맛보기  tensorflow.keras.layers     layers를 쌓아 만드는 model   multi-layer perceptron   from tensorflow.keras import layers  # 3개의 layers model = tf.keras.Sequential()  # 64개의 output units, 완전 연결 층 model.add(layers.Dense(64, activation = &#39;relu&#39;)) model.add(layers.Dense(64, activation = &#39;relu&#39;))  # 10개의 output units, Softmax 층 model.add(layers.Dense(10, activation = &#39;softmax&#39;))  ">







  <meta property="article:published_time" content="2020-04-27T00:00:00+09:00">





  

  


<link rel="canonical" href="/aidata/python/lec-ML_quick_review/">




<script type="application/ld+json">
  {
    "@context": "https://schema.org",
    
      "@type": "Person",
      "name": "gitgitWi",
      "url": "https://gitgitwi.github.io/"
    
  }
</script>


  <meta name="google-site-verification" content="OiLW2mngNdN99bgruXQu7hREiSsX2Afh0mK30ResEzE" />





<!-- end _includes/seo.html -->


<link href="/feed.xml" type="application/atom+xml" rel="alternate" title="gitgitWi's gitgit pages Feed">


<script data-ad-client="ca-pub-6707632410688562" async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>

<!-- https://t.co/dKP3o1e -->
<meta name="viewport" content="width=device-width, initial-scale=1.0">

<script>
  document.documentElement.className = document.documentElement.className.replace(/\bno-js\b/g, '') + ' js ';
</script>

<!-- For all browsers -->
<link rel="stylesheet" href="/assets/css/main.css">

<!--[if IE]>
  <style>
    /* old IE unsupported flexbox fixes */
    .greedy-nav .site-title {
      padding-right: 3em;
    }
    .greedy-nav button {
      position: absolute;
      top: 0;
      right: 0;
      height: 100%;
    }
  </style>
<![endif]-->



  </head>

  <body class="layout--single">
    <nav class="skip-links">
  <h2 class="screen-reader-text">Skip links</h2>
  <ul>
    <li><a href="#site-nav" class="screen-reader-shortcut">Skip to primary navigation</a></li>
    <li><a href="#main" class="screen-reader-shortcut">Skip to content</a></li>
    <li><a href="#footer" class="screen-reader-shortcut">Skip to footer</a></li>
  </ul>
</nav>

    <!--[if lt IE 9]>
<div class="notice--danger align-center" style="margin: 0;">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience.</div>
<![endif]-->

    

<div class="masthead">
  <div class="masthead__inner-wrap">
    <div class="masthead__menu">
      <nav id="site-nav" class="greedy-nav">
        
        <a class="site-title" href="/">
          gitgitWi
          
        </a>
        <ul class="visible-links"><li class="masthead__menu-item">
              <a href="/about/">About</a>
            </li><li class="masthead__menu-item">
              <a href="/categories/Aidata/">AI+BigData</a>
            </li><li class="masthead__menu-item">
              <a href="/categories/Cloud/">Docker+Cloud</a>
            </li><li class="masthead__menu-item">
              <a href="/categories/fundamentals/">Fundamentals</a>
            </li><li class="masthead__menu-item">
              <a href="/categories/Career/">취준기</a>
            </li><li class="masthead__menu-item">
              <a href="/categories/Scrabs/">Scrabs</a>
            </li><li class="masthead__menu-item">
              <a href="/categories/">Category</a>
            </li></ul>
        
        <button class="search__toggle" type="button">
          <span class="visually-hidden">Toggle search</span>
          <svg class="icon" width="16" height="16" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 15.99 16">
            <path d="M15.5,13.12L13.19,10.8a1.69,1.69,0,0,0-1.28-.55l-0.06-.06A6.5,6.5,0,0,0,5.77,0,6.5,6.5,0,0,0,2.46,11.59a6.47,6.47,0,0,0,7.74.26l0.05,0.05a1.65,1.65,0,0,0,.5,1.24l2.38,2.38A1.68,1.68,0,0,0,15.5,13.12ZM6.4,2A4.41,4.41,0,1,1,2,6.4,4.43,4.43,0,0,1,6.4,2Z" transform="translate(-.01)"></path>
          </svg>
        </button>
        
        <button class="greedy-nav__toggle hidden" type="button">
          <span class="visually-hidden">Toggle menu</span>
          <div class="navicon"></div>
        </button>
        <ul class="hidden-links hidden"></ul>
      </nav>
    </div>
  </div>
</div>


    <div class="initial-content">
      



<div id="main" role="main">
  
  <div class="sidebar sticky">
  


<div itemscope itemtype="https://schema.org/Person">

  
    <div class="author__avatar">
      
        <img src="/assets/images/me/me.png" alt="gitgitWi" itemprop="image">
      
    </div>
  

  <div class="author__content">
    
      <h3 class="author__name" itemprop="name">gitgitWi</h3>
    
    
      <div class="author__bio" itemprop="description">
        <p>코딩 보다 어려운 인스톨</p>

      </div>
    
  </div>

  <div class="author__urls-wrapper">
    <button class="btn btn--inverse">Follow</button>
    <ul class="author__urls social-icons">
      
        <li itemprop="homeLocation" itemscope itemtype="https://schema.org/Place">
          <i class="fas fa-fw fa-map-marker-alt" aria-hidden="true"></i> <span itemprop="name">Seoul/S.Korea</span>
        </li>
      

      
        
          
            <li><a href="https://gitgitwi.github.io/" rel="nofollow noopener noreferrer"><i class="fas fa-fw fa-link" aria-hidden="true"></i><span class="label">HOME</span></a></li>
          
        
          
            <li><a href="https://github.com/gitgitWi" rel="nofollow noopener noreferrer"><i class="fab fa-fw fa-github" aria-hidden="true"></i><span class="label">GitHub</span></a></li>
          
        
          
            <li><a href="mailto:gitgitwi@gmail.com" rel="nofollow noopener noreferrer"><i class="fas fa-fw fa-envelope-square" aria-hidden="true"></i><span class="label">Email</span></a></li>
          
        
      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      <!--
  <li>
    <a href="http://link-to-whatever-social-network.com/user/" itemprop="sameAs" rel="nofollow noopener noreferrer">
      <i class="fas fa-fw" aria-hidden="true"></i> Custom Social Profile Link
    </a>
  </li>
-->
    </ul>
  </div>
</div>

  
  </div>



  <article class="page" itemscope itemtype="https://schema.org/CreativeWork">
    <meta itemprop="headline" content="[Python] ML Quick Review">
    <meta itemprop="description" content="연휴기간 (04/30~05/05) 과제  본인이 지원하고자하는 회사 3군데 조사  1.의 회사 관련 포트폴리오 주제 선정          06/01 ~ 06/14 : 최종 포트폴리오 준비 기간      06/15 : 프로젝트 발표      동시에 Java Spring 추가 학습 예정      1. Machine LearningBasic Types  지도학습 (supervised learning)  비지도학습 (unsupervised learning)두 학습 모두 컴퓨터가 인식 가능한 입력 데이터 필요 (0, 1)고려사항  어떤 질문에 대한 답을 원하는가? 현재 데이터가 원하는 답을 줄 수 있는가?  내가 원하는 질문의 답에 대한 ML 기술/algorithm은 무엇?  충분한 학습용 데이터가 있는지?  현재 데이터의 특성, 좋은 예측을 만들수 있는지?  ML App.의 성과를 어떻게 측정할 수 있는지?  ML Solution이 다른 연구/제품과 어떻게 협력할 수 있는가?2. Python Libraries related to ML  Scikit-learn  Numpy  Scipy : 희소행렬(sparse matrix)  Matplotlib : plots  Pandas : DataFrame, Series3. Scikit-learnKNN (k-nearest neighbors) ModelIris dataset로 단순하게 구현해보기; KNN 관련 가장 간단한 datasetdataset  학습 : 기출문제  훈련 : 모의고사  예측 : 실제 시험지도 학습 및 훈련을 위한 dataset은 사람이 직접 만들어줘야 함일반적으로 학습 : 훈련 = 7 : 3Check Characteristics of data  data에 대한 사전 탐색 필수  web project의 경우 data-flow 중요iris = load_iris()type(iris)                  # sklearn.utils.Bunchiris.keys()iris.target_names           # 품종명iris.feature_names          # [&#39;sepal length (cm)&#39;, &#39;sepal width (cm)&#39;, &#39;petal length (cm)&#39;, &#39;petal width (cm)&#39;]                            # [꽃받침 길이, 꽃받침 폭, 꽃잎 길이, 꽃잎 폭]iris_dataset.data.shape     # (150, 4) : sample 150, attribution 4iris.data[:10]              # ML에서 각 item은 &quot;sample&quot;이라하고, 속성은 &quot;특성&quot;이라 함iris.target                 # results of labeling이 dataset에 없는 새로운 data가 들어왔을때, 그 품종을 예측하는 ML Model을 만드는 것이 목적Evaluate the ML Model  Model에 대한 성능 평가  Problems of Overfitting; not-normalized-&gt; ML의 성능을 높이고 일반화하기 위해, 주어진 데이터를 train data - test data로 나눠야 함sklearn.model_selection.train_test_split : Split data  train data, test data  관례) scikit-learn에서 data는 대문자 X, label은 소문자 y로 표기  수학 표기 방식을 따르되, data는 2차원 matrix이므로 대문자 X, target은 1차원 vector이므로 소문자 y 사용  데이터가 순서대로 나누어지지 않도록, random 하게 섞음  test set은 모든 class의 data를 포함하도록 잘 섞어야 함from sklearn.model_selection import train_test_splitX_train, X_test, y_train, y_test = train_test_split(iris_dataset.data, iris_dataset.target, test_size = 0.25, random_state = 2020)print (X_train.shape, X_test.shape, y_train.shape, y_test.shape)print (X_train[:10], X_test[:10], y_train[:10], y_test[:10],)Look into dataML 없이도 풀수 있는 문제가 아닌지, 필요한 정보가 누락되어 있는지 data 조사DataFrame, Scatter plotiris_df = pd.DataFrame(X_train, columns=iris_dataset.feature_names)iris_df.head()iris_df.isnull().sum()pd.plotting.scatter_matrix(iris_df, c = y_train, figsize=(15,15), marker=&#39;o&#39;, hist_kwds={&#39;bins&#39; : 20}, s=60, alpha=.8)Fitting (Machine Learning) by KNN Modelfrom sklearn.neighbors import KNeighborsClassifierknn = KNeighborsClassifier(n_neighbors = 3)knn.fit(X_train, Y_train)KNN ModelK-nearset neighbors  train data 를 통해 model 만들고, 새로운 data 들어오면 가까운 훈련 data point를 찾아 분류  scikit-learn의 모든 ML model은 estimator라는 python class로 구현  KNN algorithm은 neighbors module 아래 KNeighborsClassifier class에 구현parameters of KNNKNeighborsClassifier(algorithm=&#39;auto&#39;,                     leaf_size=30,                     metric=&#39;minkowski&#39;,                     metric_params=None,                     n_jobs=None,                     n_neighbors=3,                     p=2,                     weights=&#39;uniform&#39;)Predict about new datan by 4 arrayX_new = np.array([[3, 4.2, 0.8, 0.4]])prediction = knn.predict(X_new)print (f&quot;Predict about X_new : {prediction}&quot;)print (f&quot;Name of the predicted one : {iris_dataset.target_names[prediction]}&quot;)y_predict = knn.predict(X_test)y_predict == y_testEvaluate Accuracyprint (f&quot;Accuracy of test set by &#39;mean&#39; : {np.mean(y_predict == y_test) * 100}&quot;)print (f&quot;Accuracy of test set by &#39;knn.score&#39; : {knn.score(X_test, y_test) * 100}&quot;)from sklearn import metricsprint (f&quot;Accuracy of test set by &#39;metrics.accuracy_score&#39; : {metrics.accuracy_score(y_test, y_predict) * 100}&quot;)multiple ‘k’saccuracy_set = []k_set = [i for i in range(1,12,2)]print (k_set)for k in k_set:    knn = KNeighborsClassifier(n_neighbors=k)    knn.fit(X_train, y_train)    y_predicts = knn.predict(X_test)    accuracy = metrics.accuracy_score(y_test, y_predicts)    accuracy_set.append(accuracy)from pprint import pprintpprint(accuracy_set)print (max(accuracy_set))kfold for Cross Validation  sklearn.model_selection.cross_val_score  train_test_split() 보다 성능이 좋은 평가방법  데이터를 k번 쪼개서 k번 검증cross-val-score      dataset : sklearn.datasets.load_breast_cancer      type(cancer)  cancer.data[:10]  cancer.feature_names  cancer.target_names  cancer.target[:10]            test models          sklearn.linear_model.LinearRegression        LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None, normalize=False)                    sklearn.neighbors.KNeighborsClassifier          KNeighborsClassifier(algorithm=&#39;auto&#39;,                         leaf_size=30, metric=&#39;minkowski&#39;,                        metric_params=None,                        n_jobs=None,                         n_neighbors=4,                         p=2,                        weights=&#39;uniform&#39;)`  sklearn.svm.LinearSVC    LinearSVC(C=1.0,             class_weight=None,             dual=True,             fit_intercept=True,             intercept_scaling=1,             loss=&#39;squared_hinge&#39;,             max_iter=1000,             multi_class=&#39;ovr&#39;,             penalty=&#39;l2&#39;,             random_state=0,             tol=0.0001,             verbose=0)        sklearn.tree.DecisionTreeClassifier    DecisionTreeClassifier(class_weight=None,                         criterion=&#39;gini&#39;,                         max_depth=3,                         max_features=None,                         max_leaf_nodes=None,                         min_impurity_decrease=0.0,                         min_impurity_split=None,                         min_samples_leaf=1,                         min_samples_split=2,                         min_weight_fraction_leaf=0.0,                         presort=False,                         random_state=0,                         splitter=&#39;best&#39;)        sklearn.ensemble.RandomForestClassifier    RandomForestClassifier(bootstrap=True,                         class_weight=None,                         criterion=&#39;gini&#39;,                        max_depth=None,                         max_features=&#39;auto&#39;,                         max_leaf_nodes=None,                        min_impurity_decrease=0.0,                         min_impurity_split=None,                         min_samples_leaf=1,                         min_samples_split=2,                         min_weight_fraction_leaf=0.0,                         n_estimators=6,                         n_jobs=None,                         oob_score=False,                         random_state=None,                         verbose=0,                         warm_start=False)      exec. Cross Value Scorescore1 = cross_val_score( lr, cancer.data, cancer.target)score2 = cross_val_score( knn, cancer.data, cancer.target)score3 = cross_val_score( svm, cancer.data, cancer.target)score4 = cross_val_score( tree, cancer.data, cancer.target)score5 = cross_val_score( forest, cancer.data, cancer.target)print (f&#39;Linear Regression Cross Value Score : {score1.mean()}&#39;)print (f&#39;KNN Cross Value Score : {score2.mean()}&#39;)print (f&#39;SVM Cross Value Score : {score3.mean()}&#39;)print (f&#39;Decision Tree Cross Value Score : {score4.mean()}&#39;)print (f&#39;Random Forest Cross Value Score : {score5.mean()}&#39;)data split해서 fittingdata의 편향을 줄이기 위함lr = LinearRegression().fit(X_train, Y_train)knn = KNeighborsClassifier(n_neighbors=4).fit(X_train, Y_train)svm = LinearSVC(random_state=0).fit(X_train, Y_train)tree = DecisionTreeClassifier(max_depth=3, random_state=0).fit(X_train, Y_train)forest = RandomForestClassifier(n_estimators=6).fit(X_train, Y_train)Accuracy앞의 cross_val_score와 비교print (f&#39;Linear Regression Accuracy : {lr.score(X_test, Y_test)}&#39;)print (f&#39;KNN Accuracy : {knn.score(X_test, Y_test)}&#39;)print (f&#39;SVM Accuracy : {svm.score(X_test, Y_test)}&#39;)print (f&#39;Decision Tree Accuracy : {tree.score(X_test, Y_test)}&#39;)print (f&#39;Random Forest Accuracy : {forest.score(X_test, Y_test)}&#39;)===Data Scaling  Data Scaling  one of preprocessings  데이터 값이 너무 크거나 작은 경우 algorithm 학습이 0으로 수렴하거나 무한으로 발산해버릴 가능성 있기 때문Scalers1. Standard Scaler  mean = 0, Var = 12. Robust Scaler  median, quartile3. MinMax Scaler  values of all features  : 0 ~ 14. Normalizer  위의 3 Scaler 와 달리 row 마다 정규화  Uclid 거리가 1이 되도록 data 조정  Spherical contour(구형 윤곽) : 좀더 빠르게 학습가능, 좋다는 의미가 아님Fitting  fit : learn data  transform : scalingUse dataset: Breast-Cancerfrom sklearn.datasets import load_breast_cancerfrom sklearn.model_selection import train_test_splitcancer = load_breast_cancer()X_train, X_test, y_train, y_test = train_test_split(cancer.data, cancer.target, stratify = cancer.target, random_state = 2020)Standard Scalerfrom sklearn.preprocessing import StandardScalerscaler = StandardScaler()X_train_scale = scaler.fit_transform(X_train)print (f&quot;스케일 조정 전 features MIN Values : \n{X_train.min(axis = 0)}&quot;)print (f&quot;스케일 조정 전 features MAX Values : \n{X_train.max(axis = 0)}&quot;)print (f&quot;스케일 조정 후 features MIN Values : \n{X_train_scale.min(axis = 0)}&quot;)print (f&quot;스케일 조정 후 features MAX Values : \n{X_train_scale.max(axis = 0)}&quot;)Robert Scalerfrom sklearn.preprocessing import RobustScalerrs = RobustScaler()X_train_rs = rs.fit_transform(X_train)print (f&quot;스케일 조정 전 features MIN Values : \n{X_train.min(axis = 0)}&quot;)print (f&quot;스케일 조정 전 features MAX Values : \n{X_train.max(axis = 0)}&quot;)print (f&quot;스케일 조정 후 features MIN Values : \n{X_train_rs.min(axis = 0)}&quot;)print (f&quot;스케일 조정 후 features MAX Values : \n{X_train_rs.max(axis = 0)}&quot;)MinMax Scalerfrom sklearn.preprocessing import MinMaxScalermms = MinMaxScaler()X_train_mms = mms.fit_transform(X_train)print (f&quot;스케일 조정 전 features MIN Values : \n{X_train.min(axis = 0)}&quot;)print (f&quot;스케일 조정 전 features MAX Values : \n{X_train.max(axis = 0)}&quot;)print (f&quot;스케일 조정 후 features MIN Values : \n{X_train_mms.min(axis = 0)}&quot;)print (f&quot;스케일 조정 후 features MAX Values : \n{X_train_mms.max(axis = 0)}&quot;)Normalizerfrom sklearn.preprocessing import Normalizernor = Normalizer()X_train_nor = nor.fit_transform(X_train)print (f&quot;스케일 조정 전 features MIN Values : \n{X_train.min(axis = 0)}&quot;)print (f&quot;스케일 조정 전 features MAX Values : \n{X_train.max(axis = 0)}&quot;)print (f&quot;스케일 조정 후 features MIN Values : \n{X_train_nor.min(axis = 0)}&quot;)print (f&quot;스케일 조정 후 features MAX Values : \n{X_train_nor.max(axis = 0)}&quot;)analysis between before and after data Scaling using SVC  before data scalingfrom sklearn.svm import SVCX_train, X_test, y_train, y_test = train_test_split(cancer.data, cancer.target, random_state = 2020)svc = SVC()svc.fit(X_train, y_train)svc.score(X_test, y_test)       # 0.5734265734265734  after data scalingmms = MinMaxScaler()X_train_mms = mms.fit_transform(X_train)X_test_mms = mms.transform(X_test)svc.fit(X_train_mms, y_train)svc.score(X_test_mms, y_test)   # 0.958041958041958std = StandardScaler()X_train_std = std.fit_transform(X_train)X_test_std = std.transform(X_test)svc.fit(X_train_std, y_train)svc.score(X_test_std, y_test)   # 0.965034965034965robu = RobustScaler()X_train_robu = robu.fit_transform(X_train)X_test_robu = robu.transform(X_test)svc.fit(X_train_robu, y_train)svc.score(X_test_robu, y_test)  # 0.986013986013986norm = Normalizer()X_train_norm = norm.fit_transform(X_train)X_test_norm = norm.transform(X_test)svc.fit(X_train_norm, y_train)svc.score(X_test_norm, y_test)  # 0.5734265734265734Deep Learning with Tensorflow (as tf) &amp; Keras  tensorflow 내부에 image classification model 등 각종 models of machine learning 공개  Inception3 : 일반적인 이미지 예측 model, 여기에 내가 개인적으로 갖고 있는 이미지들로 학습  처음부터 새로 model 만드는 것보다 inception3 등 기존 예측 models를 re-training 시켜서 사용하는 것만 잘해도 tf를 잘 활용할 수 있다Data Flow Graph  tf 는 data flow graph 형태로 작동 : data flow에 관련된 graph를 잘 알아야 tf를 잘 쓸 수 있다구성요소  Node : mathematical operations with tensors  Edge : flow way of tensor( multidimensional data array )  tensor(data)가 nodes를 지나면서 연산이 이루어짐, tensor가 graph상에서 이동(flow)해서 TensorFlowTensor  multidimensional data array : any value available          Rank : number of dimensions                  0 : scalar          1 : vector          2 : matrix          3 : 3-tensor          n : n-tensor                    Shape : number of elements in each dimensions                  ex) [[1,2,3,],[4,5,6,],[7,8,9,]].shape = [3,3]                    Type : data-type, 대부분 float32      Keras  원래 Tensorflow와는 별개의 library, TF 2.0로 버전업하면서 tf에 포함시킴주요 특징  Modularity :          keras의 module들은 독립적, 설정가능, 가능한 최소한의 제약사항으로 서로 연결, models은 sequences or graphs로 구성한 것      특히 신경망층, 비용함수, 최적화기, 초기화기법, 활성화함수, 정규화기법 등 모두 독립적 modules, 새로운 model 만들기 위해 이러한 modules 조합 가능        Minimalism : 각 module은 짧고 간결, 모든 code는 한번 훑어보는 것으로도 이해 가능해야, 단 반복속도 및 혁신성은 다소 떨어질 수 있음  쉬운 확장성 : easy to add new classes or functions to modules, 고급연구에 필요한 다양한 표현 가능  Python based : 별도의 model 설정 필요없이 python codes로 정의 가능기본 개념  Model : basic data structure          sequence model : 원하는 layers를 쉽게 순차적으로 쌓을 수 있음      다중 출력 등 좀더 복잡한 model 구성은 keras의 함수 API 사용        Deep Learning Model by Keras                            dataset 생성                          원본 data 불러오거나 simulation 통해 data 생성              훈련 set / 검증 set / 시험 set 생성              data transformatting : ex. images to array                                                            model 구성                          sequence model 생성한 뒤(객체), 필요한 layer 추가하여 구성              좀 더 복잡한 model 필요 시 Keras 함수 API 사용                                                            Model’s learning process 설정                          compile()              학습 전 학습에 대한 설정              손실 함수 및 최적화 방법 정의                                                            learning process                          fit()              훈련 set 이용해 model로 학습                                                            학습과정 살펴보기                          훈련 set - 검증 set의 손실 및 정확도 측정              반복 횟수에 따른 손실 및 정확도 추이를 보며 학습 상황 판단                                                            Evalutate Model                          evaluate()              준비된 시험 set로 학습한 model 평가                                                            use this model                          predict()              임의의 입력, get model’s output                                          ML과의 차이점  ML은 모델 훈련만 - DL은 모델과 학습과정 설계 가능  ML은 학습 결과만 return - DL은 학습 과정 중간에 대한 check 가능Sequential Model 맛보기tensorflow.keras.layers  layers를 쌓아 만드는 model  multi-layer perceptronfrom tensorflow.keras import layers# 3개의 layersmodel = tf.keras.Sequential()# 64개의 output units, 완전 연결 층model.add(layers.Dense(64, activation = &#39;relu&#39;))model.add(layers.Dense(64, activation = &#39;relu&#39;))# 10개의 output units, Softmax 층model.add(layers.Dense(10, activation = &#39;softmax&#39;))">
    <meta itemprop="datePublished" content="2020-04-27T00:00:00+09:00">
    

    <div class="page__inner-wrap">
      
        <header>
          <h1 id="page-title" class="page__title" itemprop="headline">[Python] ML Quick Review
</h1>
          <!-- 
            <p class="page__meta"><i class="far fa-clock" aria-hidden="true"></i> 




  8 minute read

</p> -->
          
          <p class="page__date"><i class="fas fa-fw fa-calendar-alt" aria-hidden="true"></i> Updated: <time datetime="2020-04-27T00:00:00+09:00">April 27, 2020</time></p>
          
          
        </header>
      

      <section class="page__content" itemprop="text">
        
          <aside class="sidebar__right sticky">
            <nav class="toc">
              <header><h4 class="nav__title"><i class="fas fa-file-alt"></i> ML Quick Review</h4></header>
              <ul class="toc__menu">
  <li><a href="#1-machine-learning">1. Machine Learning</a>
    <ul>
      <li><a href="#basic-types">Basic Types</a></li>
      <li><a href="#고려사항">고려사항</a></li>
    </ul>
  </li>
  <li><a href="#2-python-libraries-related-to-ml">2. Python Libraries related to ML</a></li>
  <li><a href="#3-scikit-learn">3. Scikit-learn</a>
    <ul>
      <li><a href="#knn-k-nearest-neighbors-model">KNN (k-nearest neighbors) Model</a>
        <ul>
          <li><a href="#dataset">dataset</a></li>
          <li><a href="#check-characteristics-of-data">Check Characteristics of data</a></li>
          <li><a href="#evaluate-the-ml-model">Evaluate the ML Model</a></li>
          <li><a href="#sklearnmodel_selectiontrain_test_split--split-data">sklearn.model_selection.train_test_split : Split data</a></li>
          <li><a href="#look-into-data">Look into data</a>
            <ul>
              <li><a href="#dataframe-scatter-plot">DataFrame, Scatter plot</a></li>
            </ul>
          </li>
          <li><a href="#fitting-machine-learning-by-knn-model">Fitting (Machine Learning) by KNN Model</a>
            <ul>
              <li><a href="#knn-model">KNN Model</a></li>
              <li><a href="#parameters-of-knn">parameters of KNN</a></li>
            </ul>
          </li>
          <li><a href="#predict-about-new-data">Predict about new data</a></li>
          <li><a href="#evaluate-accuracy">Evaluate Accuracy</a></li>
        </ul>
      </li>
      <li><a href="#"></a>
        <ul>
          <li><a href="#kfold-for-cross-validation">kfold for Cross Validation</a>
            <ul>
              <li><a href="#cross-val-score">cross-val-score</a></li>
              <li><a href="#exec-cross-value-score">exec. Cross Value Score</a></li>
              <li><a href="#data-split해서-fitting">data split해서 fitting</a></li>
              <li><a href="#accuracy">Accuracy</a></li>
            </ul>
          </li>
        </ul>
      </li>
      <li><a href="#data-scaling">Data Scaling</a>
        <ul>
          <li><a href="#scalers">Scalers</a>
            <ul>
              <li><a href="#1-standard-scaler">1. Standard Scaler</a></li>
              <li><a href="#2-robust-scaler">2. Robust Scaler</a></li>
              <li><a href="#3-minmax-scaler">3. MinMax Scaler</a></li>
              <li><a href="#4-normalizer">4. Normalizer</a></li>
            </ul>
          </li>
        </ul>
      </li>
      <li><a href="#fitting">Fitting</a></li>
      <li><a href="#use-dataset-breast-cancer">Use dataset: Breast-Cancer</a></li>
      <li><a href="#standard-scaler">Standard Scaler</a></li>
      <li><a href="#robert-scaler">Robert Scaler</a></li>
      <li><a href="#minmax-scaler">MinMax Scaler</a></li>
      <li><a href="#normalizer">Normalizer</a>
        <ul>
          <li><a href="#analysis-between-before-and-after-data-scaling-using-svc">analysis between before and after data Scaling using SVC</a></li>
        </ul>
      </li>
    </ul>
  </li>
  <li><a href="#deep-learning-with-tensorflow-as-tf--keras">Deep Learning with Tensorflow (as tf) &amp; Keras</a>
    <ul>
      <li><a href="#data-flow-graph">Data Flow Graph</a>
        <ul>
          <li><a href="#구성요소">구성요소</a></li>
          <li><a href="#tensor">Tensor</a></li>
        </ul>
      </li>
      <li><a href="#keras">Keras</a>
        <ul>
          <li><a href="#주요-특징">주요 특징</a></li>
          <li><a href="#기본-개념">기본 개념</a></li>
          <li><a href="#ml과의-차이점">ML과의 차이점</a></li>
          <li><a href="#sequential-model-맛보기">Sequential Model 맛보기</a></li>
        </ul>
      </li>
    </ul>
  </li>
</ul>

            </nav>
          </aside>
        
        <p><strong><em>연휴기간 (04/30~05/05) 과제</em></strong></p>

<ol>
  <li>본인이 지원하고자하는 회사 3군데 조사</li>
  <li>1.의 회사 관련 포트폴리오 주제 선정
    <ul>
      <li>06/01 ~ 06/14 : 최종 포트폴리오 준비 기간</li>
      <li>06/15 : 프로젝트 발표</li>
      <li>동시에 Java Spring 추가 학습 예정</li>
    </ul>
  </li>
</ol>

<p><br /><br /></p>

<h1 id="1-machine-learning">1. Machine Learning</h1>

<h2 id="basic-types">Basic Types</h2>

<ul>
  <li>지도학습 (supervised learning)</li>
  <li>비지도학습 (unsupervised learning)</li>
</ul>

<p>두 학습 모두 컴퓨터가 인식 가능한 입력 데이터 필요 (0, 1)</p>

<h2 id="고려사항">고려사항</h2>

<ul>
  <li>어떤 질문에 대한 답을 원하는가? 현재 데이터가 원하는 답을 줄 수 있는가?</li>
  <li>내가 원하는 질문의 답에 대한 ML 기술/algorithm은 무엇?</li>
  <li>충분한 학습용 데이터가 있는지?</li>
  <li>현재 데이터의 특성, 좋은 예측을 만들수 있는지?</li>
  <li>ML App.의 성과를 어떻게 측정할 수 있는지?</li>
  <li>ML Solution이 다른 연구/제품과 어떻게 협력할 수 있는가?</li>
</ul>

<p><br /><br /></p>

<h1 id="2-python-libraries-related-to-ml">2. Python Libraries related to ML</h1>

<ul>
  <li>Scikit-learn</li>
  <li>Numpy</li>
  <li>Scipy : 희소행렬(sparse matrix)</li>
  <li>Matplotlib : plots</li>
  <li>Pandas : DataFrame, Series</li>
</ul>

<p><br /><br /></p>

<h1 id="3-scikit-learn">3. Scikit-learn</h1>

<h2 id="knn-k-nearest-neighbors-model">KNN (k-nearest neighbors) Model</h2>

<p>Iris dataset로 단순하게 구현해보기; KNN 관련 가장 간단한 dataset</p>

<h3 id="dataset">dataset</h3>

<ul>
  <li>학습 : 기출문제</li>
  <li>훈련 : 모의고사</li>
  <li>예측 : 실제 시험</li>
</ul>

<p>지도 학습 및 훈련을 위한 dataset은 사람이 직접 만들어줘야 함<br />
일반적으로 학습 : 훈련 = 7 : 3<br />
<br /></p>

<h3 id="check-characteristics-of-data">Check Characteristics of data</h3>

<ul>
  <li>data에 대한 사전 탐색 필수</li>
  <li>web project의 경우 data-flow 중요</li>
</ul>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">iris</span> <span class="o">=</span> <span class="n">load_iris</span><span class="p">()</span>
<span class="nb">type</span><span class="p">(</span><span class="n">iris</span><span class="p">)</span>                  <span class="c1"># sklearn.utils.Bunch
</span><span class="n">iris</span><span class="o">.</span><span class="n">keys</span><span class="p">()</span>
<span class="n">iris</span><span class="o">.</span><span class="n">target_names</span>           <span class="c1"># 품종명
</span><span class="n">iris</span><span class="o">.</span><span class="n">feature_names</span>          <span class="c1"># ['sepal length (cm)', 'sepal width (cm)', 'petal length (cm)', 'petal width (cm)']
</span>                            <span class="c1"># [꽃받침 길이, 꽃받침 폭, 꽃잎 길이, 꽃잎 폭]
</span><span class="n">iris_dataset</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">shape</span>     <span class="c1"># (150, 4) : sample 150, attribution 4
</span><span class="n">iris</span><span class="o">.</span><span class="n">data</span><span class="p">[:</span><span class="mi">10</span><span class="p">]</span>              <span class="c1"># ML에서 각 item은 "sample"이라하고, 속성은 "특성"이라 함
</span><span class="n">iris</span><span class="o">.</span><span class="n">target</span>                 <span class="c1"># results of labeling
</span></code></pre></div></div>

<p>이 dataset에 없는 새로운 data가 들어왔을때, 그 품종을 예측하는 ML Model을 만드는 것이 목적
<br /></p>

<h3 id="evaluate-the-ml-model">Evaluate the ML Model</h3>

<ul>
  <li>Model에 대한 성능 평가</li>
  <li>Problems of <code class="highlighter-rouge">Overfitting</code>; not-normalized</li>
</ul>

<p>-&gt; ML의 성능을 높이고 일반화하기 위해, 주어진 데이터를 train data - test data로 나눠야 함
<br /></p>

<h3 id="sklearnmodel_selectiontrain_test_split--split-data"><code class="highlighter-rouge">sklearn.model_selection.train_test_split</code> : Split data</h3>

<dl>
  <dt><strong>train data, test data</strong></dt>
  <dd>관례) scikit-learn에서 data는 대문자 X, label은 소문자 y로 표기</dd>
  <dd>수학 표기 방식을 따르되, data는 2차원 matrix이므로 대문자 X, target은 1차원 vector이므로 소문자 y 사용</dd>
  <dd>데이터가 순서대로 나누어지지 않도록, random 하게 섞음</dd>
  <dd>test set은 모든 class의 data를 포함하도록 잘 섞어야 함</dd>
</dl>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">train_test_split</span>
<span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">iris_dataset</span><span class="o">.</span><span class="n">data</span><span class="p">,</span> <span class="n">iris_dataset</span><span class="o">.</span><span class="n">target</span><span class="p">,</span> <span class="n">test_size</span> <span class="o">=</span> <span class="mf">0.25</span><span class="p">,</span> <span class="n">random_state</span> <span class="o">=</span> <span class="mi">2020</span><span class="p">)</span>

<span class="k">print</span> <span class="p">(</span><span class="n">X_train</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">X_test</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">y_train</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">y_test</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<span class="k">print</span> <span class="p">(</span><span class="n">X_train</span><span class="p">[:</span><span class="mi">10</span><span class="p">],</span> <span class="n">X_test</span><span class="p">[:</span><span class="mi">10</span><span class="p">],</span> <span class="n">y_train</span><span class="p">[:</span><span class="mi">10</span><span class="p">],</span> <span class="n">y_test</span><span class="p">[:</span><span class="mi">10</span><span class="p">],)</span>
</code></pre></div></div>

<p><br /></p>

<h3 id="look-into-data">Look into data</h3>

<p>ML 없이도 풀수 있는 문제가 아닌지, 필요한 정보가 누락되어 있는지 data 조사</p>

<h4 id="dataframe-scatter-plot">DataFrame, Scatter plot</h4>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">iris_df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="n">iris_dataset</span><span class="o">.</span><span class="n">feature_names</span><span class="p">)</span>
<span class="n">iris_df</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
<span class="n">iris_df</span><span class="o">.</span><span class="n">isnull</span><span class="p">()</span><span class="o">.</span><span class="nb">sum</span><span class="p">()</span>
<span class="n">pd</span><span class="o">.</span><span class="n">plotting</span><span class="o">.</span><span class="n">scatter_matrix</span><span class="p">(</span><span class="n">iris_df</span><span class="p">,</span> <span class="n">c</span> <span class="o">=</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">15</span><span class="p">,</span><span class="mi">15</span><span class="p">),</span> <span class="n">marker</span><span class="o">=</span><span class="s">'o'</span><span class="p">,</span> <span class="n">hist_kwds</span><span class="o">=</span><span class="p">{</span><span class="s">'bins'</span> <span class="p">:</span> <span class="mi">20</span><span class="p">},</span> <span class="n">s</span><span class="o">=</span><span class="mi">60</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">.8</span><span class="p">)</span>
</code></pre></div></div>

<p><br /></p>

<h3 id="fitting-machine-learning-by-knn-model">Fitting (Machine Learning) by KNN Model</h3>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">sklearn.neighbors</span> <span class="kn">import</span> <span class="n">KNeighborsClassifier</span>
<span class="n">knn</span> <span class="o">=</span> <span class="n">KNeighborsClassifier</span><span class="p">(</span><span class="n">n_neighbors</span> <span class="o">=</span> <span class="mi">3</span><span class="p">)</span>
<span class="n">knn</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">Y_train</span><span class="p">)</span>
</code></pre></div></div>

<p><br /></p>

<h4 id="knn-model">KNN Model</h4>

<p><strong>K-nearset neighbors</strong></p>

<ul>
  <li>train data 를 통해 model 만들고, 새로운 data 들어오면 가까운 훈련 data point를 찾아 분류</li>
  <li>scikit-learn의 모든 ML model은 estimator라는 python class로 구현</li>
  <li>KNN algorithm은 neighbors module 아래 KNeighborsClassifier class에 구현</li>
</ul>

<h4 id="parameters-of-knn">parameters of KNN</h4>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">KNeighborsClassifier</span><span class="p">(</span><span class="n">algorithm</span><span class="o">=</span><span class="s">'auto'</span><span class="p">,</span> 
                    <span class="n">leaf_size</span><span class="o">=</span><span class="mi">30</span><span class="p">,</span> 
                    <span class="n">metric</span><span class="o">=</span><span class="s">'minkowski'</span><span class="p">,</span> 
                    <span class="n">metric_params</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> 
                    <span class="n">n_jobs</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> 
                    <span class="n">n_neighbors</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> 
                    <span class="n">p</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> 
                    <span class="n">weights</span><span class="o">=</span><span class="s">'uniform'</span><span class="p">)</span>
</code></pre></div></div>

<p><br /></p>

<h3 id="predict-about-new-data">Predict about new data</h3>

<p>n by 4 array</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">X_new</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mi">3</span><span class="p">,</span> <span class="mf">4.2</span><span class="p">,</span> <span class="mf">0.8</span><span class="p">,</span> <span class="mf">0.4</span><span class="p">]])</span>
<span class="n">prediction</span> <span class="o">=</span> <span class="n">knn</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_new</span><span class="p">)</span>
<span class="k">print</span> <span class="p">(</span><span class="n">f</span><span class="s">"Predict about X_new : {prediction}"</span><span class="p">)</span>
<span class="k">print</span> <span class="p">(</span><span class="n">f</span><span class="s">"Name of the predicted one : {iris_dataset.target_names[prediction]}"</span><span class="p">)</span>

<span class="n">y_predict</span> <span class="o">=</span> <span class="n">knn</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
<span class="n">y_predict</span> <span class="o">==</span> <span class="n">y_test</span>
</code></pre></div></div>

<p><br /></p>

<h3 id="evaluate-accuracy">Evaluate Accuracy</h3>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">print</span> <span class="p">(</span><span class="n">f</span><span class="s">"Accuracy of test set by 'mean' : {np.mean(y_predict == y_test) * 100}"</span><span class="p">)</span>
<span class="k">print</span> <span class="p">(</span><span class="n">f</span><span class="s">"Accuracy of test set by 'knn.score' : {knn.score(X_test, y_test) * 100}"</span><span class="p">)</span>

<span class="kn">from</span> <span class="nn">sklearn</span> <span class="kn">import</span> <span class="n">metrics</span>
<span class="k">print</span> <span class="p">(</span><span class="n">f</span><span class="s">"Accuracy of test set by 'metrics.accuracy_score' : {metrics.accuracy_score(y_test, y_predict) * 100}"</span><span class="p">)</span>
</code></pre></div></div>

<p>multiple ‘k’s</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">accuracy_set</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">k_set</span> <span class="o">=</span> <span class="p">[</span><span class="n">i</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">12</span><span class="p">,</span><span class="mi">2</span><span class="p">)]</span>
<span class="k">print</span> <span class="p">(</span><span class="n">k_set</span><span class="p">)</span>

<span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="n">k_set</span><span class="p">:</span>
    <span class="n">knn</span> <span class="o">=</span> <span class="n">KNeighborsClassifier</span><span class="p">(</span><span class="n">n_neighbors</span><span class="o">=</span><span class="n">k</span><span class="p">)</span>
    <span class="n">knn</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
    <span class="n">y_predicts</span> <span class="o">=</span> <span class="n">knn</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
    <span class="n">accuracy</span> <span class="o">=</span> <span class="n">metrics</span><span class="o">.</span><span class="n">accuracy_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_predicts</span><span class="p">)</span>
    <span class="n">accuracy_set</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">accuracy</span><span class="p">)</span>

<span class="kn">from</span> <span class="nn">pprint</span> <span class="kn">import</span> <span class="n">pprint</span>
<span class="n">pprint</span><span class="p">(</span><span class="n">accuracy_set</span><span class="p">)</span>
<span class="k">print</span> <span class="p">(</span><span class="nb">max</span><span class="p">(</span><span class="n">accuracy_set</span><span class="p">))</span>
</code></pre></div></div>

<h2><br /><br /></h2>

<h3 id="kfold-for-cross-validation"><code class="highlighter-rouge">kfold</code> for Cross Validation</h3>

<p><img src="https://scikit-learn.org/stable/_images/grid_search_cross_validation.png" alt="grid_search_cross_validation" /></p>

<ul>
  <li><code class="highlighter-rouge">sklearn.model_selection.cross_val_score</code></li>
  <li><code class="highlighter-rouge">train_test_split()</code> 보다 성능이 좋은 평가방법</li>
  <li>데이터를 k번 쪼개서 k번 검증</li>
</ul>

<h4 id="cross-val-score"><code class="highlighter-rouge">cross-val-score</code></h4>

<p><img src="https://scikit-learn.org/stable/_static/ml_map.png" alt="ml_map" /></p>

<p><img src="https://scikit-learn.org/stable/_images/sphx_glr_plot_classifier_comparison_001.png" alt="classifier_comparison" /></p>

<ul>
  <li>
    <p>dataset : <code class="highlighter-rouge">sklearn.datasets.load_breast_cancer</code></p>

    <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code>  <span class="nb">type</span><span class="p">(</span><span class="n">cancer</span><span class="p">)</span>
  <span class="n">cancer</span><span class="o">.</span><span class="n">data</span><span class="p">[:</span><span class="mi">10</span><span class="p">]</span>
  <span class="n">cancer</span><span class="o">.</span><span class="n">feature_names</span>
  <span class="n">cancer</span><span class="o">.</span><span class="n">target_names</span>
  <span class="n">cancer</span><span class="o">.</span><span class="n">target</span><span class="p">[:</span><span class="mi">10</span><span class="p">]</span>
</code></pre></div>    </div>
  </li>
  <li>
    <p>test models</p>
    <ul>
      <li><code class="highlighter-rouge">sklearn.linear_model.LinearRegression</code>
        <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">LinearRegression</span><span class="p">(</span><span class="n">copy_X</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">fit_intercept</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">n_jobs</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="n">normalize</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
</code></pre></div>        </div>
      </li>
      <li><code class="highlighter-rouge">sklearn.neighbors.KNeighborsClassifier</code></li>
    </ul>
  </li>
</ul>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code>    <span class="n">KNeighborsClassifier</span><span class="p">(</span><span class="n">algorithm</span><span class="o">=</span><span class="s">'auto'</span><span class="p">,</span> 
                        <span class="n">leaf_size</span><span class="o">=</span><span class="mi">30</span><span class="p">,</span> <span class="n">metric</span><span class="o">=</span><span class="s">'minkowski'</span><span class="p">,</span>
                        <span class="n">metric_params</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span>
                        <span class="n">n_jobs</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> 
                        <span class="n">n_neighbors</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span> 
                        <span class="n">p</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
                        <span class="n">weights</span><span class="o">=</span><span class="s">'uniform'</span><span class="p">)</span>
</code></pre></div></div>
<p>`</p>
<ul>
  <li><code class="highlighter-rouge">sklearn.svm.LinearSVC</code>
    <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">LinearSVC</span><span class="p">(</span><span class="n">C</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span> 
            <span class="n">class_weight</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> 
            <span class="n">dual</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> 
            <span class="n">fit_intercept</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> 
            <span class="n">intercept_scaling</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> 
            <span class="n">loss</span><span class="o">=</span><span class="s">'squared_hinge'</span><span class="p">,</span> 
            <span class="n">max_iter</span><span class="o">=</span><span class="mi">1000</span><span class="p">,</span> 
            <span class="n">multi_class</span><span class="o">=</span><span class="s">'ovr'</span><span class="p">,</span> 
            <span class="n">penalty</span><span class="o">=</span><span class="s">'l2'</span><span class="p">,</span> 
            <span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> 
            <span class="n">tol</span><span class="o">=</span><span class="mf">0.0001</span><span class="p">,</span> 
            <span class="n">verbose</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
</code></pre></div>    </div>
  </li>
  <li><code class="highlighter-rouge">sklearn.tree.DecisionTreeClassifier</code>
    <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">DecisionTreeClassifier</span><span class="p">(</span><span class="n">class_weight</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> 
                        <span class="n">criterion</span><span class="o">=</span><span class="s">'gini'</span><span class="p">,</span> 
                        <span class="n">max_depth</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> 
                        <span class="n">max_features</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> 
                        <span class="n">max_leaf_nodes</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> 
                        <span class="n">min_impurity_decrease</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> 
                        <span class="n">min_impurity_split</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> 
                        <span class="n">min_samples_leaf</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> 
                        <span class="n">min_samples_split</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> 
                        <span class="n">min_weight_fraction_leaf</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> 
                        <span class="n">presort</span><span class="o">=</span><span class="bp">False</span><span class="p">,</span> 
                        <span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> 
                        <span class="n">splitter</span><span class="o">=</span><span class="s">'best'</span><span class="p">)</span>
</code></pre></div>    </div>
  </li>
  <li><code class="highlighter-rouge">sklearn.ensemble.RandomForestClassifier</code>
    <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">RandomForestClassifier</span><span class="p">(</span><span class="n">bootstrap</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> 
                        <span class="n">class_weight</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> 
                        <span class="n">criterion</span><span class="o">=</span><span class="s">'gini'</span><span class="p">,</span>
                        <span class="n">max_depth</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> 
                        <span class="n">max_features</span><span class="o">=</span><span class="s">'auto'</span><span class="p">,</span> 
                        <span class="n">max_leaf_nodes</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span>
                        <span class="n">min_impurity_decrease</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> 
                        <span class="n">min_impurity_split</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> 
                        <span class="n">min_samples_leaf</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> 
                        <span class="n">min_samples_split</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> 
                        <span class="n">min_weight_fraction_leaf</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> 
                        <span class="n">n_estimators</span><span class="o">=</span><span class="mi">6</span><span class="p">,</span> 
                        <span class="n">n_jobs</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> 
                        <span class="n">oob_score</span><span class="o">=</span><span class="bp">False</span><span class="p">,</span> 
                        <span class="n">random_state</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> 
                        <span class="n">verbose</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> 
                        <span class="n">warm_start</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
</code></pre></div>    </div>
  </li>
</ul>

<h4 id="exec-cross-value-score">exec. Cross Value Score</h4>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">score1</span> <span class="o">=</span> <span class="n">cross_val_score</span><span class="p">(</span> <span class="n">lr</span><span class="p">,</span> <span class="n">cancer</span><span class="o">.</span><span class="n">data</span><span class="p">,</span> <span class="n">cancer</span><span class="o">.</span><span class="n">target</span><span class="p">)</span>
<span class="n">score2</span> <span class="o">=</span> <span class="n">cross_val_score</span><span class="p">(</span> <span class="n">knn</span><span class="p">,</span> <span class="n">cancer</span><span class="o">.</span><span class="n">data</span><span class="p">,</span> <span class="n">cancer</span><span class="o">.</span><span class="n">target</span><span class="p">)</span>
<span class="n">score3</span> <span class="o">=</span> <span class="n">cross_val_score</span><span class="p">(</span> <span class="n">svm</span><span class="p">,</span> <span class="n">cancer</span><span class="o">.</span><span class="n">data</span><span class="p">,</span> <span class="n">cancer</span><span class="o">.</span><span class="n">target</span><span class="p">)</span>
<span class="n">score4</span> <span class="o">=</span> <span class="n">cross_val_score</span><span class="p">(</span> <span class="n">tree</span><span class="p">,</span> <span class="n">cancer</span><span class="o">.</span><span class="n">data</span><span class="p">,</span> <span class="n">cancer</span><span class="o">.</span><span class="n">target</span><span class="p">)</span>
<span class="n">score5</span> <span class="o">=</span> <span class="n">cross_val_score</span><span class="p">(</span> <span class="n">forest</span><span class="p">,</span> <span class="n">cancer</span><span class="o">.</span><span class="n">data</span><span class="p">,</span> <span class="n">cancer</span><span class="o">.</span><span class="n">target</span><span class="p">)</span>

<span class="k">print</span> <span class="p">(</span><span class="n">f</span><span class="s">'Linear Regression Cross Value Score : {score1.mean()}'</span><span class="p">)</span>
<span class="k">print</span> <span class="p">(</span><span class="n">f</span><span class="s">'KNN Cross Value Score : {score2.mean()}'</span><span class="p">)</span>
<span class="k">print</span> <span class="p">(</span><span class="n">f</span><span class="s">'SVM Cross Value Score : {score3.mean()}'</span><span class="p">)</span>
<span class="k">print</span> <span class="p">(</span><span class="n">f</span><span class="s">'Decision Tree Cross Value Score : {score4.mean()}'</span><span class="p">)</span>
<span class="k">print</span> <span class="p">(</span><span class="n">f</span><span class="s">'Random Forest Cross Value Score : {score5.mean()}'</span><span class="p">)</span>
</code></pre></div></div>

<h4 id="data-split해서-fitting">data split해서 fitting</h4>

<p>data의 편향을 줄이기 위함</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">lr</span> <span class="o">=</span> <span class="n">LinearRegression</span><span class="p">()</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">Y_train</span><span class="p">)</span>
<span class="n">knn</span> <span class="o">=</span> <span class="n">KNeighborsClassifier</span><span class="p">(</span><span class="n">n_neighbors</span><span class="o">=</span><span class="mi">4</span><span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">Y_train</span><span class="p">)</span>
<span class="n">svm</span> <span class="o">=</span> <span class="n">LinearSVC</span><span class="p">(</span><span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">Y_train</span><span class="p">)</span>
<span class="n">tree</span> <span class="o">=</span> <span class="n">DecisionTreeClassifier</span><span class="p">(</span><span class="n">max_depth</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">Y_train</span><span class="p">)</span>
<span class="n">forest</span> <span class="o">=</span> <span class="n">RandomForestClassifier</span><span class="p">(</span><span class="n">n_estimators</span><span class="o">=</span><span class="mi">6</span><span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">Y_train</span><span class="p">)</span>
</code></pre></div></div>

<h4 id="accuracy">Accuracy</h4>

<p>앞의 <code class="highlighter-rouge">cross_val_score</code>와 비교</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">print</span> <span class="p">(</span><span class="n">f</span><span class="s">'Linear Regression Accuracy : {lr.score(X_test, Y_test)}'</span><span class="p">)</span>
<span class="k">print</span> <span class="p">(</span><span class="n">f</span><span class="s">'KNN Accuracy : {knn.score(X_test, Y_test)}'</span><span class="p">)</span>
<span class="k">print</span> <span class="p">(</span><span class="n">f</span><span class="s">'SVM Accuracy : {svm.score(X_test, Y_test)}'</span><span class="p">)</span>
<span class="k">print</span> <span class="p">(</span><span class="n">f</span><span class="s">'Decision Tree Accuracy : {tree.score(X_test, Y_test)}'</span><span class="p">)</span>
<span class="k">print</span> <span class="p">(</span><span class="n">f</span><span class="s">'Random Forest Accuracy : {forest.score(X_test, Y_test)}'</span><span class="p">)</span>
</code></pre></div></div>

<p><br /><br /></p>

<p>===</p>

<h2 id="data-scaling">Data Scaling</h2>

<dl>
  <dt>Data Scaling</dt>
  <dd>one of preprocessings</dd>
  <dd>데이터 값이 너무 크거나 작은 경우 algorithm 학습이 0으로 수렴하거나 무한으로 발산해버릴 가능성 있기 때문</dd>
</dl>

<h3 id="scalers">Scalers</h3>

<p><img src="https://scikit-learn.org/stable/_images/sphx_glr_plot_scaling_importance_001.png" alt="Importance of Feature Scaling" /></p>

<p><img src="https://mblogthumb-phinf.pstatic.net/MjAxODA2MDdfMjY4/MDAxNTI4Mjk5MjU3NTQ2.vOMcaK9iWPOV8C5DQloUbWOnt4hQ93do9suj7Tytlh8g.vK69i-zMuLs3jep2bNVx34Y_jDNG-QbmhTRREkz3Powg.PNG.wideeyed/3.png?type=w800" alt="comparing scalers" /></p>

<h4 id="1-standard-scaler">1. Standard Scaler</h4>

<ul>
  <li>mean = 0, Var = 1</li>
</ul>

<h4 id="2-robust-scaler">2. Robust Scaler</h4>

<ul>
  <li>median, quartile</li>
</ul>

<h4 id="3-minmax-scaler">3. MinMax Scaler</h4>

<ul>
  <li>values of all features  : 0 ~ 1</li>
</ul>

<h4 id="4-normalizer">4. Normalizer</h4>

<ul>
  <li>위의 3 Scaler 와 달리 row 마다 정규화</li>
  <li>Uclid 거리가 1이 되도록 data 조정</li>
  <li>Spherical contour(구형 윤곽) : 좀더 빠르게 학습가능, 좋다는 의미가 아님</li>
</ul>

<h2 id="fitting">Fitting</h2>

<ul>
  <li>fit : learn data</li>
  <li>transform : scaling</li>
</ul>

<h2 id="use-dataset-breast-cancer">Use dataset: Breast-Cancer</h2>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">sklearn.datasets</span> <span class="kn">import</span> <span class="n">load_breast_cancer</span>
<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">train_test_split</span>

<span class="n">cancer</span> <span class="o">=</span> <span class="n">load_breast_cancer</span><span class="p">()</span>

<span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">cancer</span><span class="o">.</span><span class="n">data</span><span class="p">,</span> <span class="n">cancer</span><span class="o">.</span><span class="n">target</span><span class="p">,</span> <span class="n">stratify</span> <span class="o">=</span> <span class="n">cancer</span><span class="o">.</span><span class="n">target</span><span class="p">,</span> <span class="n">random_state</span> <span class="o">=</span> <span class="mi">2020</span><span class="p">)</span>
</code></pre></div></div>

<h2 id="standard-scaler">Standard Scaler</h2>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">StandardScaler</span>
<span class="n">scaler</span> <span class="o">=</span> <span class="n">StandardScaler</span><span class="p">()</span>
<span class="n">X_train_scale</span> <span class="o">=</span> <span class="n">scaler</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">X_train</span><span class="p">)</span>

<span class="k">print</span> <span class="p">(</span><span class="n">f</span><span class="s">"스케일 조정 전 features MIN Values : </span><span class="se">\n</span><span class="s">{X_train.min(axis = 0)}"</span><span class="p">)</span>
<span class="k">print</span> <span class="p">(</span><span class="n">f</span><span class="s">"스케일 조정 전 features MAX Values : </span><span class="se">\n</span><span class="s">{X_train.max(axis = 0)}"</span><span class="p">)</span>
<span class="k">print</span> <span class="p">(</span><span class="n">f</span><span class="s">"스케일 조정 후 features MIN Values : </span><span class="se">\n</span><span class="s">{X_train_scale.min(axis = 0)}"</span><span class="p">)</span>
<span class="k">print</span> <span class="p">(</span><span class="n">f</span><span class="s">"스케일 조정 후 features MAX Values : </span><span class="se">\n</span><span class="s">{X_train_scale.max(axis = 0)}"</span><span class="p">)</span>
</code></pre></div></div>

<h2 id="robert-scaler">Robert Scaler</h2>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">RobustScaler</span>
<span class="n">rs</span> <span class="o">=</span> <span class="n">RobustScaler</span><span class="p">()</span>
<span class="n">X_train_rs</span> <span class="o">=</span> <span class="n">rs</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">X_train</span><span class="p">)</span>

<span class="k">print</span> <span class="p">(</span><span class="n">f</span><span class="s">"스케일 조정 전 features MIN Values : </span><span class="se">\n</span><span class="s">{X_train.min(axis = 0)}"</span><span class="p">)</span>
<span class="k">print</span> <span class="p">(</span><span class="n">f</span><span class="s">"스케일 조정 전 features MAX Values : </span><span class="se">\n</span><span class="s">{X_train.max(axis = 0)}"</span><span class="p">)</span>
<span class="k">print</span> <span class="p">(</span><span class="n">f</span><span class="s">"스케일 조정 후 features MIN Values : </span><span class="se">\n</span><span class="s">{X_train_rs.min(axis = 0)}"</span><span class="p">)</span>
<span class="k">print</span> <span class="p">(</span><span class="n">f</span><span class="s">"스케일 조정 후 features MAX Values : </span><span class="se">\n</span><span class="s">{X_train_rs.max(axis = 0)}"</span><span class="p">)</span>
</code></pre></div></div>

<h2 id="minmax-scaler">MinMax Scaler</h2>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">MinMaxScaler</span>
<span class="n">mms</span> <span class="o">=</span> <span class="n">MinMaxScaler</span><span class="p">()</span>
<span class="n">X_train_mms</span> <span class="o">=</span> <span class="n">mms</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">X_train</span><span class="p">)</span>

<span class="k">print</span> <span class="p">(</span><span class="n">f</span><span class="s">"스케일 조정 전 features MIN Values : </span><span class="se">\n</span><span class="s">{X_train.min(axis = 0)}"</span><span class="p">)</span>
<span class="k">print</span> <span class="p">(</span><span class="n">f</span><span class="s">"스케일 조정 전 features MAX Values : </span><span class="se">\n</span><span class="s">{X_train.max(axis = 0)}"</span><span class="p">)</span>
<span class="k">print</span> <span class="p">(</span><span class="n">f</span><span class="s">"스케일 조정 후 features MIN Values : </span><span class="se">\n</span><span class="s">{X_train_mms.min(axis = 0)}"</span><span class="p">)</span>
<span class="k">print</span> <span class="p">(</span><span class="n">f</span><span class="s">"스케일 조정 후 features MAX Values : </span><span class="se">\n</span><span class="s">{X_train_mms.max(axis = 0)}"</span><span class="p">)</span>
</code></pre></div></div>

<h2 id="normalizer">Normalizer</h2>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">Normalizer</span>
<span class="n">nor</span> <span class="o">=</span> <span class="n">Normalizer</span><span class="p">()</span>
<span class="n">X_train_nor</span> <span class="o">=</span> <span class="n">nor</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">X_train</span><span class="p">)</span>

<span class="k">print</span> <span class="p">(</span><span class="n">f</span><span class="s">"스케일 조정 전 features MIN Values : </span><span class="se">\n</span><span class="s">{X_train.min(axis = 0)}"</span><span class="p">)</span>
<span class="k">print</span> <span class="p">(</span><span class="n">f</span><span class="s">"스케일 조정 전 features MAX Values : </span><span class="se">\n</span><span class="s">{X_train.max(axis = 0)}"</span><span class="p">)</span>
<span class="k">print</span> <span class="p">(</span><span class="n">f</span><span class="s">"스케일 조정 후 features MIN Values : </span><span class="se">\n</span><span class="s">{X_train_nor.min(axis = 0)}"</span><span class="p">)</span>
<span class="k">print</span> <span class="p">(</span><span class="n">f</span><span class="s">"스케일 조정 후 features MAX Values : </span><span class="se">\n</span><span class="s">{X_train_nor.max(axis = 0)}"</span><span class="p">)</span>
</code></pre></div></div>

<h3 id="analysis-between-before-and-after-data-scaling-using-svc">analysis between before and after data <code class="highlighter-rouge">Scaling</code> using <code class="highlighter-rouge">SVC</code></h3>

<ul>
  <li><strong><em>before</em></strong> data scaling</li>
</ul>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">sklearn.svm</span> <span class="kn">import</span> <span class="n">SVC</span>
<span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">cancer</span><span class="o">.</span><span class="n">data</span><span class="p">,</span> <span class="n">cancer</span><span class="o">.</span><span class="n">target</span><span class="p">,</span> <span class="n">random_state</span> <span class="o">=</span> <span class="mi">2020</span><span class="p">)</span>

<span class="n">svc</span> <span class="o">=</span> <span class="n">SVC</span><span class="p">()</span>
<span class="n">svc</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>

<span class="n">svc</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">)</span>       <span class="c1"># 0.5734265734265734
</span></code></pre></div></div>

<ul>
  <li><strong><em>after</em></strong> data scaling</li>
</ul>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">mms</span> <span class="o">=</span> <span class="n">MinMaxScaler</span><span class="p">()</span>

<span class="n">X_train_mms</span> <span class="o">=</span> <span class="n">mms</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">X_train</span><span class="p">)</span>
<span class="n">X_test_mms</span> <span class="o">=</span> <span class="n">mms</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>

<span class="n">svc</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train_mms</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>

<span class="n">svc</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X_test_mms</span><span class="p">,</span> <span class="n">y_test</span><span class="p">)</span>   <span class="c1"># 0.958041958041958
</span></code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">std</span> <span class="o">=</span> <span class="n">StandardScaler</span><span class="p">()</span>

<span class="n">X_train_std</span> <span class="o">=</span> <span class="n">std</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">X_train</span><span class="p">)</span>
<span class="n">X_test_std</span> <span class="o">=</span> <span class="n">std</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>

<span class="n">svc</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train_std</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
<span class="n">svc</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X_test_std</span><span class="p">,</span> <span class="n">y_test</span><span class="p">)</span>   <span class="c1"># 0.965034965034965
</span></code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">robu</span> <span class="o">=</span> <span class="n">RobustScaler</span><span class="p">()</span>

<span class="n">X_train_robu</span> <span class="o">=</span> <span class="n">robu</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">X_train</span><span class="p">)</span>
<span class="n">X_test_robu</span> <span class="o">=</span> <span class="n">robu</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>

<span class="n">svc</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train_robu</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
<span class="n">svc</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X_test_robu</span><span class="p">,</span> <span class="n">y_test</span><span class="p">)</span>  <span class="c1"># 0.986013986013986
</span></code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">norm</span> <span class="o">=</span> <span class="n">Normalizer</span><span class="p">()</span>

<span class="n">X_train_norm</span> <span class="o">=</span> <span class="n">norm</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">X_train</span><span class="p">)</span>
<span class="n">X_test_norm</span> <span class="o">=</span> <span class="n">norm</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>

<span class="n">svc</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train_norm</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
<span class="n">svc</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X_test_norm</span><span class="p">,</span> <span class="n">y_test</span><span class="p">)</span>  <span class="c1"># 0.5734265734265734
</span></code></pre></div></div>
<p><br /><br /></p>

<hr />

<h1 id="deep-learning-with-tensorflow-as-tf--keras">Deep Learning with Tensorflow (as tf) &amp; Keras</h1>

<ul>
  <li>tensorflow 내부에 <code class="highlighter-rouge">image classification model</code> 등 각종 models of machine learning 공개</li>
  <li>Inception3 : 일반적인 이미지 예측 model, 여기에 내가 개인적으로 갖고 있는 이미지들로 학습</li>
  <li>처음부터 새로 model 만드는 것보다 inception3 등 기존 예측 models를 re-training 시켜서 사용하는 것만 잘해도 tf를 잘 활용할 수 있다</li>
</ul>

<h2 id="data-flow-graph">Data Flow Graph</h2>

<ul>
  <li>tf 는 data flow graph 형태로 작동 : data flow에 관련된 graph를 잘 알아야 tf를 잘 쓸 수 있다</li>
</ul>

<h3 id="구성요소">구성요소</h3>

<p><img src="https://image.slidesharecdn.com/pycon-zeppelin-sprint-170814171253/95/zeppelin-tensorflow-deep-learning-24-638.jpg?cb=1502730928" alt="DataFlowGraph" /></p>

<ul>
  <li>Node : mathematical operations with tensors</li>
  <li>Edge : flow way of tensor( multidimensional data array )</li>
  <li>tensor(data)가 nodes를 지나면서 연산이 이루어짐, tensor가 graph상에서 이동(flow)해서 TensorFlow</li>
</ul>

<h3 id="tensor">Tensor</h3>

<ul>
  <li>multidimensional data array : any value available
    <ul>
      <li>Rank : number of dimensions
        <ul>
          <li>0 : scalar</li>
          <li>1 : vector</li>
          <li>2 : matrix</li>
          <li>3 : 3-tensor</li>
          <li>n : n-tensor</li>
        </ul>
      </li>
      <li>Shape : number of elements in each dimensions
        <ul>
          <li>ex) [[1,2,3,],[4,5,6,],[7,8,9,]].shape = [3,3]</li>
        </ul>
      </li>
      <li>Type : data-type, 대부분 float32</li>
    </ul>
  </li>
</ul>

<h2 id="keras">Keras</h2>

<ul>
  <li>원래 Tensorflow와는 별개의 library, TF 2.0로 버전업하면서 tf에 포함시킴</li>
</ul>

<h3 id="주요-특징">주요 특징</h3>

<ul>
  <li>Modularity :
    <ul>
      <li>keras의 module들은 독립적, 설정가능, 가능한 최소한의 제약사항으로 서로 연결, models은 sequences or graphs로 구성한 것</li>
      <li>특히 신경망층, 비용함수, 최적화기, 초기화기법, 활성화함수, 정규화기법 등 모두 독립적 modules, 새로운 model 만들기 위해 이러한 modules 조합 가능</li>
    </ul>
  </li>
  <li>Minimalism : 각 module은 짧고 간결, 모든 code는 한번 훑어보는 것으로도 이해 가능해야, 단 반복속도 및 혁신성은 다소 떨어질 수 있음</li>
  <li>쉬운 확장성 : easy to add new classes or functions to modules, 고급연구에 필요한 다양한 표현 가능</li>
  <li>Python based : 별도의 model 설정 필요없이 python codes로 정의 가능</li>
</ul>

<h3 id="기본-개념">기본 개념</h3>

<ul>
  <li>Model : basic data structure
    <ul>
      <li>sequence model : 원하는 layers를 쉽게 순차적으로 쌓을 수 있음</li>
      <li>다중 출력 등 좀더 복잡한 model 구성은 keras의 함수 API 사용</li>
    </ul>
  </li>
  <li>Deep Learning Model by Keras
    <ul>
      <li>
        <ol>
          <li>dataset 생성
            <ul>
              <li>원본 data 불러오거나 simulation 통해 data 생성</li>
              <li>훈련 set / 검증 set / 시험 set 생성</li>
              <li>data transformatting : ex. images to array</li>
            </ul>
          </li>
        </ol>
      </li>
      <li>
        <ol>
          <li>model 구성
            <ul>
              <li>sequence model 생성한 뒤(객체), 필요한 layer 추가하여 구성</li>
              <li>좀 더 복잡한 model 필요 시 Keras 함수 API 사용</li>
            </ul>
          </li>
        </ol>
      </li>
      <li>
        <ol>
          <li>Model’s learning process 설정
            <ul>
              <li><code class="highlighter-rouge">compile()</code></li>
              <li>학습 전 학습에 대한 설정</li>
              <li>손실 함수 및 최적화 방법 정의</li>
            </ul>
          </li>
        </ol>
      </li>
      <li>
        <ol>
          <li>learning process
            <ul>
              <li><code class="highlighter-rouge">fit()</code></li>
              <li>훈련 set 이용해 model로 학습</li>
            </ul>
          </li>
        </ol>
      </li>
      <li>
        <ol>
          <li>학습과정 살펴보기
            <ul>
              <li>훈련 set - 검증 set의 손실 및 정확도 측정</li>
              <li>반복 횟수에 따른 손실 및 정확도 추이를 보며 학습 상황 판단</li>
            </ul>
          </li>
        </ol>
      </li>
      <li>
        <ol>
          <li>Evalutate Model
            <ul>
              <li><code class="highlighter-rouge">evaluate()</code></li>
              <li>준비된 시험 set로 학습한 model 평가</li>
            </ul>
          </li>
        </ol>
      </li>
      <li>
        <ol>
          <li>use this model
            <ul>
              <li><code class="highlighter-rouge">predict()</code></li>
              <li>임의의 입력, get model’s output</li>
            </ul>
          </li>
        </ol>
      </li>
    </ul>
  </li>
</ul>

<h3 id="ml과의-차이점">ML과의 차이점</h3>

<ul>
  <li>ML은 모델 훈련만 - DL은 모델과 학습과정 설계 가능</li>
  <li>ML은 학습 결과만 return - DL은 학습 과정 중간에 대한 check 가능</li>
</ul>

<h3 id="sequential-model-맛보기">Sequential Model 맛보기</h3>

<p><code class="highlighter-rouge">tensorflow.keras.layers</code></p>

<ul>
  <li>layers를 쌓아 만드는 model</li>
  <li>multi-layer perceptron</li>
</ul>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">tensorflow.keras</span> <span class="kn">import</span> <span class="n">layers</span>

<span class="c1"># 3개의 layers
</span><span class="n">model</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">Sequential</span><span class="p">()</span>

<span class="c1"># 64개의 output units, 완전 연결 층
</span><span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">64</span><span class="p">,</span> <span class="n">activation</span> <span class="o">=</span> <span class="s">'relu'</span><span class="p">))</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">64</span><span class="p">,</span> <span class="n">activation</span> <span class="o">=</span> <span class="s">'relu'</span><span class="p">))</span>

<span class="c1"># 10개의 output units, Softmax 층
</span><span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="n">activation</span> <span class="o">=</span> <span class="s">'softmax'</span><span class="p">))</span>
</code></pre></div></div>

        
      </section>

      <footer class="page__meta">
        
        
  


  
  
  

  <p class="page__taxonomy">
    <strong><i class="fas fa-fw fa-tags" aria-hidden="true"></i> Tags: </strong>
    <span itemprop="keywords">
    
      
      
      <a href="/tags/#lecturenotes" class="page__taxonomy-item" rel="tag">LectureNotes</a><span class="sep">, </span>
    
      
      
      <a href="/tags/#machinelearning" class="page__taxonomy-item" rel="tag">MachineLearning</a><span class="sep">, </span>
    
      
      
      <a href="/tags/#python" class="page__taxonomy-item" rel="tag">Python</a>
    
    </span>
  </p>




  


  
  
  

  <p class="page__taxonomy">
    <strong><i class="fas fa-fw fa-folder-open" aria-hidden="true"></i> Categories: </strong>
    <span itemprop="keywords">
    
      
      
      <a href="/categories/#aidata" class="page__taxonomy-item" rel="tag">Aidata</a><span class="sep">, </span>
    
      
      
      <a href="/categories/#python" class="page__taxonomy-item" rel="tag">Python</a>
    
    </span>
  </p>


        
          <p class="page__date"><strong><i class="fas fa-fw fa-calendar-alt" aria-hidden="true"></i> Updated:</strong> <time datetime="2020-04-27T00:00:00+09:00">April 27, 2020</time></p>
        
      </footer>

      <section class="page__share">
  

  <a href="https://twitter.com/intent/tweet?text=%5BPython%5D+ML+Quick+Review%20https%3A%2F%2Fgitgitwi.github.io%2Faidata%2Fpython%2Flec-ML_quick_review%2F" class="btn btn--twitter" onclick="window.open(this.href, 'window', 'left=20,top=20,width=500,height=500,toolbar=1,resizable=0'); return false;" title="Share on Twitter"><i class="fab fa-fw fa-twitter" aria-hidden="true"></i><span> Twitter</span></a>

  <a href="https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fgitgitwi.github.io%2Faidata%2Fpython%2Flec-ML_quick_review%2F" class="btn btn--facebook" onclick="window.open(this.href, 'window', 'left=20,top=20,width=500,height=500,toolbar=1,resizable=0'); return false;" title="Share on Facebook"><i class="fab fa-fw fa-facebook" aria-hidden="true"></i><span> Facebook</span></a>

  <a href="https://www.linkedin.com/shareArticle?mini=true&url=https%3A%2F%2Fgitgitwi.github.io%2Faidata%2Fpython%2Flec-ML_quick_review%2F" class="btn btn--linkedin" onclick="window.open(this.href, 'window', 'left=20,top=20,width=500,height=500,toolbar=1,resizable=0'); return false;" title="Share on LinkedIn"><i class="fab fa-fw fa-linkedin" aria-hidden="true"></i><span> LinkedIn</span></a>
</section>


    </div>

    
      <div id="disqus_thread"></div>
      <script>
        var disqus_config = function () {
        this.page.url = "https://gitgitwi.github.io/aidata/python/lec-ML_quick_review/";  // Replace PAGE_URL with your page's canonical URL variable
        this.page.identifier = "/aidata/python/lec-ML_quick_review"; // Replace PAGE_IDENTIFIER with your page's unique identifier variable
        };

        (function() { // DON'T EDIT BELOW THIS LINE
          var d = document, s = d.createElement('script');
          s.src = 'https://gitgitwi.disqus.com/embed.js';
          s.setAttribute('data-timestamp', +new Date());
          (d.head || d.body).appendChild(s);
        })();
      </script>
      <noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
    
    
    
  <nav class="pagination">
    
      <a href="/career/Fri_CPTeamX%EC%98%81%EB%93%B1%ED%8F%AC%EA%B5%AC%EC%B2%AD/" class="pagination--pager" title="CPTeam X 영등포구청 외국계 취업 멘토링(MS,AWS 등)
">Previous</a>
    
    
      <a href="/career/CPTeamX%EC%84%9C%EC%B4%88%EA%B5%AC%EC%B2%AD_%EC%99%B8%EA%B5%AD%EA%B3%84_%EC%B7%A8%EC%97%85%EB%A9%98%ED%86%A0%EB%A7%81/" class="pagination--pager" title="CPTeam X 서초구청 외국계 취업 멘토링(IBM, AWS 등)
">Next</a>
    
  </nav>

  </article>

  
  
    <div class="page__related">
      <h4 class="page__related-title">You May Also Enjoy</h4>
      <div class="grid__wrapper">
        
          



<div class="grid__item">
  <article class="archive__item" itemscope itemtype="https://schema.org/CreativeWork">
    
    <h2 class="archive__item-title" itemprop="headline">
      
        <a href="/aidata/python/DLwithCodes/" rel="permalink">[SKTacademy/코드로 알아보는 딥러닝 입문] DNN/CNN/GAN/RNN/RL with Tensorflow
</a>
      
    </h2>
    
    
      <p class="page__meta"><i class="far fa-fw fa-calendar-alt" aria-hidden="true"></i> May 04 2020</p>
    
    <p class="archive__item-excerpt" itemprop="description">
</p>
  </article>
</div>

        
          



<div class="grid__item">
  <article class="archive__item" itemscope itemtype="https://schema.org/CreativeWork">
    
    <h2 class="archive__item-title" itemprop="headline">
      
        <a href="/aidata/python/Keras06_GM/" rel="permalink">[SKTacademy/딥러닝 입문에서 활용까지] 6강. GM  ~  7강. Keras vs. PyTorch
</a>
      
    </h2>
    
    
      <p class="page__meta"><i class="far fa-fw fa-calendar-alt" aria-hidden="true"></i> May 03 2020</p>
    
    <p class="archive__item-excerpt" itemprop="description">
</p>
  </article>
</div>

        
          



<div class="grid__item">
  <article class="archive__item" itemscope itemtype="https://schema.org/CreativeWork">
    
    <h2 class="archive__item-title" itemprop="headline">
      
        <a href="/aidata/python/Keras05_RNN/" rel="permalink">[SKTacademy/딥러닝 입문에서 활용까지] 5강. RNN;  Recurrent Neural Networks
</a>
      
    </h2>
    
    
      <p class="page__meta"><i class="far fa-fw fa-calendar-alt" aria-hidden="true"></i> May 03 2020</p>
    
    <p class="archive__item-excerpt" itemprop="description">
</p>
  </article>
</div>

        
          



<div class="grid__item">
  <article class="archive__item" itemscope itemtype="https://schema.org/CreativeWork">
    
    <h2 class="archive__item-title" itemprop="headline">
      
        <a href="/aidata/python/Keras04_CNN/" rel="permalink">[SKTacademy/딥러닝 입문에서 활용까지] 4강. CNN; Convolutional Neural Networks
</a>
      
    </h2>
    
    
      <p class="page__meta"><i class="far fa-fw fa-calendar-alt" aria-hidden="true"></i> May 03 2020</p>
    
    <p class="archive__item-excerpt" itemprop="description">
</p>
  </article>
</div>

        
      </div>
    </div>
  
  
</div>

    </div>

    
      <div class="search-content">
        <div class="search-content__inner-wrap">
  
  
  <form onsubmit="return googleCustomSearchExecute();" id="cse-search-box-form-id">
    <label class="sr-only" for="cse-search-input-box-id">
      Enter your search term...
    </label>
    <input type="search" id="cse-search-input-box-id" class="search-input" tabindex="-1" placeholder="Enter your search term..." />
  </form>
  <div id="results" class="results">
    <gcse:searchresults-only></gcse:searchresults-only>
  </div>
  
</div>

      </div>
    

    <div id="footer" class="page__footer">
      <footer>
        <!-- start custom footer snippets -->

<!-- end custom footer snippets -->
        <div class="page__footer-follow">
  <ul class="social-icons">
    

    
      
        
          <li><a href="https://gitgitWi.github.io" rel="nofollow noopener noreferrer"><i class="fab fa-fw fa-github" aria-hidden="true"></i> GitHub</a></li>
        
      
    

    <li><a href="/feed.xml"><i class="fas fa-fw fa-rss-square" aria-hidden="true"></i> Feed</a></li>
  </ul>
</div>

<div class="page__footer-copyright">&copy; 2020 gitgitWi. Powered by <a href="https://jekyllrb.com" rel="nofollow">Jekyll</a> &amp; <a href="https://mademistakes.com/work/minimal-mistakes-jekyll-theme/" rel="nofollow">Minimal Mistakes</a>.</div>

      </footer>
    </div>

    
  <script src="/assets/js/main.min.js"></script>
  <script src="https://kit.fontawesome.com/4eee35f757.js"></script>



  
  
      <script>
  (function () {
    var cx = '012188663101936892718:4lpzgsvlle4';
    var gcse = document.createElement('script');
    gcse.type = 'text/javascript';
    gcse.async = true;
    gcse.src = 'https://cse.google.com/cse.js?cx=' + cx;
    var s = document.getElementsByTagName('script')[0];
    s.parentNode.insertBefore(gcse, s);
  })();

  function googleCustomSearchExecute() {
    var input = document.getElementById('cse-search-input-box-id');
    var element = google.search.cse.element.getElement('searchresults-only0');
    if (input.value == '') {
      element.clearAllResults();
    } else {
      element.execute(input.value);
    }
    return false;
  }

  
    $(document).ready(function () {
      $('input#cse-search-input-box-id').on('keyup', function () {
        googleCustomSearchExecute();
      });
    });
  
</script>
    





    
  


<div id="disqus_thread"></div>
  <script>
    var disqus_config = function () {
    this.page.url = "https://gitgitwi.github.io/aidata/python/lec-ML_quick_review/";  // Replace PAGE_URL with your page's canonical URL variable
    this.page.identifier = "/aidata/python/lec-ML_quick_review"; // Replace PAGE_IDENTIFIER with your page's unique identifier variable
    };

    (function() { // DON'T EDIT BELOW THIS LINE
      var d = document, s = d.createElement('script');
      s.src = 'https://gitgitwi.disqus.com/embed.js';
      s.setAttribute('data-timestamp', +new Date());
      (d.head || d.body).appendChild(s);
    })();
  </script>
  <noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>



  





  </body>
</html>
